{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd487927",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hostname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6b5e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /global/cfs/cdirs/m4334/jerry/climsim3_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669f89a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d960e3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib.cm import ScalarMappable\n",
    "from matplotlib import gridspec\n",
    "import matplotlib.lines as mlines\n",
    "from matplotlib.transforms import blended_transform_factory\n",
    "import os, gc, sys, glob, string, argparse\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import string\n",
    "import itertools\n",
    "import sys\n",
    "import pickle\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from climsim_utils.data_utils import *\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"axes.titlesize\":   14,\n",
    "    \"axes.labelsize\":   13,\n",
    "    \"figure.titlesize\": 17,\n",
    "    \"xtick.labelsize\":  11,\n",
    "    \"ytick.labelsize\":  11,\n",
    "    \"legend.fontsize\":  12,\n",
    "})\n",
    "\n",
    "def scale_default(param_name, scale_factor):\n",
    "    \"\"\"Get scaled version of default rcParam\"\"\"\n",
    "    return plt.rcParams[param_name] * scale_factor\n",
    "\n",
    "grid_path = '/global/cfs/cdirs/m4334/jerry/climsim3_dev/grid_info/ClimSim_low-res_grid-info.nc'\n",
    "\n",
    "input_mean_v2_rh_mc_file = 'input_mean_v2_rh_mc_pervar.nc'\n",
    "\n",
    "input_max_v2_rh_mc_file = 'input_max_v2_rh_mc_pervar.nc'\n",
    "input_min_v2_rh_mc_file = 'input_min_v2_rh_mc_pervar.nc'\n",
    "output_scale_v2_rh_mc_file = 'output_scale_std_lowerthred_v2_rh_mc.nc'\n",
    "\n",
    "input_mean_v6_file = 'input_mean_v6_pervar.nc'\n",
    "input_max_v6_file = 'input_max_v6_pervar.nc'\n",
    "input_min_v6_file = 'input_min_v6_pervar.nc'\n",
    "output_scale_v6_file = 'output_scale_std_lowerthred_v6.nc'\n",
    "\n",
    "lbd_qn_file = 'qn_exp_lambda_large.txt'\n",
    "\n",
    "grid_info = xr.open_dataset(grid_path)\n",
    "grid_area = grid_info['area'].values\n",
    "area_weight = grid_area/np.sum(grid_area)\n",
    "level = grid_info.lev.values\n",
    "\n",
    "input_mean_v2_rh_mc = xr.open_dataset('/global/cfs/cdirs/m4334/jerry/climsim3_dev/preprocessing/normalizations/inputs/' + input_mean_v2_rh_mc_file)\n",
    "input_max_v2_rh_mc = xr.open_dataset('/global/cfs/cdirs/m4334/jerry/climsim3_dev/preprocessing/normalizations/inputs/' + input_max_v2_rh_mc_file)\n",
    "input_min_v2_rh_mc = xr.open_dataset('/global/cfs/cdirs/m4334/jerry/climsim3_dev/preprocessing/normalizations/inputs/' + input_min_v2_rh_mc_file)\n",
    "output_scale_v2_rh_mc = xr.open_dataset('/global/cfs/cdirs/m4334/jerry/climsim3_dev/preprocessing/normalizations/outputs/' + output_scale_v2_rh_mc_file)\n",
    "\n",
    "input_mean_v6 = xr.open_dataset('/global/cfs/cdirs/m4334/jerry/climsim3_dev/preprocessing/normalizations/inputs/' + input_mean_v6_file)\n",
    "input_max_v6 = xr.open_dataset('/global/cfs/cdirs/m4334/jerry/climsim3_dev/preprocessing/normalizations/inputs/' + input_max_v6_file)\n",
    "input_min_v6 = xr.open_dataset('/global/cfs/cdirs/m4334/jerry/climsim3_dev/preprocessing/normalizations/inputs/' + input_min_v6_file)\n",
    "output_scale_v6 = xr.open_dataset('/global/cfs/cdirs/m4334/jerry/climsim3_dev/preprocessing/normalizations/outputs/' + output_scale_v6_file)\n",
    "\n",
    "lbd_qn = np.loadtxt('/global/cfs/cdirs/m4334/jerry/climsim3_dev/preprocessing/normalizations/inputs/' + lbd_qn_file, delimiter = ',')\n",
    "\n",
    "data_v2_rh_mc = data_utils(grid_info = grid_info, \n",
    "                           input_mean = input_mean_v2_rh_mc, \n",
    "                           input_max = input_max_v2_rh_mc, \n",
    "                           input_min = input_min_v2_rh_mc, \n",
    "                           output_scale = output_scale_v2_rh_mc,\n",
    "                           qinput_log = False,\n",
    "                           normalize = False)\n",
    "data_v2_rh_mc.set_to_v2_rh_mc_vars()\n",
    "\n",
    "data_v6 = data_utils(grid_info = grid_info,\n",
    "                     input_mean = input_mean_v6,\n",
    "                     input_max = input_max_v6,\n",
    "                     input_min = input_min_v6,\n",
    "                     output_scale = output_scale_v6,\n",
    "                     qinput_log = False,\n",
    "                     normalize = False)                     \n",
    "data_v6.set_to_v6_vars()\n",
    "\n",
    "actual_input_v2_rh_mc = np.load('/pscratch/sd/j/jerrylin/hugging/E3SM-MMF_ne4/preprocessing/v2_rh_mc/test_set/actual_input.npy')\n",
    "actual_target_v2_rh_mc = np.load('/pscratch/sd/j/jerrylin/hugging/E3SM-MMF_ne4/preprocessing/v2_rh_mc/test_set/actual_target.npy')\n",
    "\n",
    "actual_input_v6 = np.load('/pscratch/sd/j/jerrylin/hugging/E3SM-MMF_ne4/preprocessing/v6/test_set/actual_input.npy')\n",
    "actual_target_v6 = np.load('/pscratch/sd/j/jerrylin/hugging/E3SM-MMF_ne4/preprocessing/v6/test_set/actual_target.npy')\n",
    "\n",
    "assert np.array_equal(actual_target_v2_rh_mc, actual_target_v6)\n",
    "actual_target = np.load('/pscratch/sd/j/jerrylin/hugging/E3SM-MMF_ne4/preprocessing/v2_rh_mc/test_set/original_test_vars/actual_target_v2.npy')\n",
    "del actual_target_v2_rh_mc\n",
    "del actual_target_v6\n",
    "\n",
    "assert np.array_equal(actual_input_v2_rh_mc[:,:,data_v2_rh_mc.ps_index], \n",
    "                      actual_input_v6[:,:,data_v6.ps_index])\n",
    "\n",
    "surface_pressure = actual_input_v2_rh_mc[:, :, data_v2_rh_mc.ps_index]\n",
    "hyam_component = (data_v2_rh_mc.hyam * data_v2_rh_mc.p0)[None,None,:]\n",
    "hybm_component = data_v2_rh_mc.hybm[None,None,:] * surface_pressure[:,:,None]\n",
    "pressures = hyam_component + hybm_component\n",
    "pressures_binned = data_v2_rh_mc.zonal_bin_weight_3d(pressures)\n",
    "lat_bin_mids = data_v2_rh_mc.lat_bin_mids\n",
    "lats = data_v2_rh_mc.lats\n",
    "lons = data_v2_rh_mc.lons\n",
    "\n",
    "idx_p400_t10 = np.load('/pscratch/sd/z/zeyuanhu/hu_etal2024_data/microphysics_hourly/first_true_indices_p400_t10.npy')\n",
    "for i in range(idx_p400_t10.shape[0]):\n",
    "    for j in range(idx_p400_t10.shape[1]):\n",
    "        idx_p400_t10[i,j] = level[int(idx_p400_t10[i,j])]\n",
    "\n",
    "idx_p400_t10 = idx_p400_t10.mean(axis=0)\n",
    "idx_p400_t10 = idx_p400_t10[np.newaxis,:]\n",
    "\n",
    "idx_tropopause_zm = data_v2_rh_mc.zonal_bin_weight_2d(idx_p400_t10).flatten()\n",
    "\n",
    "area_weight_dict = {\n",
    "    'global': area_weight,\n",
    "    'nh': np.where(lats > 30, area_weight, 0),\n",
    "    'sh': np.where(lats < -30, area_weight, 0),\n",
    "    'tropics': np.where((lats > -30) & (lats < 30), area_weight, 0)\n",
    "}\n",
    "\n",
    "lat_idx_dict = {\n",
    "    '30S_30N': ((data_v2_rh_mc.lats < 30) & (data_v2_rh_mc.lats > -30))[None,:,None],\n",
    "    '30N_60N': ((data_v2_rh_mc.lats < 60) & (data_v2_rh_mc.lats > 30))[None,:,None],\n",
    "    '30S_60S': ((data_v2_rh_mc.lats < -30) & (data_v2_rh_mc.lats > -60))[None,:,None],\n",
    "    '60N_90N': (data_v2_rh_mc.lats > 60)[None,:,None],\n",
    "    '60S_90S': (data_v2_rh_mc.lats < -60)[None,:,None]\n",
    "}\n",
    "\n",
    "pressure_idx_dict = {\n",
    "    'below_400hPa': pressures >= 400,\n",
    "    'above_400hPa': pressures < 400\n",
    "}\n",
    "\n",
    "config_names = {\n",
    "    'standard': 'Standard',\n",
    "    'conf_loss': 'Confidence Loss',\n",
    "    'diff_loss': 'Difference Loss',\n",
    "    'multirep': 'Multirepresentation',\n",
    "    'v6': 'Expanded Variable List'\n",
    "}\n",
    "\n",
    "model_names = {\n",
    "    'unet': 'U-Net',\n",
    "    'squeezeformer': 'Squeezeformer',\n",
    "    'pure_resLSTM': 'Pure ResLSTM',\n",
    "    'pao_model': 'Pao Model',\n",
    "    'convnext': 'ConvNeXt',\n",
    "    'encdec_lstm': 'Encoder-Decoder LSTM'\n",
    "}\n",
    "\n",
    "color_dict = {\n",
    "    'unet': 'green',\n",
    "    'squeezeformer': 'purple',\n",
    "    'pure_resLSTM': 'blue',\n",
    "    'pao_model': 'red',\n",
    "    'convnext': 'gold',\n",
    "    'encdec_lstm': 'orange',\n",
    "}\n",
    "\n",
    "color_dict_config = {\n",
    "    'standard': 'blue',\n",
    "    'conf_loss': 'cyan',\n",
    "    'diff_loss': 'red',\n",
    "    'multirep': 'orange',\n",
    "    'v6': 'green'\n",
    "}\n",
    "\n",
    "offline_var_settings = {\n",
    "    'DTPHYS': {'var_title': 'dT/dt', 'var_title_long': 'Heating', 'scaling': 1., 'unit': 'K/s', 'vmax': 5e-7, 'vmin': -5e-7, 'var_index':0},\n",
    "    'DQ1PHYS': {'var_title': 'dQv/dt', 'var_title_long': 'Moistening', 'scaling': 1e3, 'unit': 'g/kg/s', 'vmax': 1e-6, 'vmin': -1e-6, 'var_index':60},\n",
    "    'DQ2PHYS': {'var_title': 'dQl/dt', 'var_title_long': 'Liquid Tendency', 'scaling': 1e6, 'unit': 'mg/kg/s', 'vmax': 1e-3, 'vmin': -1e-3, 'var_index':120},\n",
    "    'DQ3PHYS': {'var_title': 'dQi/dt', 'var_title_long': 'Ice Tendency', 'scaling': 1e6, 'unit': 'mg/kg/s', 'vmax': 1e-3, 'vmin': -1e-3, 'var_index':180},\n",
    "    'DUPHYS': {'var_title': 'dU/dt', 'var_title_long': 'Zonal Wind Tendency', 'scaling': 1., 'unit': 'm/s/s', 'vmax': 5e-7, 'vmin': -5e-7, 'var_index':240},\n",
    "    'DVPHYS': {'var_title': 'dV/dt', 'var_title_long': 'Meridional Wind Tendency', 'scaling': 1., 'unit': 'm/s/s', 'vmax': 5e-7, 'vmin': -5e-7, 'var_index':300}\n",
    "}\n",
    "\n",
    "online_var_settings = {\n",
    "    'T': {'var_title': 'Temperature', 'scaling': 1.0, 'unit': 'K', 'vmax': 5, 'vmin': -5},\n",
    "    'Q': {'var_title': 'Specific Humidity', 'scaling': 1000.0, 'unit': 'g/kg', 'vmax': 1, 'vmin': -1},\n",
    "    'U': {'var_title': 'Zonal Wind', 'scaling': 1.0, 'unit': 'm/s', 'vmax': 4, 'vmin': -4},\n",
    "    'V': {'var_title': 'Meridional Wind', 'scaling': 1.0, 'unit': 'm/s', 'vmax': 4, 'vmin': -4},\n",
    "    'CLDLIQ': {'var_title': 'Liquid Cloud', 'scaling': 1e6, 'unit': 'mg/kg', 'vmax': 40, 'vmin': -40},\n",
    "    'CLDICE': {'var_title': 'Ice Cloud', 'scaling': 1e6, 'unit': 'mg/kg', 'vmax': 5, 'vmin': -5},\n",
    "    'TOTCLD': {'var_title': 'Total Cloud', 'scaling': 1e6, 'unit': 'mg/kg', 'vmax': 40, 'vmin': -40},\n",
    "    'DTPHYS': {'var_title': 'Heating Tendency', 'scaling': 1., 'unit': 'K/s', 'vmax': 1.5e-5, 'vmin': -1.5e-5},\n",
    "    'DQ1PHYS': {'var_title': 'Moistening Tendency', 'scaling': 1e3, 'unit': 'g/kg/s', 'vmax': 1.2e-5, 'vmin': -1.2e-5},\n",
    "    'DQ2PHYS': {'var_title': 'Liquid Tendency', 'scaling': 1e6, 'unit': 'mg/kg/s', 'vmax': 0.0015, 'vmin': -0.0015},\n",
    "    'DQ3PHYS': {'var_title': 'Ice Tendency', 'scaling': 1e6, 'unit': 'mg/kg/s', 'vmax': 0.0015, 'vmin': -0.0015},\n",
    "    'DQnPHYS': {'var_title': 'Liquid + Ice Tendency', 'scaling': 1e6, 'unit': 'mg/kg/s', 'vmax': .0015, 'vmin': -.0015},\n",
    "    'DUPHYS': {'var_title': 'Zonal Wind Tendency', 'scaling': 1., 'unit': 'm/s\u00b2', 'vmax': 2.2e-6, 'vmin': -2.2e-6}\n",
    "}\n",
    "\n",
    "online_paths = {\n",
    "    'standard': '/pscratch/sd/j/jerrylin/hugging/E3SM-MMF_ne4/online_runs/climsim3_ensembles_good/standard/five_year_runs/',\n",
    "    'conf_loss': '/pscratch/sd/j/jerrylin/hugging/E3SM-MMF_ne4/online_runs/climsim3_ensembles_good/conf/five_year_runs/',\n",
    "    'diff_loss': '/pscratch/sd/j/jerrylin/hugging/E3SM-MMF_ne4/online_runs/climsim3_ensembles_good/diff/five_year_runs/',\n",
    "    'multirep': '/pscratch/sd/j/jerrylin/hugging/E3SM-MMF_ne4/online_runs/climsim3_ensembles_good/multirep/five_year_runs/',\n",
    "    'v6': '/pscratch/sd/j/jerrylin/hugging/E3SM-MMF_ne4/online_runs/climsim3_ensembles_good/v6/five_year_runs/'\n",
    "}\n",
    "\n",
    "seeds = ['seed_7', 'seed_43', 'seed_1024']\n",
    "seed_numbers = [7, 43, 1024]\n",
    "\n",
    "climsim3_figures_save_path_offline = '/global/cfs/cdirs/m4334/jerry/climsim3_figures/offline'\n",
    "climsim3_figures_save_path_online = '/global/cfs/cdirs/m4334/jerry/climsim3_figures/online'\n",
    "\n",
    "sypd_standard = [\n",
    "    17.97901035,\n",
    "    17.97901035,\n",
    "    18.05589744,\n",
    "    18.90966668,\n",
    "    19.03178614,\n",
    "    18.65975565,\n",
    "    17.80983045,\n",
    "    18.08638973,\n",
    "    17.93128756,\n",
    "    21.78946853,\n",
    "    21.9847479,\n",
    "    22.20038272,\n",
    "    25.36398855,\n",
    "    25.19805864,\n",
    "    25.19227595,\n",
    "    23.54557187,\n",
    "    23.82794497,\n",
    "    23.447502\n",
    "]\n",
    "\n",
    "sypd_conf_loss = [\n",
    "    17.50453936,\n",
    "    17.29971515,\n",
    "    17.44196107,\n",
    "    18.20260208,\n",
    "    18.19053688,\n",
    "    18.04921777,\n",
    "    16.88591639,\n",
    "    17.06639861,\n",
    "    17.10229289,\n",
    "    20.55525559,\n",
    "    20.63385549,\n",
    "    20.42521955,\n",
    "    23.65465549,\n",
    "    23.3813296,\n",
    "    23.25625602,\n",
    "    22.31773163,\n",
    "    22.25777422,\n",
    "    21.88176458\n",
    "]\n",
    "\n",
    "sypd_diff_loss =[\n",
    "    16.97469344,\n",
    "    16.92105472,\n",
    "    17.16379509,\n",
    "    18.99145235,\n",
    "    19.24026684,\n",
    "    18.69869139,\n",
    "    17.75509967,\n",
    "    16.87358759,\n",
    "    16.66731672,\n",
    "    20.77602886,\n",
    "    19.70212994,\n",
    "    19.22005471,\n",
    "    21.00260056,\n",
    "    25.47730606,\n",
    "    25.47730606,\n",
    "    24.0893883,\n",
    "    23.99985625,\n",
    "    23.78792837\n",
    "]\n",
    "\n",
    "sypd_multirep = [\n",
    "    18.33255552,\n",
    "    18.35861568,\n",
    "    18.3448099,\n",
    "    19.00295884,\n",
    "    16.93296157,\n",
    "    18.19204416,\n",
    "    17.23723679,\n",
    "    17.27385405,\n",
    "    17.27657263,\n",
    "    18.10913991,\n",
    "    19.86397164,\n",
    "    21.35810934,\n",
    "    23.51060144,\n",
    "    23.60014809,\n",
    "    24.52549157,\n",
    "    23.19360711,\n",
    "    23.43123639,\n",
    "    23.23164752\n",
    "]\n",
    "\n",
    "sypd_v6 = [\n",
    "    18.21284028,\n",
    "    18.31251632,\n",
    "    18.41758393,\n",
    "    6.894533848,\n",
    "    8.95130655,\n",
    "    7.890410959,\n",
    "    17.84446786,\n",
    "    17.79133537,\n",
    "    17.73373234,\n",
    "    21.39020294,\n",
    "    17.90628317,\n",
    "    21.40600448,\n",
    "    24.47883654,\n",
    "    24.13656852,\n",
    "    24.3122588,\n",
    "    23.34100196,\n",
    "    23.5582043,\n",
    "    23.5169076\n",
    "]\n",
    "\n",
    "pc_standard = [\n",
    "    12975373,\n",
    "    12975373,\n",
    "    12975373,\n",
    "    44785225,\n",
    "    44785225,\n",
    "    44785225,\n",
    "    15395341,\n",
    "    15395341,\n",
    "    15395341,\n",
    "    18876133,\n",
    "    18876133,\n",
    "    18876133,\n",
    "    26805429,\n",
    "    26805429,\n",
    "    26805429,\n",
    "    18582976,\n",
    "    18582976,\n",
    "    18582976\n",
    "]\n",
    "\n",
    "pc_conf_loss = [\n",
    "    12980634,\n",
    "    12980634,\n",
    "    12980634,\n",
    "    44811862,\n",
    "    44811862,\n",
    "    44811862,\n",
    "    15402010,\n",
    "    15402010,\n",
    "    15402010,\n",
    "    25407346,\n",
    "    25407346,\n",
    "    25407346,\n",
    "    26839242,\n",
    "    26839242,\n",
    "    26839242,\n",
    "    20723124,\n",
    "    20723124,\n",
    "    20723124\n",
    "]\n",
    "\n",
    "pc_diff_loss = [\n",
    "    12975373,\n",
    "    12975373,\n",
    "    12975373,\n",
    "    44785225,\n",
    "    44785225,\n",
    "    44785225,\n",
    "    15395341,\n",
    "    15395341,\n",
    "    15395341,\n",
    "    18876133,\n",
    "    18876133,\n",
    "    18876133,\n",
    "    26805429,\n",
    "    26805429,\n",
    "    26805429,\n",
    "    18582976,\n",
    "    18582976,\n",
    "    18582976\n",
    "]\n",
    "\n",
    "pc_multirep = [\n",
    "    12981517,\n",
    "    12981517,\n",
    "    12981517,\n",
    "    44791369,\n",
    "    44791369,\n",
    "    44791369,\n",
    "    15428109,\n",
    "    15428109,\n",
    "    15428109,\n",
    "    18880613,\n",
    "    18880613,\n",
    "    18880613,\n",
    "    26811573,\n",
    "    26811573,\n",
    "    26811573,\n",
    "    21004960,\n",
    "    21004960,\n",
    "    21004960\n",
    "]\n",
    "\n",
    "pc_v6 = [\n",
    "    12981517,\n",
    "    12981517,\n",
    "    12981517,\n",
    "    44791369,\n",
    "    44791369,\n",
    "    44791369,\n",
    "    15428109,\n",
    "    15428109,\n",
    "    15428109,\n",
    "    18880373,\n",
    "    18880373,\n",
    "    18880373,\n",
    "    26811573,\n",
    "    26811573,\n",
    "    26811573,\n",
    "    21004960,\n",
    "    21004960,\n",
    "    21004960\n",
    "]\n",
    "\n",
    "tt_standard = [\n",
    "    5.272,\n",
    "    5.895,\n",
    "    5.902,\n",
    "    32.986,\n",
    "    32.867,\n",
    "    33,\n",
    "    9.863,\n",
    "    8.708,\n",
    "    8.733,\n",
    "    8.106,\n",
    "    8.108,\n",
    "    8.141,\n",
    "    13.254,\n",
    "    13.253,\n",
    "    12.297,\n",
    "    5.352,\n",
    "    5.425,\n",
    "    5.378\n",
    "]\n",
    "\n",
    "tt_conf_loss = [\n",
    "    5.988,\n",
    "    5.989,\n",
    "    5.986,\n",
    "    33.0425,\n",
    "    33.012,\n",
    "    32.976,\n",
    "    8.719,\n",
    "    8.698,\n",
    "    8.69,\n",
    "    8.476,\n",
    "    8.442,\n",
    "    8.452,\n",
    "    13.387,\n",
    "    13.41,\n",
    "    13.405,\n",
    "    5.439,\n",
    "    5.418,\n",
    "    5.372\n",
    "]\n",
    "\n",
    "tt_diff_loss = [\n",
    "    5.949,\n",
    "    5.955,\n",
    "    5.933,\n",
    "    32.898,\n",
    "    32.817,\n",
    "    32.962,\n",
    "    8.031,\n",
    "    8.034,\n",
    "    8.039,\n",
    "    8.122,\n",
    "    7.545,\n",
    "    8.144,\n",
    "    12.309,\n",
    "    13.017,\n",
    "    13.033,\n",
    "    5.485,\n",
    "    5.453,\n",
    "    5.41\n",
    "]\n",
    "\n",
    "tt_multirep = [\n",
    "    5.935,\n",
    "    5.939,\n",
    "    5.94,\n",
    "    32.859,\n",
    "    32.873,\n",
    "    34.003,\n",
    "    8.714,\n",
    "    8.712,\n",
    "    8.716,\n",
    "    7.708,\n",
    "    8.361,\n",
    "    8.373,\n",
    "    12.358,\n",
    "    12.423,\n",
    "    13.238,\n",
    "    5.597,\n",
    "    5.589,\n",
    "    5.662\n",
    "]\n",
    "\n",
    "tt_v6 = [\n",
    "    6.285,\n",
    "    6.317,\n",
    "    6.291,\n",
    "    34.599,\n",
    "    32.981,\n",
    "    33.007,\n",
    "    8.809,\n",
    "    8.208,\n",
    "    8.753,\n",
    "    8.458,\n",
    "    8.42,\n",
    "    8.488,\n",
    "    13.368,\n",
    "    13.363,\n",
    "    13.16,\n",
    "    6.374,\n",
    "    6.42,\n",
    "    6.342\n",
    "]\n",
    "\n",
    "standard_sypd_dict = {}\n",
    "conf_loss_sypd_dict = {}\n",
    "diff_loss_sypd_dict = {}\n",
    "multirep_sypd_dict = {}\n",
    "v6_sypd_dict = {}\n",
    "\n",
    "standard_pc_dict = {}\n",
    "conf_loss_pc_dict = {}\n",
    "diff_loss_pc_dict = {}\n",
    "multirep_pc_dict = {}\n",
    "v6_pc_dict = {}\n",
    "\n",
    "standard_tt_dict = {}\n",
    "conf_loss_tt_dict = {}\n",
    "diff_loss_tt_dict = {}\n",
    "multirep_tt_dict = {}\n",
    "v6_tt_dict = {}\n",
    "\n",
    "i = 0\n",
    "for model_name in model_names.keys():\n",
    "    for seed_number in seed_numbers:\n",
    "        standard_sypd_dict[f\"{model_name}_{seed_number}\"] = sypd_standard[i]\n",
    "        conf_loss_sypd_dict[f\"{model_name}_{seed_number}\"] = sypd_conf_loss[i]\n",
    "        diff_loss_sypd_dict[f\"{model_name}_{seed_number}\"] = sypd_diff_loss[i]\n",
    "        multirep_sypd_dict[f\"{model_name}_{seed_number}\"] = sypd_multirep[i]\n",
    "        v6_sypd_dict[f\"{model_name}_{seed_number}\"] = sypd_v6[i]\n",
    "        standard_pc_dict[f\"{model_name}_{seed_number}\"] = pc_standard[i]\n",
    "        conf_loss_pc_dict[f\"{model_name}_{seed_number}\"] = pc_conf_loss[i]\n",
    "        diff_loss_pc_dict[f\"{model_name}_{seed_number}\"] = pc_diff_loss[i]\n",
    "        multirep_pc_dict[f\"{model_name}_{seed_number}\"] = pc_multirep[i]\n",
    "        v6_pc_dict[f\"{model_name}_{seed_number}\"] = pc_v6[i]\n",
    "        standard_tt_dict[f\"{model_name}_{seed_number}\"] = tt_standard[i]\n",
    "        conf_loss_tt_dict[f\"{model_name}_{seed_number}\"] = tt_conf_loss[i]\n",
    "        diff_loss_tt_dict[f\"{model_name}_{seed_number}\"] = tt_diff_loss[i]\n",
    "        multirep_tt_dict[f\"{model_name}_{seed_number}\"] = tt_multirep[i]\n",
    "        v6_tt_dict[f\"{model_name}_{seed_number}\"] = tt_v6[i]\n",
    "        i += 1\n",
    "\n",
    "sypd_dict = {\n",
    "    'standard': standard_sypd_dict,\n",
    "    'conf_loss': conf_loss_sypd_dict,\n",
    "    'diff_loss': diff_loss_sypd_dict,\n",
    "    'multirep': multirep_sypd_dict,\n",
    "    'v6': v6_sypd_dict\n",
    "}\n",
    "pc_dict = {\n",
    "    'standard': standard_pc_dict,\n",
    "    'conf_loss': conf_loss_pc_dict,\n",
    "    'diff_loss': diff_loss_pc_dict,\n",
    "    'multirep': multirep_pc_dict,\n",
    "    'v6': v6_pc_dict\n",
    "}\n",
    "tt_dict = {\n",
    "    'standard': standard_tt_dict,\n",
    "    'conf_loss': conf_loss_tt_dict,\n",
    "    'diff_loss': diff_loss_tt_dict,\n",
    "    'multirep': multirep_tt_dict,\n",
    "    'v6': v6_tt_dict\n",
    "}\n",
    "\n",
    "def ls(data_path = \"\"):\n",
    "    return os.popen(\" \".join([\"ls\", data_path])).read().splitlines()\n",
    "\n",
    "def offline_area_time_mean_3d(arr):\n",
    "    arr_zonal_mean = data_v2_rh_mc.zonal_bin_weight_3d(arr)\n",
    "    arr_zonal_time_mean = arr_zonal_mean.mean(axis = 0)\n",
    "    arr_zonal_time_mean = xr.DataArray(arr_zonal_time_mean.T, dims = ['hybrid pressure (hPa)', 'latitude'], coords = {'hybrid pressure (hPa)':level, 'latitude': lat_bin_mids})\n",
    "    return arr_zonal_time_mean\n",
    "\n",
    "def online_area_time_mean_3d(ds, var):\n",
    "    arr = ds[var].values[1:,:,:]\n",
    "    arr_reshaped = np.transpose(arr, (0,2,1))\n",
    "    arr_zonal_mean = data_v2_rh_mc.zonal_bin_weight_3d(arr_reshaped)\n",
    "    arr_zonal_time_mean = arr_zonal_mean.mean(axis = 0)\n",
    "    arr_zonal_time_mean = xr.DataArray(arr_zonal_time_mean.T, dims = ['hybrid pressure (hPa)', 'latitude'], coords = {'hybrid pressure (hPa)':level, 'latitude': lat_bin_mids})\n",
    "    return arr_zonal_time_mean\n",
    "\n",
    "def area_mean(ds, var):\n",
    "    arr = ds[var].values\n",
    "    arr_reshaped = np.transpose(arr, (0,2,1))\n",
    "    arr_zonal_mean = data_v2_rh_mc.zonal_bin_weight_3d(arr_reshaped)\n",
    "    return arr_zonal_mean\n",
    "\n",
    "def zonal_diff(ds_sp, ds_nn, var):\n",
    "    diff_zonal_mean = (area_mean(ds_nn, var) - area_mean(ds_sp, var)).mean(axis = 0)\n",
    "    diff_zonal = xr.DataArray(diff_zonal_mean.T, dims = ['level', 'lat'], coords = {'level':level, 'lat': lat_bin_mids})\n",
    "    return diff_zonal\n",
    "\n",
    "def get_dp(ds):\n",
    "    ps = ds['PS']\n",
    "    p_interface = (ds['hyai'] * ds['P0'] + ds['hybi'] * ds['PS']).values\n",
    "    if p_interface.shape[0] == 61:\n",
    "        p_interface = np.swapaxes(p_interface, 0, 1)\n",
    "    dp = p_interface[:,1:61,:] - p_interface[:,0:60,:]\n",
    "    return dp\n",
    "\n",
    "def get_tcp_mean(ds, area_weight):\n",
    "    cld = ds['TOTCLD'].values\n",
    "    dp = get_dp(ds)\n",
    "    tcp = np.sum(cld*dp, axis = 1)/9.81\n",
    "    tcp_mean = np.average(tcp, weights = area_weight, axis = 1)\n",
    "    return tcp_mean\n",
    "\n",
    "def get_tcp_std(ds, area_weight):\n",
    "    cld = ds['TOTCLD'].values\n",
    "    dp = get_dp(ds)\n",
    "    tcp = np.sum(cld*dp, axis = 1)/9.81\n",
    "    tcp_mean = np.average(tcp, weights = area_weight, axis = 1)\n",
    "    squared_diff = (tcp - tcp_mean[:, None])**2\n",
    "    tcp_std = np.sqrt(np.average(squared_diff, weights = area_weight, axis = 1))\n",
    "    return tcp_std\n",
    "\n",
    "def read_mmf_online_data(num_years):\n",
    "    assert num_years <= 5 and num_years >= 1\n",
    "    years_regexp = '34567'[:num_years]\n",
    "    ds_mmf_1 = xr.open_mfdataset(f'/pscratch/sd/z/zeyuanhu/hu_etal2024_data_v2/data/h0/5year/mmf_ref/control_fullysp_jan_wmlio_r3.eam.h0.000[{years_regexp}]*.nc')\n",
    "    ds_mmf_2 = xr.open_mfdataset(f'/pscratch/sd/z/zeyuanhu/hu_etal2024_data_v2/data/h0/5year/mmf_b/control_fullysp_jan_wmlio_r3_b.eam.h0.000[{years_regexp}]*.nc')\n",
    "    ds_mmf_1['DQnPHYS'] = ds_mmf_1['DQ2PHYS'] + ds_mmf_1['DQ3PHYS']\n",
    "    ds_mmf_2['DQnPHYS'] = ds_mmf_2['DQ2PHYS'] + ds_mmf_2['DQ3PHYS']\n",
    "    ds_mmf_1['TOTCLD'] = ds_mmf_1['CLDICE'] + ds_mmf_1['CLDLIQ']\n",
    "    ds_mmf_2['TOTCLD'] = ds_mmf_2['CLDICE'] + ds_mmf_2['CLDLIQ']\n",
    "    ds_mmf_1['PRECT'] = ds_mmf_1['PRECC'] + ds_mmf_1['PRECL']\n",
    "    ds_mmf_2['PRECT'] = ds_mmf_2['PRECC'] + ds_mmf_2['PRECL']\n",
    "    return ds_mmf_1, ds_mmf_2\n",
    "\n",
    "def read_nn_online_data(config_name, model_name, seed, num_years):\n",
    "    assert num_years <= 5 and num_years >= 1\n",
    "    years_regexp = '34567'[:num_years]\n",
    "    if config_name == 'standard':\n",
    "        extract_path = os.path.join(online_paths[config_name], f'{model_name}_seed_{seed}', 'run', f'{model_name}_seed_{seed}.eam.h0.000[{years_regexp}]*.nc')\n",
    "    elif config_name == 'conf_loss':\n",
    "        extract_path = os.path.join(online_paths[config_name], f'{model_name}_conf_seed_{seed}', 'run', f'{model_name}_conf_seed_{seed}.eam.h0.000[{years_regexp}]*.nc')\n",
    "    elif config_name == 'diff_loss':\n",
    "        extract_path = os.path.join(online_paths[config_name], f'{model_name}_diff_seed_{seed}', 'run', f'{model_name}_diff_seed_{seed}.eam.h0.000[{years_regexp}]*.nc')\n",
    "    elif config_name == 'multirep':\n",
    "        extract_path = os.path.join(online_paths[config_name], f'{model_name}_multirep_seed_{seed}', 'run', f'{model_name}_multirep_seed_{seed}.eam.h0.000[{years_regexp}]*.nc')\n",
    "    elif config_name == 'v6':\n",
    "        extract_path = os.path.join(online_paths[config_name], f'{model_name}_v6_seed_{seed}', 'run', f'{model_name}_v6_seed_{seed}.eam.h0.000[{years_regexp}]*.nc')\n",
    "    if len(ls(extract_path)) == 0:\n",
    "        return None\n",
    "    ds_nn = xr.open_mfdataset(extract_path)\n",
    "    if len(ds_nn['time']) < 12 * num_years:\n",
    "        return None\n",
    "    ds_nn['DQnPHYS'] = ds_nn['DQ2PHYS'] + ds_nn['DQ3PHYS']\n",
    "    ds_nn['TOTCLD'] = ds_nn['CLDICE'] + ds_nn['CLDLIQ']\n",
    "    ds_nn['PRECT'] = ds_nn['PRECC'] + ds_nn['PRECL']\n",
    "    return ds_nn\n",
    "\n",
    "def read_nn_online_precip_data(config_name, model_name, seed, num_years):\n",
    "    assert num_years <= 5 and num_years >= 1\n",
    "    years_regexp = '34567'[:num_years]\n",
    "    if config_name == 'standard':\n",
    "        extract_path = os.path.join(online_paths[config_name], f'{model_name}_seed_{seed}', 'run', 'precip_dir', 'combined_precip.nc')\n",
    "    elif config_name == 'conf_loss':\n",
    "        extract_path = os.path.join(online_paths[config_name], f'{model_name}_conf_seed_{seed}', 'run', 'precip_dir', 'combined_precip.nc')\n",
    "    elif config_name == 'diff_loss':\n",
    "        extract_path = os.path.join(online_paths[config_name], f'{model_name}_diff_seed_{seed}', 'run', 'precip_dir', 'combined_precip.nc')\n",
    "    elif config_name == 'multirep':\n",
    "        extract_path = os.path.join(online_paths[config_name], f'{model_name}_multirep_seed_{seed}', 'run', 'precip_dir', 'combined_precip.nc')\n",
    "    elif config_name == 'v6':\n",
    "        extract_path = os.path.join(online_paths[config_name], f'{model_name}_v6_seed_{seed}', 'run', 'precip_dir', 'combined_precip.nc')\n",
    "    if len(ls(extract_path)) == 0:\n",
    "        return None\n",
    "    ds_nn = xr.open_dataset(extract_path)\n",
    "    if len(ds_nn['time']) < 365 * 24 * num_years:\n",
    "        return None\n",
    "    return ds_nn['PRECT']\n",
    "\n",
    "def get_pressure_area_weights(ds, surface_type = None):\n",
    "    ds_dp = get_dp(ds)\n",
    "    ds_total_weight = ds_dp * area_weight[None, None, :]\n",
    "    ds_total_weight = ds_total_weight.mean(axis = 0)\n",
    "    ds_total_weight = ds_total_weight/ds_total_weight.sum()\n",
    "    if surface_type is None:\n",
    "        return ds_total_weight\n",
    "    elif surface_type == 'land':\n",
    "        land_area = ds['LANDFRAC'].values * grid_area[None, :]\n",
    "        land_area_sums = np.array([[np.sum(land_area[t,:][data_v2_rh_mc.lat_bin_dict[lat_bin]]) for lat_bin in data_v2_rh_mc.lat_bin_dict.keys()] for t in range(land_area.shape[0])])\n",
    "        land_area_divs = np.stack([np.divide(1, land_area_sums[:, bin_index], where=~(land_area_sums[:, bin_index] == 0), out=np.zeros_like(land_area_sums[:, bin_index])) for bin_index in data_v2_rh_mc.lat_bin_indices], axis=1)\n",
    "        land_area_weighting = land_area * land_area_divs\n",
    "        return land_area_weighting\n",
    "    elif surface_type == 'ocean':\n",
    "        ocean_area = ds['OCNFRAC'].values * grid_area[None, :]\n",
    "        ocean_area_sums = np.array([[np.sum(ocean_area[t,:][data_v2_rh_mc.lat_bin_dict[lat_bin]]) for lat_bin in data_v2_rh_mc.lat_bin_dict.keys()] for t in range(ocean_area.shape[0])])\n",
    "        ocean_area_divs = np.stack([np.divide(1, ocean_area_sums[:, bin_index], where=~(ocean_area_sums[:, bin_index] == 0), out=np.zeros_like(ocean_area_sums[:, bin_index])) for bin_index in data_v2_rh_mc.lat_bin_indices], axis=1)\n",
    "        ocean_area_weighting = ocean_area * ocean_area_divs\n",
    "        return ocean_area_weighting\n",
    "    elif surface_type == 'ice':\n",
    "        ice_area = ds['ICEFRAC'].values * grid_area[None, :]\n",
    "        ice_area_sums = np.array([[np.sum(ice_area[t,:][data_v2_rh_mc.lat_bin_dict[lat_bin]]) for lat_bin in data_v2_rh_mc.lat_bin_dict.keys()] for t in range(ice_area.shape[0])])\n",
    "        ice_area_divs = np.stack([np.divide(1, ice_area_sums[:, bin_index], where=~(ice_area_sums[:, bin_index] == 0), out=np.zeros_like(ice_area_sums[:, bin_index])) for bin_index in data_v2_rh_mc.lat_bin_indices], axis=1)\n",
    "        ice_area_weighting = ice_area * ice_area_divs\n",
    "        return ice_area_weighting\n",
    "    else:\n",
    "        raise ValueError(\"Invalid surface type. Choose from 'land', 'ocean', or 'ice'.\")\n",
    "\n",
    "def get_offline_precip_area_weights(nn_preds, precc_index = 363):\n",
    "    nn_precc = nn_preds[:,:,precc_index] * 86400 * 1000\n",
    "    no_precip_mask = nn_precc[:,:] == 0\n",
    "    nn_active_precip = nn_precc[:,:][~no_precip_mask]\n",
    "    nn_active_precip_quantiles = np.quantile(nn_active_precip, [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n",
    "    active_precip_1_10_percentile_mask = (nn_precc[:,:] > 0) & (nn_precc[:,:] <= nn_active_precip_quantiles[0])\n",
    "    active_precip_10_20_percentile_mask = (nn_precc[:,:] > nn_active_precip_quantiles[0]) & (nn_precc[:,:] <= nn_active_precip_quantiles[1])\n",
    "    active_precip_20_30_percentile_mask = (nn_precc[:,:] > nn_active_precip_quantiles[1]) & (nn_precc[:,:] <= nn_active_precip_quantiles[2])\n",
    "    active_precip_30_40_percentile_mask = (nn_precc[:,:] > nn_active_precip_quantiles[2]) & (nn_precc[:,:] <= nn_active_precip_quantiles[3])\n",
    "    active_precip_40_50_percentile_mask = (nn_precc[:,:] > nn_active_precip_quantiles[3]) & (nn_precc[:,:] <= nn_active_precip_quantiles[4])\n",
    "    active_precip_50_60_percentile_mask = (nn_precc[:,:] > nn_active_precip_quantiles[4]) & (nn_precc[:,:] <= nn_active_precip_quantiles[5])\n",
    "    active_precip_60_70_percentile_mask = (nn_precc[:,:] > nn_active_precip_quantiles[5]) & (nn_precc[:,:] <= nn_active_precip_quantiles[6])\n",
    "    active_precip_70_80_percentile_mask = (nn_precc[:,:] > nn_active_precip_quantiles[6]) & (nn_precc[:,:] <= nn_active_precip_quantiles[7])\n",
    "    active_precip_80_90_percentile_mask = (nn_precc[:,:] > nn_active_precip_quantiles[7]) & (nn_precc[:,:] <= nn_active_precip_quantiles[8])\n",
    "    active_precip_90_100_percentile_mask = (nn_precc[:,:] > nn_active_precip_quantiles[8]) & (nn_precc[:,:] <= nn_active_precip_quantiles[9])\n",
    "    precip_area_dict = {\n",
    "        'no_precip': no_precip_mask * area_weight[None,:],\n",
    "        'active_precip_1_10_percentile': active_precip_1_10_percentile_mask * area_weight[None,:],\n",
    "        'active_precip_10_20_percentile': active_precip_10_20_percentile_mask * area_weight[None,:],\n",
    "        'active_precip_20_30_percentile': active_precip_20_30_percentile_mask * area_weight[None,:],\n",
    "        'active_precip_30_40_percentile': active_precip_30_40_percentile_mask * area_weight[None,:],\n",
    "        'active_precip_40_50_percentile': active_precip_40_50_percentile_mask * area_weight[None,:],\n",
    "        'active_precip_50_60_percentile': active_precip_50_60_percentile_mask * area_weight[None,:],\n",
    "        'active_precip_60_70_percentile': active_precip_60_70_percentile_mask * area_weight[None,:],\n",
    "        'active_precip_70_80_percentile': active_precip_70_80_percentile_mask * area_weight[None,:],\n",
    "        'active_precip_80_90_percentile': active_precip_80_90_percentile_mask * area_weight[None,:],\n",
    "        'active_precip_90_100_percentile': active_precip_90_100_percentile_mask * area_weight[None,:]\n",
    "    }\n",
    "    precip_area_divs = {key: np.divide(np.ones_like(precip_area_dict[key]), np.sum(precip_area_dict[key]), out = np.zeros_like(precip_area_dict[key]), where = (precip_area_dict[key] != 0)) for key in precip_area_dict.keys()}\n",
    "    for key in precip_area_dict.keys():\n",
    "        precip_area_dict[key] = (precip_area_dict[key] * precip_area_divs[key])[:,:,None]\n",
    "    return precip_area_dict\n",
    "\n",
    "precip_percentile_labels = {\n",
    "    'no_precip': 'No Precipitation',\n",
    "    'active_precip_1_10_percentile': '1-10th percentile',\n",
    "    'active_precip_10_20_percentile': '10-20th percentile',\n",
    "    'active_precip_20_30_percentile': '20-30th percentile',\n",
    "    'active_precip_30_40_percentile': '30-40th percentile',\n",
    "    'active_precip_40_50_percentile': '40-50th percentile',\n",
    "    'active_precip_50_60_percentile': '50-60th percentile',\n",
    "    'active_precip_60_70_percentile': '60-70th percentile',\n",
    "    'active_precip_70_80_percentile': '70-80th percentile',\n",
    "    'active_precip_80_90_percentile': '80-90th percentile',\n",
    "    'active_precip_90_100_percentile': '90-100th percentile'\n",
    "}\n",
    "\n",
    "standard_save_path = '/pscratch/sd/j/jerrylin/hugging/E3SM-MMF_ne4/preprocessing/v2_rh_mc/test_set/test_preds/standard/'\n",
    "conf_loss_save_path = '/pscratch/sd/j/jerrylin/hugging/E3SM-MMF_ne4/preprocessing/v2_rh_mc/test_set/test_preds/conf_loss/'\n",
    "diff_loss_save_path = '/pscratch/sd/j/jerrylin/hugging/E3SM-MMF_ne4/preprocessing/v2_rh_mc/test_set/test_preds/diff_loss/'\n",
    "multirep_save_path = '/pscratch/sd/j/jerrylin/hugging/E3SM-MMF_ne4/preprocessing/v2_rh_mc/test_set/test_preds/multirep/'\n",
    "v6_save_path = '/pscratch/sd/j/jerrylin/hugging/E3SM-MMF_ne4/preprocessing/v6/test_set/test_preds/'\n",
    "\n",
    "def load_seed_data(save_path, npz_file, seed_key):\n",
    "    with np.load(os.path.join(save_path, npz_file)) as data:\n",
    "        return data[seed_key]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d473d3",
   "metadata": {},
   "source": [
    "## Load offline preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0c326d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('loading standard preds')\n",
    "standard_preds = {\n",
    "    'unet': lambda seed_key: load_seed_data(standard_save_path, 'standard_unet_preds.npz', seed_key),\n",
    "    'squeezeformer': lambda seed_key: load_seed_data(standard_save_path, 'standard_squeezeformer_preds.npz', seed_key),\n",
    "    'pure_resLSTM': lambda seed_key: load_seed_data(standard_save_path, 'standard_pure_resLSTM_preds.npz', seed_key),\n",
    "    'pao_model': lambda seed_key: load_seed_data(standard_save_path, 'standard_pao_model_preds.npz', seed_key),\n",
    "    'convnext': lambda seed_key: load_seed_data(standard_save_path, 'standard_convnext_preds.npz', seed_key),\n",
    "    'encdec_lstm': lambda seed_key: load_seed_data(standard_save_path, 'standard_encdec_lstm_preds.npz', seed_key)\n",
    "}\n",
    "\n",
    "print('loading conf loss preds')\n",
    "conf_loss_preds = {\n",
    "    'unet': lambda seed_key: load_seed_data(conf_loss_save_path, 'conf_loss_unet_preds.npz', seed_key),\n",
    "    'squeezeformer': lambda seed_key: load_seed_data(conf_loss_save_path, 'conf_loss_squeezeformer_preds.npz', seed_key),\n",
    "    'pure_resLSTM': lambda seed_key: load_seed_data(conf_loss_save_path, 'conf_loss_pure_resLSTM_preds.npz', seed_key),\n",
    "    'pao_model': lambda seed_key: load_seed_data(conf_loss_save_path, 'conf_loss_pao_model_preds.npz', seed_key),\n",
    "    'convnext': lambda seed_key: load_seed_data(conf_loss_save_path, 'conf_loss_convnext_preds.npz', seed_key),\n",
    "    'encdec_lstm': lambda seed_key: load_seed_data(conf_loss_save_path, 'conf_loss_encdec_lstm_preds.npz', seed_key)\n",
    "}\n",
    "\n",
    "print('loading conf loss conf')\n",
    "conf_loss_conf = {\n",
    "    'unet': lambda seed_key: load_seed_data(conf_loss_save_path, 'conf_loss_unet_conf.npz', seed_key),\n",
    "    'squeezeformer': lambda seed_key: load_seed_data(conf_loss_save_path, 'conf_loss_squeezeformer_conf.npz', seed_key),\n",
    "    'pure_resLSTM': lambda seed_key: load_seed_data(conf_loss_save_path, 'conf_loss_pure_resLSTM_conf.npz', seed_key),\n",
    "    'pao_model': lambda seed_key: load_seed_data(conf_loss_save_path, 'conf_loss_pao_model_conf.npz', seed_key),\n",
    "    'convnext': lambda seed_key: load_seed_data(conf_loss_save_path, 'conf_loss_convnext_conf.npz', seed_key),\n",
    "    'encdec_lstm': lambda seed_key: load_seed_data(conf_loss_save_path, 'conf_loss_encdec_lstm_conf.npz', seed_key)\n",
    "}\n",
    "\n",
    "print('loading diff loss preds')\n",
    "diff_loss_preds = {\n",
    "    'unet': lambda seed_key: load_seed_data(diff_loss_save_path, 'diff_loss_unet_preds.npz', seed_key),\n",
    "    'squeezeformer': lambda seed_key: load_seed_data(diff_loss_save_path, 'diff_loss_squeezeformer_preds.npz', seed_key),\n",
    "    'pure_resLSTM': lambda seed_key: load_seed_data(diff_loss_save_path, 'diff_loss_pure_resLSTM_preds.npz', seed_key),\n",
    "    'pao_model': lambda seed_key: load_seed_data(diff_loss_save_path, 'diff_loss_pao_model_preds.npz', seed_key),\n",
    "    'convnext': lambda seed_key: load_seed_data(diff_loss_save_path, 'diff_loss_convnext_preds.npz', seed_key),\n",
    "    'encdec_lstm': lambda seed_key: load_seed_data(diff_loss_save_path, 'diff_loss_encdec_lstm_preds.npz', seed_key)\n",
    "}\n",
    "\n",
    "print('loading multirep preds')\n",
    "multirep_preds = {\n",
    "    'unet': lambda seed_key: load_seed_data(multirep_save_path, 'multirep_unet_preds.npz', seed_key),\n",
    "    'squeezeformer': lambda seed_key: load_seed_data(multirep_save_path, 'multirep_squeezeformer_preds.npz', seed_key),\n",
    "    'pure_resLSTM': lambda seed_key: load_seed_data(multirep_save_path, 'multirep_pure_resLSTM_preds.npz', seed_key),\n",
    "    'pao_model': lambda seed_key: load_seed_data(multirep_save_path, 'multirep_pao_model_preds.npz', seed_key),\n",
    "    'convnext': lambda seed_key: load_seed_data(multirep_save_path, 'multirep_convnext_preds.npz', seed_key),\n",
    "    'encdec_lstm': lambda seed_key: load_seed_data(multirep_save_path, 'multirep_encdec_lstm_preds.npz', seed_key)\n",
    "}\n",
    "\n",
    "print('loading v6 preds')\n",
    "v6_preds = {\n",
    "    'unet': lambda seed_key: load_seed_data(v6_save_path, 'v6_unet_preds.npz', seed_key),\n",
    "    'squeezeformer': lambda seed_key: load_seed_data(v6_save_path, 'v6_squeezeformer_preds.npz', seed_key),\n",
    "    'pure_resLSTM': lambda seed_key: load_seed_data(v6_save_path, 'v6_pure_resLSTM_preds.npz', seed_key),\n",
    "    'pao_model': lambda seed_key: load_seed_data(v6_save_path, 'v6_pao_model_preds.npz', seed_key),\n",
    "    'convnext': lambda seed_key: load_seed_data(v6_save_path, 'v6_convnext_preds.npz', seed_key),\n",
    "    'encdec_lstm': lambda seed_key: load_seed_data(v6_save_path, 'v6_encdec_lstm_preds.npz', seed_key)\n",
    "}\n",
    "\n",
    "config_preds = {\n",
    "    'standard': standard_preds,\n",
    "    'conf_loss': conf_loss_preds,\n",
    "    'diff_loss': diff_loss_preds,\n",
    "    'multirep': multirep_preds,\n",
    "    'v6': v6_preds\n",
    "}\n",
    "\n",
    "print('loading Kaggle preds')\n",
    "kaggle_check_path = '/pscratch/sd/j/jerrylin/kaggle_check'\n",
    "\n",
    "greysnow = np.load(os.path.join(kaggle_check_path, 'prds.npy'))\n",
    "greysnow = greysnow.reshape(-1, data_v2_rh_mc.num_latlon, 368)\n",
    "\n",
    "adam = pd.read_parquet(os.path.join(kaggle_check_path, 'final_blend_v10.parquet'))\n",
    "adam = adam.iloc[:,1:].values\n",
    "adam = adam.reshape(-1, data_v2_rh_mc.num_latlon, 368)\n",
    "\n",
    "print(greysnow.shape, adam.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3691ee",
   "metadata": {},
   "source": [
    "## Load offline R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e5242e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(standard_save_path, \"standard_unet_r2.pkl\"), \"rb\") as f:\n",
    "    standard_unet_r2 = pickle.load(f)\n",
    "with open(os.path.join(standard_save_path, \"standard_squeezeformer_r2.pkl\"), \"rb\") as f:\n",
    "    standard_squeezeformer_r2 = pickle.load(f)\n",
    "with open(os.path.join(standard_save_path, \"standard_pure_resLSTM_r2.pkl\"), \"rb\") as f:\n",
    "    standard_pure_resLSTM_r2 = pickle.load(f)\n",
    "with open(os.path.join(standard_save_path, \"standard_pao_model_r2.pkl\"), \"rb\") as f:\n",
    "    standard_pao_model_r2 = pickle.load(f)\n",
    "with open(os.path.join(standard_save_path, \"standard_convnext_r2.pkl\"), \"rb\") as f:\n",
    "    standard_convnext_r2 = pickle.load(f)\n",
    "with open(os.path.join(standard_save_path, \"standard_encdec_lstm_r2.pkl\"), \"rb\") as f:\n",
    "    standard_encdec_lstm_r2 = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(conf_loss_save_path, \"conf_loss_unet_r2.pkl\"), \"rb\") as f:\n",
    "    conf_loss_unet_r2 = pickle.load(f)\n",
    "with open(os.path.join(conf_loss_save_path, \"conf_loss_squeezeformer_r2.pkl\"), \"rb\") as f:\n",
    "    conf_loss_squeezeformer_r2 = pickle.load(f)\n",
    "with open(os.path.join(conf_loss_save_path, \"conf_loss_pure_resLSTM_r2.pkl\"), \"rb\") as f:\n",
    "    conf_loss_pure_resLSTM_r2 = pickle.load(f)\n",
    "with open(os.path.join(conf_loss_save_path, \"conf_loss_pao_model_r2.pkl\"), \"rb\") as f:\n",
    "    conf_loss_pao_model_r2 = pickle.load(f)\n",
    "with open(os.path.join(conf_loss_save_path, \"conf_loss_convnext_r2.pkl\"), \"rb\") as f:\n",
    "    conf_loss_convnext_r2 = pickle.load(f)\n",
    "with open(os.path.join(conf_loss_save_path, \"conf_loss_encdec_lstm_r2.pkl\"), \"rb\") as f:\n",
    "    conf_loss_encdec_lstm_r2 = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(diff_loss_save_path, \"diff_loss_unet_r2.pkl\"), \"rb\") as f:\n",
    "    diff_loss_unet_r2 = pickle.load(f)\n",
    "with open(os.path.join(diff_loss_save_path, \"diff_loss_squeezeformer_r2.pkl\"), \"rb\") as f:\n",
    "    diff_loss_squeezeformer_r2 = pickle.load(f)\n",
    "with open(os.path.join(diff_loss_save_path, \"diff_loss_pure_resLSTM_r2.pkl\"), \"rb\") as f:\n",
    "    diff_loss_pure_resLSTM_r2 = pickle.load(f)\n",
    "with open(os.path.join(diff_loss_save_path, \"diff_loss_pao_model_r2.pkl\"), \"rb\") as f:\n",
    "    diff_loss_pao_model_r2 = pickle.load(f)\n",
    "with open(os.path.join(diff_loss_save_path, \"diff_loss_convnext_r2.pkl\"), \"rb\") as f:\n",
    "    diff_loss_convnext_r2 = pickle.load(f)\n",
    "with open(os.path.join(diff_loss_save_path, \"diff_loss_encdec_lstm_r2.pkl\"), \"rb\") as f:\n",
    "    diff_loss_encdec_lstm_r2 = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(multirep_save_path, \"multirep_unet_r2.pkl\"), \"rb\") as f:\n",
    "    multirep_unet_r2 = pickle.load(f)\n",
    "with open(os.path.join(multirep_save_path, \"multirep_squeezeformer_r2.pkl\"), \"rb\") as f:\n",
    "    multirep_squeezeformer_r2 = pickle.load(f)\n",
    "with open(os.path.join(multirep_save_path, \"multirep_pure_resLSTM_r2.pkl\"), \"rb\") as f:\n",
    "    multirep_pure_resLSTM_r2 = pickle.load(f)\n",
    "with open(os.path.join(multirep_save_path, \"multirep_pao_model_r2.pkl\"), \"rb\") as f:\n",
    "    multirep_pao_model_r2 = pickle.load(f)\n",
    "with open(os.path.join(multirep_save_path, \"multirep_convnext_r2.pkl\"), \"rb\") as f:\n",
    "    multirep_convnext_r2 = pickle.load(f)\n",
    "with open(os.path.join(multirep_save_path, \"multirep_encdec_lstm_r2.pkl\"), \"rb\") as f:\n",
    "    multirep_encdec_lstm_r2 = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(v6_save_path, \"v6_unet_r2.pkl\"), \"rb\") as f:\n",
    "    v6_unet_r2 = pickle.load(f)\n",
    "with open(os.path.join(v6_save_path, \"v6_squeezeformer_r2.pkl\"), \"rb\") as f:\n",
    "    v6_squeezeformer_r2 = pickle.load(f)\n",
    "with open(os.path.join(v6_save_path, \"v6_pure_resLSTM_r2.pkl\"), \"rb\") as f:\n",
    "    v6_pure_resLSTM_r2 = pickle.load(f)\n",
    "with open(os.path.join(v6_save_path, \"v6_pao_model_r2.pkl\"), \"rb\") as f:\n",
    "    v6_pao_model_r2 = pickle.load(f)\n",
    "with open(os.path.join(v6_save_path, \"v6_convnext_r2.pkl\"), \"rb\") as f:\n",
    "    v6_convnext_r2 = pickle.load(f)\n",
    "with open(os.path.join(v6_save_path, \"v6_encdec_lstm_r2.pkl\"), \"rb\") as f:\n",
    "    v6_encdec_lstm_r2 = pickle.load(f)\n",
    "\n",
    "standard_r2_dict = {\n",
    "    'unet': standard_unet_r2,\n",
    "    'squeezeformer': standard_squeezeformer_r2,\n",
    "    'pure_resLSTM': standard_pure_resLSTM_r2,\n",
    "    'pao_model': standard_pao_model_r2,\n",
    "    'convnext': standard_convnext_r2,\n",
    "    'encdec_lstm': standard_encdec_lstm_r2\n",
    "}\n",
    "\n",
    "conf_loss_r2_dict = {\n",
    "    'unet': conf_loss_unet_r2,\n",
    "    'squeezeformer': conf_loss_squeezeformer_r2,\n",
    "    'pure_resLSTM': conf_loss_pure_resLSTM_r2,\n",
    "    'pao_model': conf_loss_pao_model_r2,\n",
    "    'convnext': conf_loss_convnext_r2,\n",
    "    'encdec_lstm': conf_loss_encdec_lstm_r2\n",
    "}\n",
    "\n",
    "diff_loss_r2_dict = {\n",
    "    'unet': diff_loss_unet_r2,\n",
    "    'squeezeformer': diff_loss_squeezeformer_r2,\n",
    "    'pure_resLSTM': diff_loss_pure_resLSTM_r2,\n",
    "    'pao_model': diff_loss_pao_model_r2,\n",
    "    'convnext': diff_loss_convnext_r2,\n",
    "    'encdec_lstm': diff_loss_encdec_lstm_r2\n",
    "}\n",
    "\n",
    "multirep_r2_dict = {\n",
    "    'unet': multirep_unet_r2,\n",
    "    'squeezeformer': multirep_squeezeformer_r2,\n",
    "    'pure_resLSTM': multirep_pure_resLSTM_r2,\n",
    "    'pao_model': multirep_pao_model_r2,\n",
    "    'convnext': multirep_convnext_r2,\n",
    "    'encdec_lstm': multirep_encdec_lstm_r2\n",
    "}\n",
    "\n",
    "v6_r2_dict = {\n",
    "    'unet': v6_unet_r2,\n",
    "    'squeezeformer': v6_squeezeformer_r2,\n",
    "    'pure_resLSTM': v6_pure_resLSTM_r2,\n",
    "    'pao_model': v6_pao_model_r2,\n",
    "    'convnext': v6_convnext_r2,\n",
    "    'encdec_lstm': v6_encdec_lstm_r2\n",
    "}\n",
    "\n",
    "huetal2025_r2_path = '/pscratch/sd/z/zeyuanhu/hu_etal2024_data_v2/data/r2'\n",
    "huetal2025_r2_model0 = np.load(os.path.join(huetal2025_r2_path, 'r2-v2rh_mlp_nonaggressive_cliprh_huber_rop_3l_lr1em3_r2.npy'))\n",
    "huetal2025_r2_model1 = np.load(os.path.join(huetal2025_r2_path, 'r2-v2rh_unet_nonaggressive_cliprh_huber_rop2.npy'))\n",
    "huetal2025_r2_model2 = np.load(os.path.join(huetal2025_r2_path, 'r2-v4plus_unet_nonaggressive_cliprh_huber.npy'))\n",
    "huetal2025_r2_model3 = np.load(os.path.join(huetal2025_r2_path, 'r2-v5_unet_nonaggressive_cliprh_huber_rop2_r2.npy'))\n",
    "huetal2025_r2 = np.stack([huetal2025_r2_model0, huetal2025_r2_model1, huetal2025_r2_model2, huetal2025_r2_model3], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c6b3a7",
   "metadata": {},
   "source": [
    "# Load online runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccff01e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rmse(ds1, ds2, total_weight, var, num_years):\n",
    "    months = np.arange(1, num_years * 12 + 1)\n",
    "    # Initialize the RMSE array with NaN values\n",
    "    rmse_per_month = np.full(len(months), np.nan)\n",
    "    if not ds1:\n",
    "        return rmse_per_month\n",
    "\n",
    "    total_weight = get_dp(ds2) * ds2['area'].values[:,None,:]\n",
    "    # Determine the number of months in ds1\n",
    "    num_months = ds1[var].shape[0]\n",
    "    \n",
    "    # Slice total_weight to match the number of months in ds1\n",
    "    total_weight_sliced = total_weight[:num_months, :, :]\n",
    "    \n",
    "    # Compute RMSE for existing months\n",
    "    squared_diff = (ds1[var] - ds2[var]) ** 2\n",
    "    weighted_squared_diff = squared_diff * total_weight_sliced\n",
    "    weighted_sum = weighted_squared_diff.sum(axis=(1, 2))\n",
    "    total_weight_sum = total_weight_sliced.sum(axis=(1, 2))\n",
    "    weighted_mean_squared_diff = weighted_sum / total_weight_sum\n",
    "    rmse_existing_months = np.sqrt(weighted_mean_squared_diff)\n",
    "    \n",
    "    # Fill in the RMSE array with the computed values\n",
    "    rmse_per_month[:num_months] = rmse_existing_months.values\n",
    "    rmse_per_month = rmse_per_month * online_var_settings[var]['scaling']\n",
    "    return rmse_per_month\n",
    "\n",
    "ds_mmf_1_5_year, ds_mmf_2_5_year = read_mmf_online_data(num_years = 5)\n",
    "ds_mmf_1_4_year, ds_mmf_2_4_year = read_mmf_online_data(num_years = 4)\n",
    "mmf_1_total_weight_5_year = get_pressure_area_weights(ds_mmf_1_5_year)\n",
    "mmf_1_total_weight_4_year = get_pressure_area_weights(ds_mmf_1_4_year)\n",
    "\n",
    "online_nn_data_save_path = '/global/cfs/cdirs/m4334/jerry/climsim3_figures/online/online_nn_data'\n",
    "\n",
    "file_name = \"ds_nn_standard_5_year.pkl\"\n",
    "with open(os.path.join(online_nn_data_save_path, file_name), \"rb\") as file:\n",
    "    ds_nn_standard_5_year = pickle.load(file)\n",
    "\n",
    "file_name = \"ds_nn_conf_loss_5_year.pkl\"\n",
    "with open(os.path.join(online_nn_data_save_path, file_name), \"rb\") as file:\n",
    "    ds_nn_conf_loss_5_year = pickle.load(file)\n",
    "\n",
    "file_name = \"ds_nn_diff_loss_5_year.pkl\"\n",
    "with open(os.path.join(online_nn_data_save_path, file_name), \"rb\") as file:\n",
    "    ds_nn_diff_loss_5_year = pickle.load(file)\n",
    "\n",
    "file_name = \"ds_nn_multirep_5_year.pkl\"\n",
    "with open(os.path.join(online_nn_data_save_path, file_name), \"rb\") as file:\n",
    "    ds_nn_multirep_5_year = pickle.load(file)\n",
    "\n",
    "file_name = \"ds_nn_v6_5_year.pkl\"\n",
    "with open(os.path.join(online_nn_data_save_path, file_name), \"rb\") as file:\n",
    "    ds_nn_v6_5_year = pickle.load(file)\n",
    "\n",
    "file_name = \"ds_nn_standard_4_year.pkl\"\n",
    "with open(os.path.join(online_nn_data_save_path, file_name), \"rb\") as file:\n",
    "    ds_nn_standard_4_year = pickle.load(file)\n",
    "\n",
    "file_name = \"ds_nn_conf_loss_4_year.pkl\"\n",
    "with open(os.path.join(online_nn_data_save_path, file_name), \"rb\") as file:\n",
    "    ds_nn_conf_loss_4_year = pickle.load(file)\n",
    "\n",
    "file_name = \"ds_nn_diff_loss_4_year.pkl\"\n",
    "with open(os.path.join(online_nn_data_save_path, file_name), \"rb\") as file:\n",
    "    ds_nn_diff_loss_4_year = pickle.load(file)\n",
    "\n",
    "file_name = \"ds_nn_multirep_4_year.pkl\"\n",
    "with open(os.path.join(online_nn_data_save_path, file_name), \"rb\") as file:\n",
    "    ds_nn_multirep_4_year = pickle.load(file)\n",
    "\n",
    "file_name = \"ds_nn_v6_4_year.pkl\"\n",
    "with open(os.path.join(online_nn_data_save_path, file_name), \"rb\") as file:\n",
    "    ds_nn_v6_4_year = pickle.load(file)\n",
    "\n",
    "online_rmse_growth_save_path = '/global/cfs/cdirs/m4334/jerry/climsim3_figures/online/online_rmse_growth'\n",
    "\n",
    "file_name = \"mmf_1_5_year_rmse.pkl\"\n",
    "with open(os.path.join(online_rmse_growth_save_path, file_name), \"rb\") as f:\n",
    "    mmf_1_5_year_rmse = pickle.load(f)\n",
    "\n",
    "file_name = \"mmf_1_4_year_rmse.pkl\"\n",
    "with open(os.path.join(online_rmse_growth_save_path, file_name), \"rb\") as f:\n",
    "    mmf_1_4_year_rmse = pickle.load(f)\n",
    "\n",
    "file_name = \"ds_nn_rmse_standard_5_year.pkl\"\n",
    "with open(os.path.join(online_rmse_growth_save_path, file_name), \"rb\") as f:\n",
    "    ds_nn_rmse_standard_5_year = pickle.load(f)\n",
    "\n",
    "file_name = \"ds_nn_rmse_conf_loss_5_year.pkl\"\n",
    "with open(os.path.join(online_rmse_growth_save_path, file_name), \"rb\") as f:\n",
    "    ds_nn_rmse_conf_loss_5_year = pickle.load(f)\n",
    "\n",
    "file_name = \"ds_nn_rmse_diff_loss_5_year.pkl\"\n",
    "with open(os.path.join(online_rmse_growth_save_path, file_name), \"rb\") as f:\n",
    "    ds_nn_rmse_diff_loss_5_year = pickle.load(f)\n",
    "\n",
    "file_name = \"ds_nn_rmse_multirep_5_year.pkl\"\n",
    "with open(os.path.join(online_rmse_growth_save_path, file_name), \"rb\") as f:\n",
    "    ds_nn_rmse_multirep_5_year = pickle.load(f)\n",
    "\n",
    "file_name = \"ds_nn_rmse_v6_4_year.pkl\"\n",
    "with open(os.path.join(online_rmse_growth_save_path, file_name), \"rb\") as f:\n",
    "    ds_nn_rmse_v6_4_year = pickle.load(f)\n",
    "\n",
    "ds_mmf_1_4_year, ds_mmf_2_4_year = read_mmf_online_data(num_years = 4)\n",
    "mmf_1_hourly_prect_4_year = xr.open_mfdataset('/pscratch/sd/z/zeyuanhu/hu_etal2024_data_v2/data_hourly/precip_hourly/mmf_ref/PRECT*nc')['PRECT'].sel(time = slice(None, str(4 + 2).zfill(4))).values * 86400 * 1000\n",
    "mmf_1_hourly_prect_4_year_flat = mmf_1_hourly_prect_4_year.flatten()\n",
    "\n",
    "online_nn_hourly_prect_save_path = '/global/cfs/cdirs/m4334/jerry/climsim3_figures/online/hourly_prect'\n",
    "\n",
    "file_name = \"hourly_prect_standard_5_year.pkl\"\n",
    "with open(os.path.join(online_nn_hourly_prect_save_path, file_name), \"rb\") as file:\n",
    "    nn_hourly_prect_standard_5_year = pickle.load(file)\n",
    "\n",
    "file_name = \"hourly_prect_conf_loss_5_year.pkl\"\n",
    "with open(os.path.join(online_nn_hourly_prect_save_path, file_name), \"rb\") as file:\n",
    "    nn_hourly_prect_conf_loss_5_year = pickle.load(file)\n",
    "\n",
    "file_name = \"hourly_prect_diff_loss_5_year.pkl\"\n",
    "with open(os.path.join(online_nn_hourly_prect_save_path, file_name), \"rb\") as file:\n",
    "    nn_hourly_prect_diff_loss_5_year = pickle.load(file)\n",
    "\n",
    "file_name = \"hourly_prect_multirep_5_year.pkl\"\n",
    "with open(os.path.join(online_nn_hourly_prect_save_path, file_name), \"rb\") as file:\n",
    "    nn_hourly_prect_multirep_5_year = pickle.load(file)\n",
    "\n",
    "file_name = \"hourly_prect_v6_5_year.pkl\"\n",
    "with open(os.path.join(online_nn_hourly_prect_save_path, file_name), \"rb\") as file:\n",
    "    nn_hourly_prect_v6_5_year = pickle.load(file)\n",
    "\n",
    "file_name = \"hourly_prect_standard_4_year.pkl\"\n",
    "with open(os.path.join(online_nn_hourly_prect_save_path, file_name), \"rb\") as file:\n",
    "    nn_hourly_prect_standard_4_year = pickle.load(file)\n",
    "\n",
    "file_name = \"hourly_prect_conf_loss_4_year.pkl\"\n",
    "with open(os.path.join(online_nn_hourly_prect_save_path, file_name), \"rb\") as file:\n",
    "    nn_hourly_prect_conf_loss_4_year = pickle.load(file)\n",
    "\n",
    "file_name = \"hourly_prect_diff_loss_4_year.pkl\"\n",
    "with open(os.path.join(online_nn_hourly_prect_save_path, file_name), \"rb\") as file:\n",
    "    nn_hourly_prect_diff_loss_4_year = pickle.load(file)\n",
    "\n",
    "file_name = \"hourly_prect_multirep_4_year.pkl\"\n",
    "with open(os.path.join(online_nn_hourly_prect_save_path, file_name), \"rb\") as file:\n",
    "    nn_hourly_prect_multirep_4_year = pickle.load(file)\n",
    "\n",
    "file_name = \"hourly_prect_v6_4_year.pkl\"\n",
    "with open(os.path.join(online_nn_hourly_prect_save_path, file_name), \"rb\") as file:\n",
    "    nn_hourly_prect_v6_4_year = pickle.load(file)\n",
    "\n",
    "rmse_dict_save_path = '/global/cfs/cdirs/m4334/jerry/climsim3_figures/online/online_global_rmse_config_dicts'\n",
    "\n",
    "rmse_dict_file_path_standard_5_year = os.path.join(rmse_dict_save_path, 'standard_global_rmse_5_year.pkl')\n",
    "rmse_dict_file_path_conf_loss_5_year = os.path.join(rmse_dict_save_path, 'conf_loss_global_rmse_5_year.pkl')\n",
    "rmse_dict_file_path_diff_loss_5_year = os.path.join(rmse_dict_save_path, 'diff_loss_global_rmse_5_year.pkl')\n",
    "rmse_dict_file_path_multirep_5_year = os.path.join(rmse_dict_save_path, 'multirep_global_rmse_5_year.pkl')\n",
    "rmse_dict_file_path_v6_5_year = os.path.join(rmse_dict_save_path, 'v6_global_rmse_5_year.pkl')\n",
    "\n",
    "rmse_dict_file_path_standard_4_year = os.path.join(rmse_dict_save_path, 'standard_global_rmse_4_year.pkl')\n",
    "rmse_dict_file_path_conf_loss_4_year = os.path.join(rmse_dict_save_path, 'conf_loss_global_rmse_4_year.pkl')\n",
    "rmse_dict_file_path_diff_loss_4_year = os.path.join(rmse_dict_save_path, 'diff_loss_global_rmse_4_year.pkl')\n",
    "rmse_dict_file_path_multirep_4_year = os.path.join(rmse_dict_save_path, 'multirep_global_rmse_4_year.pkl')\n",
    "rmse_dict_file_path_v6_4_year = os.path.join(rmse_dict_save_path, 'v6_global_rmse_4_year.pkl')\n",
    "\n",
    "with open(rmse_dict_file_path_standard_5_year, 'rb') as f:\n",
    "    standard_global_rmse_5_year = pickle.load(f)\n",
    "\n",
    "with open(rmse_dict_file_path_conf_loss_5_year, 'rb') as f:\n",
    "    conf_loss_global_rmse_5_year = pickle.load(f)\n",
    "\n",
    "with open(rmse_dict_file_path_diff_loss_5_year, 'rb') as f:\n",
    "    diff_loss_global_rmse_5_year = pickle.load(f)\n",
    "\n",
    "with open(rmse_dict_file_path_multirep_5_year, 'rb') as f:\n",
    "    multirep_global_rmse_5_year = pickle.load(f)\n",
    "\n",
    "with open(rmse_dict_file_path_v6_5_year, 'rb') as f:\n",
    "    v6_global_rmse_5_year = pickle.load(f)\n",
    "\n",
    "with open(rmse_dict_file_path_standard_4_year, 'rb') as f:\n",
    "    standard_global_rmse_4_year = pickle.load(f)\n",
    "\n",
    "with open(rmse_dict_file_path_conf_loss_4_year, 'rb') as f:\n",
    "    conf_loss_global_rmse_4_year = pickle.load(f)\n",
    "\n",
    "with open(rmse_dict_file_path_diff_loss_4_year, 'rb') as f:\n",
    "    diff_loss_global_rmse_4_year = pickle.load(f)\n",
    "\n",
    "with open(rmse_dict_file_path_multirep_4_year, 'rb') as f:\n",
    "    multirep_global_rmse_4_year = pickle.load(f)\n",
    "\n",
    "with open(rmse_dict_file_path_v6_4_year, 'rb') as f:\n",
    "    v6_global_rmse_4_year = pickle.load(f)\n",
    "\n",
    "nn_global_rmse_dict_5_year = {\n",
    "    'standard': standard_global_rmse_5_year,\n",
    "    'conf_loss': conf_loss_global_rmse_5_year,\n",
    "    'diff_loss': diff_loss_global_rmse_5_year,\n",
    "    'multirep': multirep_global_rmse_5_year,\n",
    "    'v6': v6_global_rmse_5_year\n",
    "}\n",
    "\n",
    "global_rmse_dict_full_5_year = {'T': [], 'Q': [], 'U': [], 'V': [], 'CLDLIQ': [], 'CLDICE': [], 'DTPHYS': [], 'DQ1PHYS': [], 'DQnPHYS': [], 'DUPHYS': []}\n",
    "for var in global_rmse_dict_full_5_year.keys():\n",
    "    for config_name in config_names.keys():\n",
    "        for model_name in model_names.keys():\n",
    "            for idx, seed_number in enumerate(seed_numbers):\n",
    "                new_result = nn_global_rmse_dict_5_year[config_name][var][model_name][idx]\n",
    "                if not np.isnan(new_result):\n",
    "                    global_rmse_dict_full_5_year[var].append({'config_name': config_name, \n",
    "                                                    'model_name': model_name,\n",
    "                                                    'seed_idx': idx, \n",
    "                                                    'seed_number': seed_number,\n",
    "                                                    'rmse': new_result})\n",
    "\n",
    "nn_global_rmse_dict_4_year = {\n",
    "    'standard': standard_global_rmse_4_year,\n",
    "    'conf_loss': conf_loss_global_rmse_4_year,\n",
    "    'diff_loss': diff_loss_global_rmse_4_year,\n",
    "    'multirep': multirep_global_rmse_4_year,\n",
    "    'v6': v6_global_rmse_4_year\n",
    "}\n",
    "\n",
    "global_rmse_dict_full_4_year = {'T': [], 'Q': [], 'U': [], 'V': [], 'CLDLIQ': [], 'CLDICE': [], 'DTPHYS': [], 'DQ1PHYS': [], 'DQnPHYS': [], 'DUPHYS': []}\n",
    "for var in global_rmse_dict_full_4_year.keys():\n",
    "    for config_name in config_names.keys():\n",
    "        for model_name in model_names.keys():\n",
    "            for idx, seed_number in enumerate(seed_numbers):\n",
    "                new_result = nn_global_rmse_dict_4_year[config_name][var][model_name][idx]\n",
    "                if not np.isnan(new_result):\n",
    "                    global_rmse_dict_full_4_year[var].append({'config_name': config_name, \n",
    "                                                    'model_name': model_name,\n",
    "                                                    'seed_idx': idx, \n",
    "                                                    'seed_number': seed_number,\n",
    "                                                    'rmse': new_result})\n",
    "\n",
    "top_model_dict_5_year = {}\n",
    "for var in global_rmse_dict_full_5_year.keys():\n",
    "    global_rmse_dict_full_5_year[var] = sorted(global_rmse_dict_full_5_year[var], key = lambda sota_dict: sota_dict['rmse'])\n",
    "    top_model_dict_5_year[var] =  global_rmse_dict_full_5_year[var][0]\n",
    "\n",
    "top_model_dict_4_year = {}\n",
    "for var in global_rmse_dict_full_4_year.keys():\n",
    "    global_rmse_dict_full_4_year[var] = sorted(global_rmse_dict_full_4_year[var], key = lambda sota_dict: sota_dict['rmse'])\n",
    "    top_model_dict_4_year[var] =  global_rmse_dict_full_4_year[var][0]\n",
    "\n",
    "prev_sota = {'T': .98, 'Q': .25, 'CLDLIQ': 5.39, 'CLDICE': 2.09, 'U': 1.68, 'V': .77}\n",
    "sota_breakers = {'T': [], 'Q': [], 'CLDLIQ': [], 'CLDICE': [], 'U': [], 'V': []}\n",
    "nonnan_rmse_dict = {'T': [], 'Q': [], 'CLDLIQ': [], 'CLDICE': [], 'U': [], 'V': []}\n",
    "for var in prev_sota.keys():\n",
    "    for config_name in config_names.keys():\n",
    "        for model_name in model_names.keys():\n",
    "            for idx, seed_number in enumerate(seed_numbers):\n",
    "                new_result = np.round(nn_global_rmse_dict_5_year[config_name][var][model_name][idx], 2)\n",
    "                if not np.isnan(new_result):\n",
    "                    nonnan_rmse_dict[var].append({'config_name': config_name, \n",
    "                                                  'model_name': model_name,\n",
    "                                                  'seed_idx': idx, \n",
    "                                                  'seed_number': seed_number,\n",
    "                                                  'rmse': new_result,\n",
    "                                                  'sypd': sypd_dict[config_name][f'{model_name}_{seed_number}'],\n",
    "                                                  'pc': pc_dict[config_name][f'{model_name}_{seed_number}']})\n",
    "                    if new_result < prev_sota[var]:\n",
    "                        sota_breakers[var].append({'config_name': config_name, \n",
    "                                                   'model_name': model_name,\n",
    "                                                   'seed_idx': idx, \n",
    "                                                   'seed_number': seed_number,\n",
    "                                                   'rmse': new_result,\n",
    "                                                   'sypd': sypd_dict[config_name][f'{model_name}_{seed_number}'],\n",
    "                                                   'pc': pc_dict[config_name][f'{model_name}_{seed_number}']})\n",
    "\n",
    "for var in prev_sota.keys():\n",
    "    sota_breakers[var] = sorted(sota_breakers[var], key = lambda sota_dict: sota_dict['rmse'])\n",
    "    nonnan_rmse_dict[var] = sorted(nonnan_rmse_dict[var], key = lambda nonnan_dict: nonnan_dict['rmse'])\n",
    "\n",
    "zeyuan_path = '/pscratch/sd/z/zeyuanhu/hu_etal2024_data_v2/data/h0/5year/unet_v5/'\n",
    "def read_nn_online_data_zeyuan(config_name, num_years):\n",
    "    assert num_years <= 5 and num_years >= 1\n",
    "    years_regexp = '34567'[:num_years]\n",
    "    assert config_name in ['huber_rop', 'huber_step']\n",
    "    if config_name == 'huber_rop':\n",
    "        extract_path = os.path.join(zeyuan_path, config_name, f'v5_noclassifier_huber_1y_noaggressive_rop2_5year_3node.eam.h0.000[{years_regexp}]*.nc')\n",
    "    elif config_name == 'huber_step':\n",
    "        extract_path = os.path.join(zeyuan_path, config_name, f'v5_noclassifier_huber_1y_noaggressive_5year_3node.eam.h0.000[{years_regexp}]*.nc')\n",
    "    ds_nn = xr.open_mfdataset(extract_path)\n",
    "    if len(ds_nn['time']) < 12 * num_years:\n",
    "        return None\n",
    "    ds_nn['DQnPHYS'] = ds_nn['DQ2PHYS'] + ds_nn['DQ3PHYS']\n",
    "    ds_nn['TOTCLD'] = ds_nn['CLDICE'] + ds_nn['CLDLIQ']\n",
    "    ds_nn['PRECT'] = ds_nn['PRECC'] + ds_nn['PRECL']\n",
    "    return ds_nn\n",
    "\n",
    "huber_rop_run = read_nn_online_data_zeyuan('huber_rop', 5)\n",
    "huber_step_run = read_nn_online_data_zeyuan('huber_step', 5)\n",
    "\n",
    "huetal_sota_dict = {\n",
    "    'T': (.99, 1.21),\n",
    "    'Q': (.33, .25),\n",
    "    'CLDLIQ': (13.05, 5.40),\n",
    "    'CLDICE': (2.10, 2.29),\n",
    "    'U': (1.70, 1.98),\n",
    "    'V': (.79, .89)\n",
    "}\n",
    "\n",
    "mmf_ref_dict = {\n",
    "    'T': .18,\n",
    "    'Q': .06,\n",
    "    'CLDLIQ': .80,\n",
    "    'CLDICE': .65,\n",
    "    'U': .44,\n",
    "    'V': .35\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77017425",
   "metadata": {},
   "source": [
    "## Generalized Offline R2 plotting vs standard config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0253a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_offline_R2_lines_standard_vs_config(config = None, show = True, save_path = None):\n",
    "    assert config in ['conf_loss', 'diff_loss', 'multirep', 'v6']\n",
    "    if config == 'conf_loss':\n",
    "        config_r2 = conf_loss_r2_dict\n",
    "    elif config == 'diff_loss':\n",
    "        config_r2 = diff_loss_r2_dict\n",
    "    elif config == 'multirep':\n",
    "        config_r2 = multirep_r2_dict\n",
    "    elif config == 'v6':\n",
    "        config_r2 = v6_r2_dict\n",
    "\n",
    "    standard_unet_dTdt_r2 = np.stack([standard_unet_r2[seed][0][:60] for seed in seeds])\n",
    "    standard_squeezeformer_dTdt_r2 = np.stack([standard_squeezeformer_r2[seed][0][:60] for seed in seeds])\n",
    "    standard_pure_resLSTM_dTdt_r2 = np.stack([standard_pure_resLSTM_r2[seed][0][:60] for seed in seeds])\n",
    "    standard_pao_model_dTdt_r2 = np.stack([standard_pao_model_r2[seed][0][:60] for seed in seeds])\n",
    "    standard_convnext_dTdt_r2 = np.stack([standard_convnext_r2[seed][0][:60] for seed in seeds])\n",
    "    standard_encdec_lstm_dTdt_r2 = np.stack([standard_encdec_lstm_r2[seed][0][:60] for seed in seeds])\n",
    "\n",
    "    config_unet_dTdt_r2 = np.stack([config_r2['unet'][seed][0][:60] for seed in seeds])\n",
    "    config_squeezeformer_dTdt_r2 = np.stack([config_r2['squeezeformer'][seed][0][:60] for seed in seeds])\n",
    "    config_pure_resLSTM_dTdt_r2 = np.stack([config_r2['pure_resLSTM'][seed][0][:60] for seed in seeds])\n",
    "    config_pao_model_dTdt_r2 = np.stack([config_r2['pao_model'][seed][0][:60] for seed in seeds])\n",
    "    config_convnext_dTdt_r2 = np.stack([config_r2['convnext'][seed][0][:60] for seed in seeds])\n",
    "    config_encdec_lstm_dTdt_r2 = np.stack([config_r2['encdec_lstm'][seed][0][:60] for seed in seeds])\n",
    "\n",
    "    standard_unet_dQvdt_r2 = np.stack([standard_unet_r2[seed][0][60:120] for seed in seeds])\n",
    "    standard_squeezeformer_dQvdt_r2 = np.stack([standard_squeezeformer_r2[seed][0][60:120] for seed in seeds])\n",
    "    standard_pure_resLSTM_dQvdt_r2 = np.stack([standard_pure_resLSTM_r2[seed][0][60:120] for seed in seeds])\n",
    "    standard_pao_model_dQvdt_r2 = np.stack([standard_pao_model_r2[seed][0][60:120] for seed in seeds])\n",
    "    standard_convnext_dQvdt_r2 = np.stack([standard_convnext_r2[seed][0][60:120] for seed in seeds])\n",
    "    standard_encdec_lstm_dQvdt_r2 = np.stack([standard_encdec_lstm_r2[seed][0][60:120] for seed in seeds])\n",
    "\n",
    "    config_unet_dQvdt_r2 = np.stack([config_r2['unet'][seed][0][60:120] for seed in seeds])\n",
    "    config_squeezeformer_dQvdt_r2 = np.stack([config_r2['squeezeformer'][seed][0][60:120] for seed in seeds])\n",
    "    config_pure_resLSTM_dQvdt_r2 = np.stack([config_r2['pure_resLSTM'][seed][0][60:120] for seed in seeds])\n",
    "    config_pao_model_dQvdt_r2 = np.stack([config_r2['pao_model'][seed][0][60:120] for seed in seeds])\n",
    "    config_convnext_dQvdt_r2 = np.stack([config_r2['convnext'][seed][0][60:120] for seed in seeds])\n",
    "    config_encdec_lstm_dQvdt_r2 = np.stack([config_r2['encdec_lstm'][seed][0][60:120] for seed in seeds])\n",
    "\n",
    "    standard_unet_dQldt_r2 = np.stack([standard_unet_r2[seed][0][120:180] for seed in seeds])\n",
    "    standard_squeezeformer_dQldt_r2 = np.stack([standard_squeezeformer_r2[seed][0][120:180] for seed in seeds])\n",
    "    standard_pure_resLSTM_dQldt_r2 = np.stack([standard_pure_resLSTM_r2[seed][0][120:180] for seed in seeds])\n",
    "    standard_pao_model_dQldt_r2 = np.stack([standard_pao_model_r2[seed][0][120:180] for seed in seeds])\n",
    "    standard_convnext_dQldt_r2 = np.stack([standard_convnext_r2[seed][0][120:180] for seed in seeds])\n",
    "    standard_encdec_lstm_dQldt_r2 = np.stack([standard_encdec_lstm_r2[seed][0][120:180] for seed in seeds])\n",
    "\n",
    "    config_unet_dQldt_r2 = np.stack([config_r2['unet'][seed][0][120:180] for seed in seeds])\n",
    "    config_squeezeformer_dQldt_r2 = np.stack([config_r2['squeezeformer'][seed][0][120:180] for seed in seeds])\n",
    "    config_pure_resLSTM_dQldt_r2 = np.stack([config_r2['pure_resLSTM'][seed][0][120:180] for seed in seeds])\n",
    "    config_pao_model_dQldt_r2 = np.stack([config_r2['pao_model'][seed][0][120:180] for seed in seeds])\n",
    "    config_convnext_dQldt_r2 = np.stack([config_r2['convnext'][seed][0][120:180] for seed in seeds])\n",
    "    config_encdec_lstm_dQldt_r2 = np.stack([config_r2['encdec_lstm'][seed][0][120:180] for seed in seeds])\n",
    "\n",
    "    standard_unet_dQidt_r2 = np.stack([standard_unet_r2[seed][0][180:240] for seed in seeds])\n",
    "    standard_squeezeformer_dQidt_r2 = np.stack([standard_squeezeformer_r2[seed][0][180:240] for seed in seeds])\n",
    "    standard_pure_resLSTM_dQidt_r2 = np.stack([standard_pure_resLSTM_r2[seed][0][180:240] for seed in seeds])\n",
    "    standard_pao_model_dQidt_r2 = np.stack([standard_pao_model_r2[seed][0][180:240] for seed in seeds])\n",
    "    standard_convnext_dQidt_r2 = np.stack([standard_convnext_r2[seed][0][180:240] for seed in seeds])\n",
    "    standard_encdec_lstm_dQidt_r2 = np.stack([standard_encdec_lstm_r2[seed][0][180:240] for seed in seeds])\n",
    "\n",
    "    config_unet_dQidt_r2 = np.stack([config_r2['unet'][seed][0][180:240] for seed in seeds])\n",
    "    config_squeezeformer_dQidt_r2 = np.stack([config_r2['squeezeformer'][seed][0][180:240] for seed in seeds])\n",
    "    config_pure_resLSTM_dQidt_r2 = np.stack([config_r2['pure_resLSTM'][seed][0][180:240] for seed in seeds])\n",
    "    config_pao_model_dQidt_r2 = np.stack([config_r2['pao_model'][seed][0][180:240] for seed in seeds])\n",
    "    config_convnext_dQidt_r2 = np.stack([config_r2['convnext'][seed][0][180:240] for seed in seeds])\n",
    "    config_encdec_lstm_dQidt_r2 = np.stack([config_r2['encdec_lstm'][seed][0][180:240] for seed in seeds])\n",
    "\n",
    "    standard_unet_dUdt_r2 = np.stack([standard_unet_r2[seed][0][240:300] for seed in seeds])\n",
    "    standard_squeezeformer_dUdt_r2 = np.stack([standard_squeezeformer_r2[seed][0][240:300] for seed in seeds])\n",
    "    standard_pure_resLSTM_dUdt_r2 = np.stack([standard_pure_resLSTM_r2[seed][0][240:300] for seed in seeds])\n",
    "    standard_pao_model_dUdt_r2 = np.stack([standard_pao_model_r2[seed][0][240:300] for seed in seeds])\n",
    "    standard_convnext_dUdt_r2 = np.stack([standard_convnext_r2[seed][0][240:300] for seed in seeds])\n",
    "    standard_encdec_lstm_dUdt_r2 = np.stack([standard_encdec_lstm_r2[seed][0][240:300] for seed in seeds])\n",
    "\n",
    "    config_unet_dUdt_r2 = np.stack([config_r2['unet'][seed][0][240:300] for seed in seeds])\n",
    "    config_squeezeformer_dUdt_r2 = np.stack([config_r2['squeezeformer'][seed][0][240:300] for seed in seeds])\n",
    "    config_pure_resLSTM_dUdt_r2 = np.stack([config_r2['pure_resLSTM'][seed][0][240:300] for seed in seeds])\n",
    "    config_pao_model_dUdt_r2 = np.stack([config_r2['pao_model'][seed][0][240:300] for seed in seeds])\n",
    "    config_convnext_dUdt_r2 = np.stack([config_r2['convnext'][seed][0][240:300] for seed in seeds])\n",
    "    config_encdec_lstm_dUdt_r2 = np.stack([config_r2['encdec_lstm'][seed][0][240:300] for seed in seeds])\n",
    "\n",
    "    standard_unet_dVdt_r2 = np.stack([standard_unet_r2[seed][0][300:360] for seed in seeds])\n",
    "    standard_squeezeformer_dVdt_r2 = np.stack([standard_squeezeformer_r2[seed][0][300:360] for seed in seeds])\n",
    "    standard_pure_resLSTM_dVdt_r2 = np.stack([standard_pure_resLSTM_r2[seed][0][300:360] for seed in seeds])\n",
    "    standard_pao_model_dVdt_r2 = np.stack([standard_pao_model_r2[seed][0][300:360] for seed in seeds])\n",
    "    standard_convnext_dVdt_r2 = np.stack([standard_convnext_r2[seed][0][300:360] for seed in seeds])\n",
    "    standard_encdec_lstm_dVdt_r2 = np.stack([standard_encdec_lstm_r2[seed][0][300:360] for seed in seeds])\n",
    "\n",
    "    config_unet_dVdt_r2 = np.stack([config_r2['unet'][seed][0][300:360] for seed in seeds])\n",
    "    config_squeezeformer_dVdt_r2 = np.stack([config_r2['squeezeformer'][seed][0][300:360] for seed in seeds])\n",
    "    config_pure_resLSTM_dVdt_r2 = np.stack([config_r2['pure_resLSTM'][seed][0][300:360] for seed in seeds])\n",
    "    config_pao_model_dVdt_r2 = np.stack([config_r2['pao_model'][seed][0][300:360] for seed in seeds])\n",
    "    config_convnext_dVdt_r2 = np.stack([config_r2['convnext'][seed][0][300:360] for seed in seeds])\n",
    "    config_encdec_lstm_dVdt_r2 = np.stack([config_r2['encdec_lstm'][seed][0][300:360] for seed in seeds])\n",
    "\n",
    "    standard_unet_NETSW_r2 = np.stack([standard_unet_r2[seed][0][360] for seed in seeds])\n",
    "    standard_squeezeformer_NETSW_r2 = np.stack([standard_squeezeformer_r2[seed][0][360] for seed in seeds])\n",
    "    standard_pure_resLSTM_NETSW_r2 = np.stack([standard_pure_resLSTM_r2[seed][0][360] for seed in seeds])\n",
    "    standard_pao_model_NETSW_r2 = np.stack([standard_pao_model_r2[seed][0][360] for seed in seeds])\n",
    "    standard_convnext_NETSW_r2 = np.stack([standard_convnext_r2[seed][0][360] for seed in seeds])\n",
    "    standard_encdec_lstm_NETSW_r2 = np.stack([standard_encdec_lstm_r2[seed][0][360] for seed in seeds])\n",
    "\n",
    "    config_unet_NETSW_r2 = np.stack([config_r2['unet'][seed][0][360] for seed in seeds])\n",
    "    config_squeezeformer_NETSW_r2 = np.stack([config_r2['squeezeformer'][seed][0][360] for seed in seeds])\n",
    "    config_pure_resLSTM_NETSW_r2 = np.stack([config_r2['pure_resLSTM'][seed][0][360] for seed in seeds])\n",
    "    config_pao_model_NETSW_r2 = np.stack([config_r2['pao_model'][seed][0][360] for seed in seeds])\n",
    "    config_convnext_NETSW_r2 = np.stack([config_r2['convnext'][seed][0][360] for seed in seeds])\n",
    "    config_encdec_lstm_NETSW_r2 = np.stack([config_r2['encdec_lstm'][seed][0][360] for seed in seeds])\n",
    "\n",
    "    standard_unet_FLWDS_r2 = np.stack([standard_unet_r2[seed][0][361] for seed in seeds])\n",
    "    standard_squeezeformer_FLWDS_r2 = np.stack([standard_squeezeformer_r2[seed][0][361] for seed in seeds])\n",
    "    standard_pure_resLSTM_FLWDS_r2 = np.stack([standard_pure_resLSTM_r2[seed][0][361] for seed in seeds])\n",
    "    standard_pao_model_FLWDS_r2 = np.stack([standard_pao_model_r2[seed][0][361] for seed in seeds])\n",
    "    standard_convnext_FLWDS_r2 = np.stack([standard_convnext_r2[seed][0][361] for seed in seeds])\n",
    "    standard_encdec_lstm_FLWDS_r2 = np.stack([standard_encdec_lstm_r2[seed][0][361] for seed in seeds])\n",
    "\n",
    "    config_unet_FLWDS_r2 = np.stack([config_r2['unet'][seed][0][361] for seed in seeds])\n",
    "    config_squeezeformer_FLWDS_r2 = np.stack([config_r2['squeezeformer'][seed][0][361] for seed in seeds])\n",
    "    config_pure_resLSTM_FLWDS_r2 = np.stack([config_r2['pure_resLSTM'][seed][0][361] for seed in seeds])\n",
    "    config_pao_model_FLWDS_r2 = np.stack([config_r2['pao_model'][seed][0][361] for seed in seeds])\n",
    "    config_convnext_FLWDS_r2 = np.stack([config_r2['convnext'][seed][0][361] for seed in seeds])\n",
    "    config_encdec_lstm_FLWDS_r2 = np.stack([config_r2['encdec_lstm'][seed][0][361] for seed in seeds])\n",
    "\n",
    "    standard_unet_PRECSC_r2 = np.stack([standard_unet_r2[seed][0][362] for seed in seeds])\n",
    "    standard_squeezeformer_PRECSC_r2 = np.stack([standard_squeezeformer_r2[seed][0][362] for seed in seeds])\n",
    "    standard_pure_resLSTM_PRECSC_r2 = np.stack([standard_pure_resLSTM_r2[seed][0][362] for seed in seeds])\n",
    "    standard_pao_model_PRECSC_r2 = np.stack([standard_pao_model_r2[seed][0][362] for seed in seeds])\n",
    "    standard_convnext_PRECSC_r2 = np.stack([standard_convnext_r2[seed][0][362] for seed in seeds])\n",
    "    standard_encdec_lstm_PRECSC_r2 = np.stack([standard_encdec_lstm_r2[seed][0][362] for seed in seeds])\n",
    "\n",
    "    config_unet_PRECSC_r2 = np.stack([config_r2['unet'][seed][0][362] for seed in seeds])\n",
    "    config_squeezeformer_PRECSC_r2 = np.stack([config_r2['squeezeformer'][seed][0][362] for seed in seeds])\n",
    "    config_pure_resLSTM_PRECSC_r2 = np.stack([config_r2['pure_resLSTM'][seed][0][362] for seed in seeds])\n",
    "    config_pao_model_PRECSC_r2 = np.stack([config_r2['pao_model'][seed][0][362] for seed in seeds])\n",
    "    config_convnext_PRECSC_r2 = np.stack([config_r2['convnext'][seed][0][362] for seed in seeds])\n",
    "    config_encdec_lstm_PRECSC_r2 = np.stack([config_r2['encdec_lstm'][seed][0][362] for seed in seeds])\n",
    "\n",
    "    standard_unet_PRECC_r2 = np.stack([standard_unet_r2[seed][0][363] for seed in seeds])\n",
    "    standard_squeezeformer_PRECC_r2 = np.stack([standard_squeezeformer_r2[seed][0][363] for seed in seeds])\n",
    "    standard_pure_resLSTM_PRECC_r2 = np.stack([standard_pure_resLSTM_r2[seed][0][363] for seed in seeds])\n",
    "    standard_pao_model_PRECC_r2 = np.stack([standard_pao_model_r2[seed][0][363] for seed in seeds])\n",
    "    standard_convnext_PRECC_r2 = np.stack([standard_convnext_r2[seed][0][363] for seed in seeds])\n",
    "    standard_encdec_lstm_PRECC_r2 = np.stack([standard_encdec_lstm_r2[seed][0][363] for seed in seeds])\n",
    "\n",
    "    config_unet_PRECC_r2 = np.stack([config_r2['unet'][seed][0][363] for seed in seeds])\n",
    "    config_squeezeformer_PRECC_r2 = np.stack([config_r2['squeezeformer'][seed][0][363] for seed in seeds])\n",
    "    config_pure_resLSTM_PRECC_r2 = np.stack([config_r2['pure_resLSTM'][seed][0][363] for seed in seeds])\n",
    "    config_pao_model_PRECC_r2 = np.stack([config_r2['pao_model'][seed][0][363] for seed in seeds])\n",
    "    config_convnext_PRECC_r2 = np.stack([config_r2['convnext'][seed][0][363] for seed in seeds])\n",
    "    config_encdec_lstm_PRECC_r2 = np.stack([config_r2['encdec_lstm'][seed][0][363] for seed in seeds])\n",
    "\n",
    "    standard_unet_SOLS_r2 = np.stack([standard_unet_r2[seed][0][364] for seed in seeds])\n",
    "    standard_squeezeformer_SOLS_r2 = np.stack([standard_squeezeformer_r2[seed][0][364] for seed in seeds])\n",
    "    standard_pure_resLSTM_SOLS_r2 = np.stack([standard_pure_resLSTM_r2[seed][0][364] for seed in seeds])\n",
    "    standard_pao_model_SOLS_r2 = np.stack([standard_pao_model_r2[seed][0][364] for seed in seeds])\n",
    "    standard_convnext_SOLS_r2 = np.stack([standard_convnext_r2[seed][0][364] for seed in seeds])\n",
    "    standard_encdec_lstm_SOLS_r2 = np.stack([standard_encdec_lstm_r2[seed][0][364] for seed in seeds])\n",
    "\n",
    "    config_unet_SOLS_r2 = np.stack([config_r2['unet'][seed][0][364] for seed in seeds])\n",
    "    config_squeezeformer_SOLS_r2 = np.stack([config_r2['squeezeformer'][seed][0][364] for seed in seeds])\n",
    "    config_pure_resLSTM_SOLS_r2 = np.stack([config_r2['pure_resLSTM'][seed][0][364] for seed in seeds])\n",
    "    config_pao_model_SOLS_r2 = np.stack([config_r2['pao_model'][seed][0][364] for seed in seeds])\n",
    "    config_convnext_SOLS_r2 = np.stack([config_r2['convnext'][seed][0][364] for seed in seeds])\n",
    "    config_encdec_lstm_SOLS_r2 = np.stack([config_r2['encdec_lstm'][seed][0][364] for seed in seeds])\n",
    "\n",
    "    standard_unet_SOLL_r2 = np.stack([standard_unet_r2[seed][0][365] for seed in seeds])\n",
    "    standard_squeezeformer_SOLL_r2 = np.stack([standard_squeezeformer_r2[seed][0][365] for seed in seeds])\n",
    "    standard_pure_resLSTM_SOLL_r2 = np.stack([standard_pure_resLSTM_r2[seed][0][365] for seed in seeds])\n",
    "    standard_pao_model_SOLL_r2 = np.stack([standard_pao_model_r2[seed][0][365] for seed in seeds])\n",
    "    standard_convnext_SOLL_r2 = np.stack([standard_convnext_r2[seed][0][365] for seed in seeds])\n",
    "    standard_encdec_lstm_SOLL_r2 = np.stack([standard_encdec_lstm_r2[seed][0][365] for seed in seeds])\n",
    "\n",
    "    config_unet_SOLL_r2 = np.stack([config_r2['unet'][seed][0][365] for seed in seeds])\n",
    "    config_squeezeformer_SOLL_r2 = np.stack([config_r2['squeezeformer'][seed][0][365] for seed in seeds])\n",
    "    config_pure_resLSTM_SOLL_r2 = np.stack([config_r2['pure_resLSTM'][seed][0][365] for seed in seeds])\n",
    "    config_pao_model_SOLL_r2 = np.stack([config_r2['pao_model'][seed][0][365] for seed in seeds])\n",
    "    config_convnext_SOLL_r2 = np.stack([config_r2['convnext'][seed][0][365] for seed in seeds])\n",
    "    config_encdec_lstm_SOLL_r2 = np.stack([config_r2['encdec_lstm'][seed][0][365] for seed in seeds])\n",
    "\n",
    "    standard_unet_SOLSD_r2 = np.stack([standard_unet_r2[seed][0][366] for seed in seeds])\n",
    "    standard_squeezeformer_SOLSD_r2 = np.stack([standard_squeezeformer_r2[seed][0][366] for seed in seeds])\n",
    "    standard_pure_resLSTM_SOLSD_r2 = np.stack([standard_pure_resLSTM_r2[seed][0][366] for seed in seeds])\n",
    "    standard_pao_model_SOLSD_r2 = np.stack([standard_pao_model_r2[seed][0][366] for seed in seeds])\n",
    "    standard_convnext_SOLSD_r2 = np.stack([standard_convnext_r2[seed][0][366] for seed in seeds])\n",
    "    standard_encdec_lstm_SOLSD_r2 = np.stack([standard_encdec_lstm_r2[seed][0][366] for seed in seeds])\n",
    "\n",
    "    config_unet_SOLSD_r2 = np.stack([config_r2['unet'][seed][0][366] for seed in seeds])\n",
    "    config_squeezeformer_SOLSD_r2 = np.stack([config_r2['squeezeformer'][seed][0][366] for seed in seeds])\n",
    "    config_pure_resLSTM_SOLSD_r2 = np.stack([config_r2['pure_resLSTM'][seed][0][366] for seed in seeds])\n",
    "    config_pao_model_SOLSD_r2 = np.stack([config_r2['pao_model'][seed][0][366] for seed in seeds])\n",
    "    config_convnext_SOLSD_r2 = np.stack([config_r2['convnext'][seed][0][366] for seed in seeds])\n",
    "    config_encdec_lstm_SOLSD_r2 = np.stack([config_r2['encdec_lstm'][seed][0][366] for seed in seeds])\n",
    "\n",
    "    standard_unet_SOLLD_r2 = np.stack([standard_unet_r2[seed][0][367] for seed in seeds])\n",
    "    standard_squeezeformer_SOLLD_r2 = np.stack([standard_squeezeformer_r2[seed][0][367] for seed in seeds])\n",
    "    standard_pure_resLSTM_SOLLD_r2 = np.stack([standard_pure_resLSTM_r2[seed][0][367] for seed in seeds])\n",
    "    standard_pao_model_SOLLD_r2 = np.stack([standard_pao_model_r2[seed][0][367] for seed in seeds])\n",
    "    standard_convnext_SOLLD_r2 = np.stack([standard_convnext_r2[seed][0][367] for seed in seeds])\n",
    "    standard_encdec_lstm_SOLLD_r2 = np.stack([standard_encdec_lstm_r2[seed][0][367] for seed in seeds])\n",
    "\n",
    "    config_unet_SOLLD_r2 = np.stack([config_r2['unet'][seed][0][367] for seed in seeds])\n",
    "    config_squeezeformer_SOLLD_r2 = np.stack([config_r2['squeezeformer'][seed][0][367] for seed in seeds])\n",
    "    config_pure_resLSTM_SOLLD_r2 = np.stack([config_r2['pure_resLSTM'][seed][0][367] for seed in seeds])\n",
    "    config_pao_model_SOLLD_r2 = np.stack([config_r2['pao_model'][seed][0][367] for seed in seeds])\n",
    "    config_convnext_SOLLD_r2 = np.stack([config_r2['convnext'][seed][0][367] for seed in seeds])\n",
    "    config_encdec_lstm_SOLLD_r2 = np.stack([config_r2['encdec_lstm'][seed][0][367] for seed in seeds])\n",
    "\n",
    "    standard_dTdt_r2 = {\n",
    "        'min': np.stack([standard_unet_dTdt_r2.min(axis=0), standard_squeezeformer_dTdt_r2.min(axis=0), standard_pure_resLSTM_dTdt_r2.min(axis=0), standard_pao_model_dTdt_r2.min(axis=0), standard_convnext_dTdt_r2.min(axis=0), standard_encdec_lstm_dTdt_r2.min(axis=0)], axis = 0),\n",
    "        'median': np.stack([np.median(standard_unet_dTdt_r2, axis=0), np.median(standard_squeezeformer_dTdt_r2, axis=0), np.median(standard_pure_resLSTM_dTdt_r2, axis=0), np.median(standard_pao_model_dTdt_r2, axis=0), np.median(standard_convnext_dTdt_r2, axis=0), np.median(standard_encdec_lstm_dTdt_r2, axis=0)], axis = 0),\n",
    "        'max': np.stack([standard_unet_dTdt_r2.max(axis=0), standard_squeezeformer_dTdt_r2.max(axis=0), standard_pure_resLSTM_dTdt_r2.max(axis=0), standard_pao_model_dTdt_r2.max(axis=0), standard_convnext_dTdt_r2.max(axis=0), standard_encdec_lstm_dTdt_r2.max(axis=0)], axis = 0)\n",
    "    }\n",
    "    config_dTdt_r2 = {\n",
    "        'min': np.stack([config_unet_dTdt_r2.min(axis=0), config_squeezeformer_dTdt_r2.min(axis=0), config_pure_resLSTM_dTdt_r2.min(axis=0), config_pao_model_dTdt_r2.min(axis=0), config_convnext_dTdt_r2.min(axis=0), config_encdec_lstm_dTdt_r2.min(axis=0)], axis = 0),\n",
    "        'median': np.stack([np.median(config_unet_dTdt_r2, axis=0), np.median(config_squeezeformer_dTdt_r2, axis=0), np.median(config_pure_resLSTM_dTdt_r2, axis=0), np.median(config_pao_model_dTdt_r2, axis=0), np.median(config_convnext_dTdt_r2, axis=0), np.median(config_encdec_lstm_dTdt_r2, axis=0)], axis = 0),\n",
    "        'max': np.stack([config_unet_dTdt_r2.max(axis=0), config_squeezeformer_dTdt_r2.max(axis=0), config_pure_resLSTM_dTdt_r2.max(axis=0), config_pao_model_dTdt_r2.max(axis=0), config_convnext_dTdt_r2.max(axis=0), config_encdec_lstm_dTdt_r2.max(axis=0)], axis = 0)\n",
    "    }\n",
    "    standard_dQvdt_r2 = {\n",
    "        'min': np.stack([standard_unet_dQvdt_r2.min(axis=0), standard_squeezeformer_dQvdt_r2.min(axis=0), standard_pure_resLSTM_dQvdt_r2.min(axis=0), standard_pao_model_dQvdt_r2.min(axis=0), standard_convnext_dQvdt_r2.min(axis=0), standard_encdec_lstm_dQvdt_r2.min(axis=0)], axis = 0),\n",
    "        'median': np.stack([np.median(standard_unet_dQvdt_r2, axis=0), np.median(standard_squeezeformer_dQvdt_r2, axis=0), np.median(standard_pure_resLSTM_dQvdt_r2, axis=0), np.median(standard_pao_model_dQvdt_r2, axis=0), np.median(standard_convnext_dQvdt_r2, axis=0), np.median(standard_encdec_lstm_dQvdt_r2, axis=0)], axis = 0),\n",
    "        'max': np.stack([standard_unet_dQvdt_r2.max(axis=0), standard_squeezeformer_dQvdt_r2.max(axis=0), standard_pure_resLSTM_dQvdt_r2.max(axis=0), standard_pao_model_dQvdt_r2.max(axis=0), standard_convnext_dQvdt_r2.max(axis=0), standard_encdec_lstm_dQvdt_r2.max(axis=0)], axis = 0)\n",
    "    }\n",
    "    config_dQvdt_r2 = {\n",
    "        'min': np.stack([config_unet_dQvdt_r2.min(axis=0), config_squeezeformer_dQvdt_r2.min(axis=0), config_pure_resLSTM_dQvdt_r2.min(axis=0), config_pao_model_dQvdt_r2.min(axis=0), config_convnext_dQvdt_r2.min(axis=0), config_encdec_lstm_dQvdt_r2.min(axis=0)], axis = 0),\n",
    "        'median': np.stack([np.median(config_unet_dQvdt_r2, axis=0), np.median(config_squeezeformer_dQvdt_r2, axis=0), np.median(config_pure_resLSTM_dQvdt_r2, axis=0), np.median(config_pao_model_dQvdt_r2, axis=0), np.median(config_convnext_dQvdt_r2, axis=0), np.median(config_encdec_lstm_dQvdt_r2, axis=0)], axis = 0),\n",
    "        'max': np.stack([config_unet_dQvdt_r2.max(axis=0), config_squeezeformer_dQvdt_r2.max(axis=0), config_pure_resLSTM_dQvdt_r2.max(axis=0), config_pao_model_dQvdt_r2.max(axis=0), config_convnext_dQvdt_r2.max(axis=0), config_encdec_lstm_dQvdt_r2.max(axis=0)], axis = 0)\n",
    "    }\n",
    "    standard_dQldt_r2 = {\n",
    "        'min': np.stack([standard_unet_dQldt_r2.min(axis=0), standard_squeezeformer_dQldt_r2.min(axis=0), standard_pure_resLSTM_dQldt_r2.min(axis=0), standard_pao_model_dQldt_r2.min(axis=0), standard_convnext_dQldt_r2.min(axis=0), standard_encdec_lstm_dQldt_r2.min(axis=0)], axis = 0),\n",
    "        'median': np.stack([np.median(standard_unet_dQldt_r2, axis=0), np.median(standard_squeezeformer_dQldt_r2, axis=0), np.median(standard_pure_resLSTM_dQldt_r2, axis=0), np.median(standard_pao_model_dQldt_r2, axis=0), np.median(standard_convnext_dQldt_r2, axis=0), np.median(standard_encdec_lstm_dQldt_r2, axis=0)], axis = 0),\n",
    "        'max': np.stack([standard_unet_dQldt_r2.max(axis=0), standard_squeezeformer_dQldt_r2.max(axis=0), standard_pure_resLSTM_dQldt_r2.max(axis=0), standard_pao_model_dQldt_r2.max(axis=0), standard_convnext_dQldt_r2.max(axis=0), standard_encdec_lstm_dQldt_r2.max(axis=0)], axis = 0)\n",
    "    }\n",
    "    config_dQldt_r2 = {\n",
    "        'min': np.stack([config_unet_dQldt_r2.min(axis=0), config_squeezeformer_dQldt_r2.min(axis=0), config_pure_resLSTM_dQldt_r2.min(axis=0), config_pao_model_dQldt_r2.min(axis=0), config_convnext_dQldt_r2.min(axis=0), config_encdec_lstm_dQldt_r2.min(axis=0)], axis = 0),\n",
    "        'median': np.stack([np.median(config_unet_dQldt_r2, axis=0), np.median(config_squeezeformer_dQldt_r2, axis=0), np.median(config_pure_resLSTM_dQldt_r2, axis=0), np.median(config_pao_model_dQldt_r2, axis=0), np.median(config_convnext_dQldt_r2, axis=0), np.median(config_encdec_lstm_dQldt_r2, axis=0)], axis = 0),\n",
    "        'max': np.stack([config_unet_dQldt_r2.max(axis=0), config_squeezeformer_dQldt_r2.max(axis=0), config_pure_resLSTM_dQldt_r2.max(axis=0), config_pao_model_dQldt_r2.max(axis=0), config_convnext_dQldt_r2.max(axis=0), config_encdec_lstm_dQldt_r2.max(axis=0)], axis = 0)\n",
    "    }\n",
    "    standard_dQidt_r2 = {\n",
    "        'min': np.stack([standard_unet_dQidt_r2.min(axis=0), standard_squeezeformer_dQidt_r2.min(axis=0), standard_pure_resLSTM_dQidt_r2.min(axis=0), standard_pao_model_dQidt_r2.min(axis=0), standard_convnext_dQidt_r2.min(axis=0), standard_encdec_lstm_dQidt_r2.min(axis=0)], axis = 0),\n",
    "        'median': np.stack([np.median(standard_unet_dQidt_r2, axis=0), np.median(standard_squeezeformer_dQidt_r2, axis=0), np.median(standard_pure_resLSTM_dQidt_r2, axis=0), np.median(standard_pao_model_dQidt_r2, axis=0), np.median(standard_convnext_dQidt_r2, axis=0), np.median(standard_encdec_lstm_dQidt_r2, axis=0)], axis = 0),\n",
    "        'max': np.stack([standard_unet_dQidt_r2.max(axis=0), standard_squeezeformer_dQidt_r2.max(axis=0), standard_pure_resLSTM_dQidt_r2.max(axis=0), standard_pao_model_dQidt_r2.max(axis=0), standard_convnext_dQidt_r2.max(axis=0), standard_encdec_lstm_dQidt_r2.max(axis=0)], axis = 0)\n",
    "    }\n",
    "    config_dQidt_r2 = {\n",
    "        'min': np.stack([config_unet_dQidt_r2.min(axis=0), config_squeezeformer_dQidt_r2.min(axis=0), config_pure_resLSTM_dQidt_r2.min(axis=0), config_pao_model_dQidt_r2.min(axis=0), config_convnext_dQidt_r2.min(axis=0), config_encdec_lstm_dQidt_r2.min(axis=0)], axis = 0),\n",
    "        'median': np.stack([np.median(config_unet_dQidt_r2, axis=0), np.median(config_squeezeformer_dQidt_r2, axis=0), np.median(config_pure_resLSTM_dQidt_r2, axis=0), np.median(config_pao_model_dQidt_r2, axis=0), np.median(config_convnext_dQidt_r2, axis=0), np.median(config_encdec_lstm_dQidt_r2, axis=0)], axis = 0),\n",
    "        'max': np.stack([config_unet_dQidt_r2.max(axis=0), config_squeezeformer_dQidt_r2.max(axis=0), config_pure_resLSTM_dQidt_r2.max(axis=0), config_pao_model_dQidt_r2.max(axis=0), config_convnext_dQidt_r2.max(axis=0), config_encdec_lstm_dQidt_r2.max(axis=0)], axis = 0)\n",
    "    }\n",
    "    standard_dUdt_r2 = {\n",
    "        'min': np.stack([standard_unet_dUdt_r2.min(axis=0), standard_squeezeformer_dUdt_r2.min(axis=0), standard_pure_resLSTM_dUdt_r2.min(axis=0), standard_pao_model_dUdt_r2.min(axis=0), standard_convnext_dUdt_r2.min(axis=0), standard_encdec_lstm_dUdt_r2.min(axis=0)], axis = 0),\n",
    "        'median': np.stack([np.median(standard_unet_dUdt_r2, axis=0), np.median(standard_squeezeformer_dUdt_r2, axis=0), np.median(standard_pure_resLSTM_dUdt_r2, axis=0), np.median(standard_pao_model_dUdt_r2, axis=0), np.median(standard_convnext_dUdt_r2, axis=0), np.median(standard_encdec_lstm_dUdt_r2, axis=0)], axis = 0),\n",
    "        'max': np.stack([standard_unet_dUdt_r2.max(axis=0), standard_squeezeformer_dUdt_r2.max(axis=0), standard_pure_resLSTM_dUdt_r2.max(axis=0), standard_pao_model_dUdt_r2.max(axis=0), standard_convnext_dUdt_r2.max(axis=0), standard_encdec_lstm_dUdt_r2.max(axis=0)], axis = 0)\n",
    "    }\n",
    "    config_dUdt_r2 = {\n",
    "        'min': np.stack([config_unet_dUdt_r2.min(axis=0), config_squeezeformer_dUdt_r2.min(axis=0), config_pure_resLSTM_dUdt_r2.min(axis=0), config_pao_model_dUdt_r2.min(axis=0), config_convnext_dUdt_r2.min(axis=0), config_encdec_lstm_dUdt_r2.min(axis=0)], axis = 0),\n",
    "        'median': np.stack([np.median(config_unet_dUdt_r2, axis=0), np.median(config_squeezeformer_dUdt_r2, axis=0), np.median(config_pure_resLSTM_dUdt_r2, axis=0), np.median(config_pao_model_dUdt_r2, axis=0), np.median(config_convnext_dUdt_r2, axis=0), np.median(config_encdec_lstm_dUdt_r2, axis=0)], axis = 0),\n",
    "        'max': np.stack([config_unet_dUdt_r2.max(axis=0), config_squeezeformer_dUdt_r2.max(axis=0), config_pure_resLSTM_dUdt_r2.max(axis=0), config_pao_model_dUdt_r2.max(axis=0), config_convnext_dUdt_r2.max(axis=0), config_encdec_lstm_dUdt_r2.max(axis=0)], axis = 0)\n",
    "    }\n",
    "    standard_dVdt_r2 = {\n",
    "        'min': np.stack([standard_unet_dVdt_r2.min(axis=0), standard_squeezeformer_dVdt_r2.min(axis=0), standard_pure_resLSTM_dVdt_r2.min(axis=0), standard_pao_model_dVdt_r2.min(axis=0), standard_convnext_dVdt_r2.min(axis=0), standard_encdec_lstm_dVdt_r2.min(axis=0)], axis = 0),\n",
    "        'median': np.stack([np.median(standard_unet_dVdt_r2, axis=0), np.median(standard_squeezeformer_dVdt_r2, axis=0), np.median(standard_pure_resLSTM_dVdt_r2, axis=0), np.median(standard_pao_model_dVdt_r2, axis=0), np.median(standard_convnext_dVdt_r2, axis=0), np.median(standard_encdec_lstm_dVdt_r2, axis=0)], axis = 0),\n",
    "        'max': np.stack([standard_unet_dVdt_r2.max(axis=0), standard_squeezeformer_dVdt_r2.max(axis=0), standard_pure_resLSTM_dVdt_r2.max(axis=0), standard_pao_model_dVdt_r2.max(axis=0), standard_convnext_dVdt_r2.max(axis=0), standard_encdec_lstm_dVdt_r2.max(axis=0)], axis = 0)\n",
    "    }\n",
    "    config_dVdt_r2 = {\n",
    "        'min': np.stack([config_unet_dVdt_r2.min(axis=0), config_squeezeformer_dVdt_r2.min(axis=0), config_pure_resLSTM_dVdt_r2.min(axis=0), config_pao_model_dVdt_r2.min(axis=0), config_convnext_dVdt_r2.min(axis=0), config_encdec_lstm_dVdt_r2.min(axis=0)], axis = 0),\n",
    "        'median': np.stack([np.median(config_unet_dVdt_r2, axis=0), np.median(config_squeezeformer_dVdt_r2, axis=0), np.median(config_pure_resLSTM_dVdt_r2, axis=0), np.median(config_pao_model_dVdt_r2, axis=0), np.median(config_convnext_dVdt_r2, axis=0), np.median(config_encdec_lstm_dVdt_r2, axis=0)], axis = 0),\n",
    "        'max': np.stack([config_unet_dVdt_r2.max(axis=0), config_squeezeformer_dVdt_r2.max(axis=0), config_pure_resLSTM_dVdt_r2.max(axis=0), config_pao_model_dVdt_r2.max(axis=0), config_convnext_dVdt_r2.max(axis=0), config_encdec_lstm_dVdt_r2.max(axis=0)], axis = 0)\n",
    "    }\n",
    "    standard_NETSW_r2 = {\n",
    "        'min': np.array([np.min(standard_unet_NETSW_r2), np.min(standard_squeezeformer_NETSW_r2), np.min(standard_pure_resLSTM_NETSW_r2), np.min(standard_pao_model_NETSW_r2), np.min(standard_convnext_NETSW_r2), np.min(standard_encdec_lstm_NETSW_r2)]),\n",
    "        'median': np.array([np.median(standard_unet_NETSW_r2), np.median(standard_squeezeformer_NETSW_r2), np.median(standard_pure_resLSTM_NETSW_r2), np.median(standard_pao_model_NETSW_r2), np.median(standard_convnext_NETSW_r2), np.median(standard_encdec_lstm_NETSW_r2)]),\n",
    "        'max': np.array([np.max(standard_unet_NETSW_r2), np.max(standard_squeezeformer_NETSW_r2), np.max(standard_pure_resLSTM_NETSW_r2), np.max(standard_pao_model_NETSW_r2), np.max(standard_convnext_NETSW_r2), np.max(standard_encdec_lstm_NETSW_r2)])\n",
    "    }\n",
    "    config_NETSW_r2 = {\n",
    "        'min': np.array([np.min(config_unet_NETSW_r2), np.min(config_squeezeformer_NETSW_r2), np.min(config_pure_resLSTM_NETSW_r2), np.min(config_pao_model_NETSW_r2), np.min(config_convnext_NETSW_r2), np.min(config_encdec_lstm_NETSW_r2)]),\n",
    "        'median': np.array([np.median(config_unet_NETSW_r2), np.median(config_squeezeformer_NETSW_r2), np.median(config_pure_resLSTM_NETSW_r2), np.median(config_pao_model_NETSW_r2), np.median(config_convnext_NETSW_r2), np.median(config_encdec_lstm_NETSW_r2)]),\n",
    "        'max': np.array([np.max(config_unet_NETSW_r2), np.max(config_squeezeformer_NETSW_r2), np.max(config_pure_resLSTM_NETSW_r2), np.max(config_pao_model_NETSW_r2), np.max(config_convnext_NETSW_r2), np.max(config_encdec_lstm_NETSW_r2)])\n",
    "    }\n",
    "    standard_FLWDS_r2 = {\n",
    "        'min': np.array([np.min(standard_unet_FLWDS_r2), np.min(standard_squeezeformer_FLWDS_r2), np.min(standard_pure_resLSTM_FLWDS_r2), np.min(standard_pao_model_FLWDS_r2), np.min(standard_convnext_FLWDS_r2), np.min(standard_encdec_lstm_FLWDS_r2)]),\n",
    "        'median': np.array([np.median(standard_unet_FLWDS_r2), np.median(standard_squeezeformer_FLWDS_r2), np.median(standard_pure_resLSTM_FLWDS_r2), np.median(standard_pao_model_FLWDS_r2), np.median(standard_convnext_FLWDS_r2), np.median(standard_encdec_lstm_FLWDS_r2)]),\n",
    "        'max': np.array([np.max(standard_unet_FLWDS_r2), np.max(standard_squeezeformer_FLWDS_r2), np.max(standard_pure_resLSTM_FLWDS_r2), np.max(standard_pao_model_FLWDS_r2), np.max(standard_convnext_FLWDS_r2), np.max(standard_encdec_lstm_FLWDS_r2)])\n",
    "    }\n",
    "    config_FLWDS_r2 = {\n",
    "        'min': np.array([np.min(config_unet_FLWDS_r2), np.min(config_squeezeformer_FLWDS_r2), np.min(config_pure_resLSTM_FLWDS_r2), np.min(config_pao_model_FLWDS_r2), np.min(config_convnext_FLWDS_r2), np.min(config_encdec_lstm_FLWDS_r2)]),\n",
    "        'median': np.array([np.median(config_unet_FLWDS_r2), np.median(config_squeezeformer_FLWDS_r2), np.median(config_pure_resLSTM_FLWDS_r2), np.median(config_pao_model_FLWDS_r2), np.median(config_convnext_FLWDS_r2), np.median(config_encdec_lstm_FLWDS_r2)]),\n",
    "        'max': np.array([np.max(config_unet_FLWDS_r2), np.max(config_squeezeformer_FLWDS_r2), np.max(config_pure_resLSTM_FLWDS_r2), np.max(config_pao_model_FLWDS_r2), np.max(config_convnext_FLWDS_r2), np.max(config_encdec_lstm_FLWDS_r2)])\n",
    "    }\n",
    "    standard_PRECSC_r2 = {\n",
    "        'min': np.array([np.min(standard_unet_PRECSC_r2), np.min(standard_squeezeformer_PRECSC_r2), np.min(standard_pure_resLSTM_PRECSC_r2), np.min(standard_pao_model_PRECSC_r2), np.min(standard_convnext_PRECSC_r2), np.min(standard_encdec_lstm_PRECSC_r2)]),\n",
    "        'median': np.array([np.median(standard_unet_PRECSC_r2), np.median(standard_squeezeformer_PRECSC_r2), np.median(standard_pure_resLSTM_PRECSC_r2), np.median(standard_pao_model_PRECSC_r2), np.median(standard_convnext_PRECSC_r2), np.median(standard_encdec_lstm_PRECSC_r2)]),\n",
    "        'max': np.array([np.max(standard_unet_PRECSC_r2), np.max(standard_squeezeformer_PRECSC_r2), np.max(standard_pure_resLSTM_PRECSC_r2), np.max(standard_pao_model_PRECSC_r2), np.max(standard_convnext_PRECSC_r2), np.max(standard_encdec_lstm_PRECSC_r2)])\n",
    "    }\n",
    "    config_PRECSC_r2 = {\n",
    "        'min': np.array([np.min(config_unet_PRECSC_r2), np.min(config_squeezeformer_PRECSC_r2), np.min(config_pure_resLSTM_PRECSC_r2), np.min(config_pao_model_PRECSC_r2), np.min(config_convnext_PRECSC_r2), np.min(config_encdec_lstm_PRECSC_r2)]),\n",
    "        'median': np.array([np.median(config_unet_PRECSC_r2), np.median(config_squeezeformer_PRECSC_r2), np.median(config_pure_resLSTM_PRECSC_r2), np.median(config_pao_model_PRECSC_r2), np.median(config_convnext_PRECSC_r2), np.median(config_encdec_lstm_PRECSC_r2)]),\n",
    "        'max': np.array([np.max(config_unet_PRECSC_r2), np.max(config_squeezeformer_PRECSC_r2), np.max(config_pure_resLSTM_PRECSC_r2), np.max(config_pao_model_PRECSC_r2), np.max(config_convnext_PRECSC_r2), np.max(config_encdec_lstm_PRECSC_r2)])\n",
    "    }\n",
    "    standard_PRECC_r2 = {\n",
    "        'min': np.array([np.min(standard_unet_PRECC_r2), np.min(standard_squeezeformer_PRECC_r2), np.min(standard_pure_resLSTM_PRECC_r2), np.min(standard_pao_model_PRECC_r2), np.min(standard_convnext_PRECC_r2), np.min(standard_encdec_lstm_PRECC_r2)]),\n",
    "        'median': np.array([np.median(standard_unet_PRECC_r2), np.median(standard_squeezeformer_PRECC_r2), np.median(standard_pure_resLSTM_PRECC_r2), np.median(standard_pao_model_PRECC_r2), np.median(standard_convnext_PRECC_r2), np.median(standard_encdec_lstm_PRECC_r2)]),\n",
    "        'max': np.array([np.max(standard_unet_PRECC_r2), np.max(standard_squeezeformer_PRECC_r2), np.max(standard_pure_resLSTM_PRECC_r2), np.max(standard_pao_model_PRECC_r2), np.max(standard_convnext_PRECC_r2), np.max(standard_encdec_lstm_PRECC_r2)])\n",
    "    }\n",
    "    config_PRECC_r2 = {\n",
    "        'min': np.array([np.min(config_unet_PRECC_r2), np.min(config_squeezeformer_PRECC_r2), np.min(config_pure_resLSTM_PRECC_r2), np.min(config_pao_model_PRECC_r2), np.min(config_convnext_PRECC_r2), np.min(config_encdec_lstm_PRECC_r2)]),\n",
    "        'median': np.array([np.median(config_unet_PRECC_r2), np.median(config_squeezeformer_PRECC_r2), np.median(config_pure_resLSTM_PRECC_r2), np.median(config_pao_model_PRECC_r2), np.median(config_convnext_PRECC_r2), np.median(config_encdec_lstm_PRECC_r2)]),\n",
    "        'max': np.array([np.max(config_unet_PRECC_r2), np.max(config_squeezeformer_PRECC_r2), np.max(config_pure_resLSTM_PRECC_r2), np.max(config_pao_model_PRECC_r2), np.max(config_convnext_PRECC_r2), np.max(config_encdec_lstm_PRECC_r2)])\n",
    "    }\n",
    "    standard_SOLS_r2 = {\n",
    "        'min': np.array([np.min(standard_unet_SOLS_r2), np.min(standard_squeezeformer_SOLS_r2), np.min(standard_pure_resLSTM_SOLS_r2), np.min(standard_pao_model_SOLS_r2), np.min(standard_convnext_SOLS_r2), np.min(standard_encdec_lstm_SOLS_r2)]),\n",
    "        'median': np.array([np.median(standard_unet_SOLS_r2), np.median(standard_squeezeformer_SOLS_r2), np.median(standard_pure_resLSTM_SOLS_r2), np.median(standard_pao_model_SOLS_r2), np.median(standard_convnext_SOLS_r2), np.median(standard_encdec_lstm_SOLS_r2)]),\n",
    "        'max': np.array([np.max(standard_unet_SOLS_r2), np.max(standard_squeezeformer_SOLS_r2), np.max(standard_pure_resLSTM_SOLS_r2), np.max(standard_pao_model_SOLS_r2), np.max(standard_convnext_SOLS_r2), np.max(standard_encdec_lstm_SOLS_r2)])\n",
    "    }\n",
    "    config_SOLS_r2 = {\n",
    "        'min': np.array([np.min(config_unet_SOLS_r2), np.min(config_squeezeformer_SOLS_r2), np.min(config_pure_resLSTM_SOLS_r2), np.min(config_pao_model_SOLS_r2), np.min(config_convnext_SOLS_r2), np.min(config_encdec_lstm_SOLS_r2)]),\n",
    "        'median': np.array([np.median(config_unet_SOLS_r2), np.median(config_squeezeformer_SOLS_r2), np.median(config_pure_resLSTM_SOLS_r2), np.median(config_pao_model_SOLS_r2), np.median(config_convnext_SOLS_r2), np.median(config_encdec_lstm_SOLS_r2)]),\n",
    "        'max': np.array([np.max(config_unet_SOLS_r2), np.max(config_squeezeformer_SOLS_r2), np.max(config_pure_resLSTM_SOLS_r2), np.max(config_pao_model_SOLS_r2), np.max(config_convnext_SOLS_r2), np.max(config_encdec_lstm_SOLS_r2)])\n",
    "    }\n",
    "    standard_SOLL_r2 = {\n",
    "        'min': np.array([np.min(standard_unet_SOLL_r2), np.min(standard_squeezeformer_SOLL_r2), np.min(standard_pure_resLSTM_SOLL_r2), np.min(standard_pao_model_SOLL_r2), np.min(standard_convnext_SOLL_r2), np.min(standard_encdec_lstm_SOLL_r2)]),\n",
    "        'median': np.array([np.median(standard_unet_SOLL_r2), np.median(standard_squeezeformer_SOLL_r2), np.median(standard_pure_resLSTM_SOLL_r2), np.median(standard_pao_model_SOLL_r2), np.median(standard_convnext_SOLL_r2), np.median(standard_encdec_lstm_SOLL_r2)]),\n",
    "        'max': np.array([np.max(standard_unet_SOLL_r2), np.max(standard_squeezeformer_SOLL_r2), np.max(standard_pure_resLSTM_SOLL_r2), np.max(standard_pao_model_SOLL_r2), np.max(standard_convnext_SOLL_r2), np.max(standard_encdec_lstm_SOLL_r2)])\n",
    "    }\n",
    "    config_SOLL_r2 = {\n",
    "        'min': np.array([np.min(config_unet_SOLL_r2), np.min(config_squeezeformer_SOLL_r2), np.min(config_pure_resLSTM_SOLL_r2), np.min(config_pao_model_SOLL_r2), np.min(config_convnext_SOLL_r2), np.min(config_encdec_lstm_SOLL_r2)]),\n",
    "        'median': np.array([np.median(config_unet_SOLL_r2), np.median(config_squeezeformer_SOLL_r2), np.median(config_pure_resLSTM_SOLL_r2), np.median(config_pao_model_SOLL_r2), np.median(config_convnext_SOLL_r2), np.median(config_encdec_lstm_SOLL_r2)]),\n",
    "        'max': np.array([np.max(config_unet_SOLL_r2), np.max(config_squeezeformer_SOLL_r2), np.max(config_pure_resLSTM_SOLL_r2), np.max(config_pao_model_SOLL_r2), np.max(config_convnext_SOLL_r2), np.max(config_encdec_lstm_SOLL_r2)])\n",
    "    }\n",
    "    standard_SOLSD_r2 = {\n",
    "        'min': np.array([np.min(standard_unet_SOLSD_r2), np.min(standard_squeezeformer_SOLSD_r2), np.min(standard_pure_resLSTM_SOLSD_r2), np.min(standard_pao_model_SOLSD_r2), np.min(standard_convnext_SOLSD_r2), np.min(standard_encdec_lstm_SOLSD_r2)]),\n",
    "        'median': np.array([np.median(standard_unet_SOLSD_r2), np.median(standard_squeezeformer_SOLSD_r2), np.median(standard_pure_resLSTM_SOLSD_r2), np.median(standard_pao_model_SOLSD_r2), np.median(standard_convnext_SOLSD_r2), np.median(standard_encdec_lstm_SOLSD_r2)]),\n",
    "        'max': np.array([np.max(standard_unet_SOLSD_r2), np.max(standard_squeezeformer_SOLSD_r2), np.max(standard_pure_resLSTM_SOLSD_r2), np.max(standard_pao_model_SOLSD_r2), np.max(standard_convnext_SOLSD_r2), np.max(standard_encdec_lstm_SOLSD_r2)])\n",
    "    }\n",
    "    config_SOLSD_r2 = {\n",
    "        'min': np.array([np.min(config_unet_SOLSD_r2), np.min(config_squeezeformer_SOLSD_r2), np.min(config_pure_resLSTM_SOLSD_r2), np.min(config_pao_model_SOLSD_r2), np.min(config_convnext_SOLSD_r2), np.min(config_encdec_lstm_SOLSD_r2)]),\n",
    "        'median': np.array([np.median(config_unet_SOLSD_r2), np.median(config_squeezeformer_SOLSD_r2), np.median(config_pure_resLSTM_SOLSD_r2), np.median(config_pao_model_SOLSD_r2), np.median(config_convnext_SOLSD_r2), np.median(config_encdec_lstm_SOLSD_r2)]),\n",
    "        'max': np.array([np.max(config_unet_SOLSD_r2), np.max(config_squeezeformer_SOLSD_r2), np.max(config_pure_resLSTM_SOLSD_r2), np.max(config_pao_model_SOLSD_r2), np.max(config_convnext_SOLSD_r2), np.max(config_encdec_lstm_SOLSD_r2)])\n",
    "    }\n",
    "    standard_SOLLD_r2 = {\n",
    "        'min': np.array([np.min(standard_unet_SOLLD_r2), np.min(standard_squeezeformer_SOLLD_r2), np.min(standard_pure_resLSTM_SOLLD_r2), np.min(standard_pao_model_SOLLD_r2), np.min(standard_convnext_SOLLD_r2), np.min(standard_encdec_lstm_SOLLD_r2)]),\n",
    "        'median': np.array([np.median(standard_unet_SOLLD_r2), np.median(standard_squeezeformer_SOLLD_r2), np.median(standard_pure_resLSTM_SOLLD_r2), np.median(standard_pao_model_SOLLD_r2), np.median(standard_convnext_SOLLD_r2), np.median(standard_encdec_lstm_SOLLD_r2)]),\n",
    "        'max': np.array([np.max(standard_unet_SOLLD_r2), np.max(standard_squeezeformer_SOLLD_r2), np.max(standard_pure_resLSTM_SOLLD_r2), np.max(standard_pao_model_SOLLD_r2), np.max(standard_convnext_SOLLD_r2), np.max(standard_encdec_lstm_SOLLD_r2)])\n",
    "    }\n",
    "    config_SOLLD_r2 = {\n",
    "        'min': np.array([np.min(config_unet_SOLLD_r2), np.min(config_squeezeformer_SOLLD_r2), np.min(config_pure_resLSTM_SOLLD_r2), np.min(config_pao_model_SOLLD_r2), np.min(config_convnext_SOLLD_r2), np.min(config_encdec_lstm_SOLLD_r2)]),\n",
    "        'median': np.array([np.median(config_unet_SOLLD_r2), np.median(config_squeezeformer_SOLLD_r2), np.median(config_pure_resLSTM_SOLLD_r2), np.median(config_pao_model_SOLLD_r2), np.median(config_convnext_SOLLD_r2), np.median(config_encdec_lstm_SOLLD_r2)]),\n",
    "        'max': np.array([np.max(config_unet_SOLLD_r2), np.max(config_squeezeformer_SOLLD_r2), np.max(config_pure_resLSTM_SOLLD_r2), np.max(config_pao_model_SOLLD_r2), np.max(config_convnext_SOLLD_r2), np.max(config_encdec_lstm_SOLLD_r2)])\n",
    "    }\n",
    "\n",
    "    sigma_pressure_levels = data_v2_rh_mc.grid_info['lev'].values\n",
    "    models = ['U-Net', 'Squeezeformer', 'Pure ResLSTM', 'Pao Model', 'ConvNeXt', 'Encoder-Decoder LSTM']\n",
    "    colors = ['green', 'purple', 'blue', 'red', 'gold', 'orange']\n",
    "\n",
    "    # Six variables for the six profile panels:\n",
    "    standard_r2_profiles = {\n",
    "        r'(a) $R^2$: dT/dt': standard_dTdt_r2, \n",
    "        r'(b) $R^2$: dQ$_v$/dt': standard_dQvdt_r2, \n",
    "        r'(c) $R^2$: dQ$_l$/dt': standard_dQldt_r2,\n",
    "        r'(d) $R^2$: dQ$_i$/dt': standard_dQidt_r2, \n",
    "        r'(e) $R^2$: dU/dt': standard_dUdt_r2, \n",
    "        r'(f) $R^2$: dV/dt': standard_dVdt_r2\n",
    "    }\n",
    "    config_r2_profiles = {\n",
    "        r'(a) $R^2$: dT/dt': config_dTdt_r2, \n",
    "        r'(b) $R^2$: dQ$_v$/dt': config_dQvdt_r2, \n",
    "        r'(c) $R^2$: dQ$_l$/dt': config_dQldt_r2,\n",
    "        r'(d) $R^2$: dQ$_i$/dt': config_dQidt_r2, \n",
    "        r'(e) $R^2$: dU/dt': config_dUdt_r2, \n",
    "        r'(f) $R^2$: dV/dt': config_dVdt_r2\n",
    "    }\n",
    "    standard_r2_scalars = {\n",
    "        'NETSW': standard_NETSW_r2,\n",
    "        'FLWDS': standard_FLWDS_r2,\n",
    "        'PRECSC': standard_PRECSC_r2,\n",
    "        'PRECC': standard_PRECC_r2,\n",
    "        'SOLS': standard_SOLS_r2,\n",
    "        'SOLL': standard_SOLL_r2,\n",
    "        'SOLSD': standard_SOLSD_r2,\n",
    "        'SOLLD': standard_SOLLD_r2\n",
    "    }\n",
    "    config_r2_scalars = {\n",
    "        'NETSW': config_NETSW_r2,\n",
    "        'FLWDS': config_FLWDS_r2,\n",
    "        'PRECSC': config_PRECSC_r2,\n",
    "        'PRECC': config_PRECC_r2,\n",
    "        'SOLS': config_SOLS_r2,\n",
    "        'SOLL': config_SOLL_r2,\n",
    "        'SOLSD': config_SOLSD_r2,\n",
    "        'SOLLD': config_SOLLD_r2\n",
    "    }\n",
    "    \n",
    "    # --------------------------\n",
    "    # 2) Set up the figure\n",
    "    # --------------------------\n",
    "    fig = plt.figure(figsize=(12, 10))\n",
    "    gs = gridspec.GridSpec(3, 3, height_ratios=[1, 1, 0.7], hspace=0.3, wspace=0.2)\n",
    "    \n",
    "    # Titles for the six profile panels\n",
    "    for idx, var in enumerate(standard_r2_profiles.keys()):\n",
    "        row = idx // 3\n",
    "        col = idx % 3\n",
    "        ax = fig.add_subplot(gs[row, col])\n",
    "        \n",
    "        # plot each model's profile\n",
    "        for m, model in enumerate(models):\n",
    "            ax.fill_betweenx(\n",
    "                data_v2_rh_mc.grid_info['lev'],  # y-axis (pressure levels)\n",
    "                standard_r2_profiles[var]['min'][m],      # lower bound (min profile)\n",
    "                standard_r2_profiles[var]['max'][m],      # upper bound (max profile)\n",
    "                color=colors[m],                 # color for the model\n",
    "                alpha=0.2,\n",
    "                hatch = '/',\n",
    "                zorder=1                        # transparency for the filled area\n",
    "            )\n",
    "            ax.plot(standard_r2_profiles[var]['median'][m], data_v2_rh_mc.grid_info['lev'],\n",
    "                    color=colors[m], alpha = .8, linewidth = .64, linestyle = '--', zorder = 1)\n",
    "            ax.fill_betweenx(\n",
    "                data_v2_rh_mc.grid_info['lev'],  # y-axis (pressure levels)\n",
    "                config_r2_profiles[var]['min'][m],      # lower bound (min profile)\n",
    "                config_r2_profiles[var]['max'][m],      # upper bound (max profile)\n",
    "                color=colors[m],                 # color for the model\n",
    "                alpha=0.4,\n",
    "                zorder=2                        # transparency for the filled area\n",
    "            )\n",
    "            ax.plot(config_r2_profiles[var]['median'][m], data_v2_rh_mc.grid_info['lev'],\n",
    "                    color=colors[m], label=model, alpha = 1, linewidth = .64, zorder = 2)\n",
    "\n",
    "\n",
    "        ax.set_xlim(0, 1)\n",
    "        ax.set_ylim(1000, 0)         # invert y\n",
    "        ax.set_yticks([0, 200, 400, 600, 800, 1000])\n",
    "        if col == 0:\n",
    "            ax.set_ylabel(\"Hybrid pressure (hPa)\")\n",
    "        else:\n",
    "            ax.set_yticklabels([])   # no y\u2010labels on inner panels\n",
    "        \n",
    "        ax.set_title(var)\n",
    "        ax.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "    \n",
    "    \n",
    "    # --------------------------\n",
    "    # 3) The bottom bar\u2010chart\n",
    "    # --------------------------\n",
    "    axb = fig.add_subplot(gs[2, :])\n",
    "\n",
    "    r2_scalars_labels = list(standard_r2_scalars.keys())\n",
    "    num_vars = len(r2_scalars_labels)\n",
    "    num_models = len(models)\n",
    "\n",
    "    # Prepare data for plotting\n",
    "    # Each variable has an array of 6 values (one per model)\n",
    "    standard_r2_scalars_min = np.array([standard_r2_scalars[var]['min'] for var in r2_scalars_labels])  # shape (num_vars, num_models)\n",
    "    standard_r2_scalars_median = np.array([standard_r2_scalars[var]['median'] for var in r2_scalars_labels])  # shape (num_vars, num_models)\n",
    "    standard_r2_scalars_max = np.array([standard_r2_scalars[var]['max'] for var in r2_scalars_labels])  # shape (num_vars, num_models)\n",
    "\n",
    "    config_r2_scalars_min = np.array([config_r2_scalars[var]['min'] for var in r2_scalars_labels])  # shape (num_vars, num_models)\n",
    "    config_r2_scalars_median = np.array([config_r2_scalars[var]['median'] for var in r2_scalars_labels])  # shape (num_vars, num_models)\n",
    "    config_r2_scalars_max = np.array([config_r2_scalars[var]['max'] for var in r2_scalars_labels])  # shape (num_vars, num_models)\n",
    "\n",
    "    bar_width = 0.12\n",
    "    indices = np.arange(num_vars)\n",
    "\n",
    "\n",
    "    for i in range(num_models):\n",
    "        y = config_r2_scalars_median[:, i]\n",
    "        err_high = config_r2_scalars_max[:, i] - y\n",
    "        err_low = y - config_r2_scalars_min[:, i]\n",
    "        y_err = np.vstack([err_low, err_high])\n",
    "        axb.bar(indices + i * bar_width, \n",
    "                y, \n",
    "                bar_width, \n",
    "                label=models[i], \n",
    "                color=colors[i], \n",
    "                alpha = .4, \n",
    "                yerr = y_err, \n",
    "                capsize = 1,\n",
    "                error_kw = dict(elinewidth=4, ecolor = colors[i], alpha=1.0),\n",
    "                zorder = 1)\n",
    "    for i in range(num_models):\n",
    "        y = standard_r2_scalars_median[:, i]\n",
    "        err_high = standard_r2_scalars_max[:, i] - y\n",
    "        err_low = y - standard_r2_scalars_min[:, i]\n",
    "        y_err = np.vstack([err_low, err_high])\n",
    "        axb.bar(indices + i * bar_width, \n",
    "                y, \n",
    "                bar_width, \n",
    "                color=colors[i], \n",
    "                alpha = .4, \n",
    "                yerr = y_err, \n",
    "                capsize = 1,\n",
    "                error_kw = dict(elinewidth=4, ecolor = colors[i], alpha=1.0),\n",
    "                edgecolor = 'grey',\n",
    "                hatch = '///',\n",
    "                zorder = 2)\n",
    "\n",
    "    # Labels and title\n",
    "    axb.set_xticks(indices + bar_width * (num_models - 1) / 2)\n",
    "    axb.set_xticklabels(r2_scalars_labels)\n",
    "    axb.set_ylim(0, 1.05)\n",
    "    axb.set_ylabel(r'$R^2$')\n",
    "    axb.set_title('(g) Fluxes')\n",
    "\n",
    "    # Add horizontal grid lines for better readability\n",
    "    axb.yaxis.grid(True, linestyle='--', alpha=0.7)\n",
    "    leg = axb.legend(loc='lower left', ncol=2, frameon=True)\n",
    "    for lh in leg.legend_handles:\n",
    "        lh.set_alpha(1.0)\n",
    "\n",
    "    fig.suptitle(f\"Offline $R^2$ for each architecture (Standard vs. {config_names[config]} Configuration)\", y=0.95)\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(os.path.join(save_path, f'offline_r2_lines_standard_vs_{config}.png'), dpi=300, bbox_inches='tight')\n",
    "    if show:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b346edd8",
   "metadata": {},
   "source": [
    "## Figure 2 (Offline R Squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0898acfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_offline_R2_lines_standard_vs_config(config='v6', show=True, save_path=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839066c9",
   "metadata": {},
   "source": [
    "## Figure S1 (Offline R Squared Standard vs. Confidence Loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0936906",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_offline_R2_lines_standard_vs_config(config='conf_loss', show=True, save_path=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd78e5f7",
   "metadata": {},
   "source": [
    "## Figure S2 (Offline R Squared Standard vs. Difference Loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3449f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_offline_R2_lines_standard_vs_config(config='diff_loss', show=True, save_path=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20b7a9c",
   "metadata": {},
   "source": [
    "## Figure S3 (Offline R Squared Standard vs. Multirepresentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4367b2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_offline_R2_lines_standard_vs_config(config='multirep', show=True, save_path=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753f981b",
   "metadata": {},
   "outputs": [],
   "source": [
    "online_var_settings.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11caaee1",
   "metadata": {},
   "source": [
    "## Figure S4 (Offline R Squared Standard vs. Hu et al. 2025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092d1fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_offline_R2_lines_huetal_vs_config(config = 'v6', show = True, save_path = None):\n",
    "    assert config in ['conf_loss', 'diff_loss', 'multirep', 'v6']\n",
    "    if config == 'conf_loss':\n",
    "        config_r2 = conf_loss_r2_dict\n",
    "    elif config == 'diff_loss':\n",
    "        config_r2 = diff_loss_r2_dict\n",
    "    elif config == 'multirep':\n",
    "        config_r2 = multirep_r2_dict\n",
    "    elif config == 'v6':\n",
    "        config_r2 = v6_r2_dict\n",
    "\n",
    "    huetal2025_dTdt_r2 = huetal2025_r2[:,:60]\n",
    "\n",
    "    config_unet_dTdt_r2 = np.stack([config_r2['unet'][seed][0][:60] for seed in seeds])\n",
    "    config_squeezeformer_dTdt_r2 = np.stack([config_r2['squeezeformer'][seed][0][:60] for seed in seeds])\n",
    "    config_pure_resLSTM_dTdt_r2 = np.stack([config_r2['pure_resLSTM'][seed][0][:60] for seed in seeds])\n",
    "    config_pao_model_dTdt_r2 = np.stack([config_r2['pao_model'][seed][0][:60] for seed in seeds])\n",
    "    config_convnext_dTdt_r2 = np.stack([config_r2['convnext'][seed][0][:60] for seed in seeds])\n",
    "    config_encdec_lstm_dTdt_r2 = np.stack([config_r2['encdec_lstm'][seed][0][:60] for seed in seeds])\n",
    "\n",
    "    huetal2025_dQvdt_r2 = huetal2025_r2[:,60:120]\n",
    "\n",
    "    config_unet_dQvdt_r2 = np.stack([config_r2['unet'][seed][0][60:120] for seed in seeds])\n",
    "    config_squeezeformer_dQvdt_r2 = np.stack([config_r2['squeezeformer'][seed][0][60:120] for seed in seeds])\n",
    "    config_pure_resLSTM_dQvdt_r2 = np.stack([config_r2['pure_resLSTM'][seed][0][60:120] for seed in seeds])\n",
    "    config_pao_model_dQvdt_r2 = np.stack([config_r2['pao_model'][seed][0][60:120] for seed in seeds])\n",
    "    config_convnext_dQvdt_r2 = np.stack([config_r2['convnext'][seed][0][60:120] for seed in seeds])\n",
    "    config_encdec_lstm_dQvdt_r2 = np.stack([config_r2['encdec_lstm'][seed][0][60:120] for seed in seeds])\n",
    "\n",
    "    huetal2025_dQldt_r2 = huetal2025_r2[:,120:180]\n",
    "\n",
    "    config_unet_dQldt_r2 = np.stack([config_r2['unet'][seed][0][120:180] for seed in seeds])\n",
    "    config_squeezeformer_dQldt_r2 = np.stack([config_r2['squeezeformer'][seed][0][120:180] for seed in seeds])\n",
    "    config_pure_resLSTM_dQldt_r2 = np.stack([config_r2['pure_resLSTM'][seed][0][120:180] for seed in seeds])\n",
    "    config_pao_model_dQldt_r2 = np.stack([config_r2['pao_model'][seed][0][120:180] for seed in seeds])\n",
    "    config_convnext_dQldt_r2 = np.stack([config_r2['convnext'][seed][0][120:180] for seed in seeds])\n",
    "    config_encdec_lstm_dQldt_r2 = np.stack([config_r2['encdec_lstm'][seed][0][120:180] for seed in seeds])\n",
    "\n",
    "    huetal2025_dQidt_r2 = huetal2025_r2[:,180:240]\n",
    "\n",
    "    config_unet_dQidt_r2 = np.stack([config_r2['unet'][seed][0][180:240] for seed in seeds])\n",
    "    config_squeezeformer_dQidt_r2 = np.stack([config_r2['squeezeformer'][seed][0][180:240] for seed in seeds])\n",
    "    config_pure_resLSTM_dQidt_r2 = np.stack([config_r2['pure_resLSTM'][seed][0][180:240] for seed in seeds])\n",
    "    config_pao_model_dQidt_r2 = np.stack([config_r2['pao_model'][seed][0][180:240] for seed in seeds])\n",
    "    config_convnext_dQidt_r2 = np.stack([config_r2['convnext'][seed][0][180:240] for seed in seeds])\n",
    "    config_encdec_lstm_dQidt_r2 = np.stack([config_r2['encdec_lstm'][seed][0][180:240] for seed in seeds])\n",
    "\n",
    "    huetal2025_dUdt_r2 = huetal2025_r2[:,240:300]\n",
    "\n",
    "    config_unet_dUdt_r2 = np.stack([config_r2['unet'][seed][0][240:300] for seed in seeds])\n",
    "    config_squeezeformer_dUdt_r2 = np.stack([config_r2['squeezeformer'][seed][0][240:300] for seed in seeds])\n",
    "    config_pure_resLSTM_dUdt_r2 = np.stack([config_r2['pure_resLSTM'][seed][0][240:300] for seed in seeds])\n",
    "    config_pao_model_dUdt_r2 = np.stack([config_r2['pao_model'][seed][0][240:300] for seed in seeds])\n",
    "    config_convnext_dUdt_r2 = np.stack([config_r2['convnext'][seed][0][240:300] for seed in seeds])\n",
    "    config_encdec_lstm_dUdt_r2 = np.stack([config_r2['encdec_lstm'][seed][0][240:300] for seed in seeds])\n",
    "\n",
    "    huetal2025_dVdt_r2 = huetal2025_r2[:,300:360]\n",
    "\n",
    "    config_unet_dVdt_r2 = np.stack([config_r2['unet'][seed][0][300:360] for seed in seeds])\n",
    "    config_squeezeformer_dVdt_r2 = np.stack([config_r2['squeezeformer'][seed][0][300:360] for seed in seeds])\n",
    "    config_pure_resLSTM_dVdt_r2 = np.stack([config_r2['pure_resLSTM'][seed][0][300:360] for seed in seeds])\n",
    "    config_pao_model_dVdt_r2 = np.stack([config_r2['pao_model'][seed][0][300:360] for seed in seeds])\n",
    "    config_convnext_dVdt_r2 = np.stack([config_r2['convnext'][seed][0][300:360] for seed in seeds])\n",
    "    config_encdec_lstm_dVdt_r2 = np.stack([config_r2['encdec_lstm'][seed][0][300:360] for seed in seeds])\n",
    "\n",
    "    huetal2025_NETSW_r2 = huetal2025_r2[:,360]\n",
    "\n",
    "    config_unet_NETSW_r2 = np.stack([config_r2['unet'][seed][0][360] for seed in seeds])\n",
    "    config_squeezeformer_NETSW_r2 = np.stack([config_r2['squeezeformer'][seed][0][360] for seed in seeds])\n",
    "    config_pure_resLSTM_NETSW_r2 = np.stack([config_r2['pure_resLSTM'][seed][0][360] for seed in seeds])\n",
    "    config_pao_model_NETSW_r2 = np.stack([config_r2['pao_model'][seed][0][360] for seed in seeds])\n",
    "    config_convnext_NETSW_r2 = np.stack([config_r2['convnext'][seed][0][360] for seed in seeds])\n",
    "    config_encdec_lstm_NETSW_r2 = np.stack([config_r2['encdec_lstm'][seed][0][360] for seed in seeds])\n",
    "\n",
    "    huetal2025_FLWDS_r2 = huetal2025_r2[:,361]\n",
    "\n",
    "    config_unet_FLWDS_r2 = np.stack([config_r2['unet'][seed][0][361] for seed in seeds])\n",
    "    config_squeezeformer_FLWDS_r2 = np.stack([config_r2['squeezeformer'][seed][0][361] for seed in seeds])\n",
    "    config_pure_resLSTM_FLWDS_r2 = np.stack([config_r2['pure_resLSTM'][seed][0][361] for seed in seeds])\n",
    "    config_pao_model_FLWDS_r2 = np.stack([config_r2['pao_model'][seed][0][361] for seed in seeds])\n",
    "    config_convnext_FLWDS_r2 = np.stack([config_r2['convnext'][seed][0][361] for seed in seeds])\n",
    "    config_encdec_lstm_FLWDS_r2 = np.stack([config_r2['encdec_lstm'][seed][0][361] for seed in seeds])\n",
    "\n",
    "    huetal2025_PRECSC_r2 = huetal2025_r2[:,362]\n",
    "\n",
    "    config_unet_PRECSC_r2 = np.stack([config_r2['unet'][seed][0][362] for seed in seeds])\n",
    "    config_squeezeformer_PRECSC_r2 = np.stack([config_r2['squeezeformer'][seed][0][362] for seed in seeds])\n",
    "    config_pure_resLSTM_PRECSC_r2 = np.stack([config_r2['pure_resLSTM'][seed][0][362] for seed in seeds])\n",
    "    config_pao_model_PRECSC_r2 = np.stack([config_r2['pao_model'][seed][0][362] for seed in seeds])\n",
    "    config_convnext_PRECSC_r2 = np.stack([config_r2['convnext'][seed][0][362] for seed in seeds])\n",
    "    config_encdec_lstm_PRECSC_r2 = np.stack([config_r2['encdec_lstm'][seed][0][362] for seed in seeds])\n",
    "\n",
    "    huetal2025_PRECC_r2 = huetal2025_r2[:,363]\n",
    "\n",
    "    config_unet_PRECC_r2 = np.stack([config_r2['unet'][seed][0][363] for seed in seeds])\n",
    "    config_squeezeformer_PRECC_r2 = np.stack([config_r2['squeezeformer'][seed][0][363] for seed in seeds])\n",
    "    config_pure_resLSTM_PRECC_r2 = np.stack([config_r2['pure_resLSTM'][seed][0][363] for seed in seeds])\n",
    "    config_pao_model_PRECC_r2 = np.stack([config_r2['pao_model'][seed][0][363] for seed in seeds])\n",
    "    config_convnext_PRECC_r2 = np.stack([config_r2['convnext'][seed][0][363] for seed in seeds])\n",
    "    config_encdec_lstm_PRECC_r2 = np.stack([config_r2['encdec_lstm'][seed][0][363] for seed in seeds])\n",
    "\n",
    "    huetal2025_SOLS_r2 = huetal2025_r2[:,364]\n",
    "\n",
    "    config_unet_SOLS_r2 = np.stack([config_r2['unet'][seed][0][364] for seed in seeds])\n",
    "    config_squeezeformer_SOLS_r2 = np.stack([config_r2['squeezeformer'][seed][0][364] for seed in seeds])\n",
    "    config_pure_resLSTM_SOLS_r2 = np.stack([config_r2['pure_resLSTM'][seed][0][364] for seed in seeds])\n",
    "    config_pao_model_SOLS_r2 = np.stack([config_r2['pao_model'][seed][0][364] for seed in seeds])\n",
    "    config_convnext_SOLS_r2 = np.stack([config_r2['convnext'][seed][0][364] for seed in seeds])\n",
    "    config_encdec_lstm_SOLS_r2 = np.stack([config_r2['encdec_lstm'][seed][0][364] for seed in seeds])\n",
    "\n",
    "    huetal2025_SOLL_r2 = huetal2025_r2[:,365]\n",
    "\n",
    "    config_unet_SOLL_r2 = np.stack([config_r2['unet'][seed][0][365] for seed in seeds])\n",
    "    config_squeezeformer_SOLL_r2 = np.stack([config_r2['squeezeformer'][seed][0][365] for seed in seeds])\n",
    "    config_pure_resLSTM_SOLL_r2 = np.stack([config_r2['pure_resLSTM'][seed][0][365] for seed in seeds])\n",
    "    config_pao_model_SOLL_r2 = np.stack([config_r2['pao_model'][seed][0][365] for seed in seeds])\n",
    "    config_convnext_SOLL_r2 = np.stack([config_r2['convnext'][seed][0][365] for seed in seeds])\n",
    "    config_encdec_lstm_SOLL_r2 = np.stack([config_r2['encdec_lstm'][seed][0][365] for seed in seeds])\n",
    "\n",
    "    huetal2025_SOLSD_r2 = huetal2025_r2[:,366]\n",
    "\n",
    "    config_unet_SOLSD_r2 = np.stack([config_r2['unet'][seed][0][366] for seed in seeds])\n",
    "    config_squeezeformer_SOLSD_r2 = np.stack([config_r2['squeezeformer'][seed][0][366] for seed in seeds])\n",
    "    config_pure_resLSTM_SOLSD_r2 = np.stack([config_r2['pure_resLSTM'][seed][0][366] for seed in seeds])\n",
    "    config_pao_model_SOLSD_r2 = np.stack([config_r2['pao_model'][seed][0][366] for seed in seeds])\n",
    "    config_convnext_SOLSD_r2 = np.stack([config_r2['convnext'][seed][0][366] for seed in seeds])\n",
    "    config_encdec_lstm_SOLSD_r2 = np.stack([config_r2['encdec_lstm'][seed][0][366] for seed in seeds])\n",
    "\n",
    "    huetal2025_SOLLD_r2 = huetal2025_r2[:,367]\n",
    "\n",
    "    config_unet_SOLLD_r2 = np.stack([config_r2['unet'][seed][0][367] for seed in seeds])\n",
    "    config_squeezeformer_SOLLD_r2 = np.stack([config_r2['squeezeformer'][seed][0][367] for seed in seeds])\n",
    "    config_pure_resLSTM_SOLLD_r2 = np.stack([config_r2['pure_resLSTM'][seed][0][367] for seed in seeds])\n",
    "    config_pao_model_SOLLD_r2 = np.stack([config_r2['pao_model'][seed][0][367] for seed in seeds])\n",
    "    config_convnext_SOLLD_r2 = np.stack([config_r2['convnext'][seed][0][367] for seed in seeds])\n",
    "    config_encdec_lstm_SOLLD_r2 = np.stack([config_r2['encdec_lstm'][seed][0][367] for seed in seeds])\n",
    "\n",
    "    config_dTdt_r2 = {\n",
    "        'min': np.stack([config_unet_dTdt_r2.min(axis=0), config_squeezeformer_dTdt_r2.min(axis=0), config_pure_resLSTM_dTdt_r2.min(axis=0), config_pao_model_dTdt_r2.min(axis=0), config_convnext_dTdt_r2.min(axis=0), config_encdec_lstm_dTdt_r2.min(axis=0)], axis = 0),\n",
    "        'median': np.stack([np.median(config_unet_dTdt_r2, axis=0), np.median(config_squeezeformer_dTdt_r2, axis=0), np.median(config_pure_resLSTM_dTdt_r2, axis=0), np.median(config_pao_model_dTdt_r2, axis=0), np.median(config_convnext_dTdt_r2, axis=0), np.median(config_encdec_lstm_dTdt_r2, axis=0)], axis = 0),\n",
    "        'max': np.stack([config_unet_dTdt_r2.max(axis=0), config_squeezeformer_dTdt_r2.max(axis=0), config_pure_resLSTM_dTdt_r2.max(axis=0), config_pao_model_dTdt_r2.max(axis=0), config_convnext_dTdt_r2.max(axis=0), config_encdec_lstm_dTdt_r2.max(axis=0)], axis = 0)\n",
    "    }\n",
    "    config_dQvdt_r2 = {\n",
    "        'min': np.stack([config_unet_dQvdt_r2.min(axis=0), config_squeezeformer_dQvdt_r2.min(axis=0), config_pure_resLSTM_dQvdt_r2.min(axis=0), config_pao_model_dQvdt_r2.min(axis=0), config_convnext_dQvdt_r2.min(axis=0), config_encdec_lstm_dQvdt_r2.min(axis=0)], axis = 0),\n",
    "        'median': np.stack([np.median(config_unet_dQvdt_r2, axis=0), np.median(config_squeezeformer_dQvdt_r2, axis=0), np.median(config_pure_resLSTM_dQvdt_r2, axis=0), np.median(config_pao_model_dQvdt_r2, axis=0), np.median(config_convnext_dQvdt_r2, axis=0), np.median(config_encdec_lstm_dQvdt_r2, axis=0)], axis = 0),\n",
    "        'max': np.stack([config_unet_dQvdt_r2.max(axis=0), config_squeezeformer_dQvdt_r2.max(axis=0), config_pure_resLSTM_dQvdt_r2.max(axis=0), config_pao_model_dQvdt_r2.max(axis=0), config_convnext_dQvdt_r2.max(axis=0), config_encdec_lstm_dQvdt_r2.max(axis=0)], axis = 0)\n",
    "    }\n",
    "    config_dQldt_r2 = {\n",
    "        'min': np.stack([config_unet_dQldt_r2.min(axis=0), config_squeezeformer_dQldt_r2.min(axis=0), config_pure_resLSTM_dQldt_r2.min(axis=0), config_pao_model_dQldt_r2.min(axis=0), config_convnext_dQldt_r2.min(axis=0), config_encdec_lstm_dQldt_r2.min(axis=0)], axis = 0),\n",
    "        'median': np.stack([np.median(config_unet_dQldt_r2, axis=0), np.median(config_squeezeformer_dQldt_r2, axis=0), np.median(config_pure_resLSTM_dQldt_r2, axis=0), np.median(config_pao_model_dQldt_r2, axis=0), np.median(config_convnext_dQldt_r2, axis=0), np.median(config_encdec_lstm_dQldt_r2, axis=0)], axis = 0),\n",
    "        'max': np.stack([config_unet_dQldt_r2.max(axis=0), config_squeezeformer_dQldt_r2.max(axis=0), config_pure_resLSTM_dQldt_r2.max(axis=0), config_pao_model_dQldt_r2.max(axis=0), config_convnext_dQldt_r2.max(axis=0), config_encdec_lstm_dQldt_r2.max(axis=0)], axis = 0)\n",
    "    }\n",
    "    config_dQidt_r2 = {\n",
    "        'min': np.stack([config_unet_dQidt_r2.min(axis=0), config_squeezeformer_dQidt_r2.min(axis=0), config_pure_resLSTM_dQidt_r2.min(axis=0), config_pao_model_dQidt_r2.min(axis=0), config_convnext_dQidt_r2.min(axis=0), config_encdec_lstm_dQidt_r2.min(axis=0)], axis = 0),\n",
    "        'median': np.stack([np.median(config_unet_dQidt_r2, axis=0), np.median(config_squeezeformer_dQidt_r2, axis=0), np.median(config_pure_resLSTM_dQidt_r2, axis=0), np.median(config_pao_model_dQidt_r2, axis=0), np.median(config_convnext_dQidt_r2, axis=0), np.median(config_encdec_lstm_dQidt_r2, axis=0)], axis = 0),\n",
    "        'max': np.stack([config_unet_dQidt_r2.max(axis=0), config_squeezeformer_dQidt_r2.max(axis=0), config_pure_resLSTM_dQidt_r2.max(axis=0), config_pao_model_dQidt_r2.max(axis=0), config_convnext_dQidt_r2.max(axis=0), config_encdec_lstm_dQidt_r2.max(axis=0)], axis = 0)\n",
    "    }\n",
    "    config_dUdt_r2 = {\n",
    "        'min': np.stack([config_unet_dUdt_r2.min(axis=0), config_squeezeformer_dUdt_r2.min(axis=0), config_pure_resLSTM_dUdt_r2.min(axis=0), config_pao_model_dUdt_r2.min(axis=0), config_convnext_dUdt_r2.min(axis=0), config_encdec_lstm_dUdt_r2.min(axis=0)], axis = 0),\n",
    "        'median': np.stack([np.median(config_unet_dUdt_r2, axis=0), np.median(config_squeezeformer_dUdt_r2, axis=0), np.median(config_pure_resLSTM_dUdt_r2, axis=0), np.median(config_pao_model_dUdt_r2, axis=0), np.median(config_convnext_dUdt_r2, axis=0), np.median(config_encdec_lstm_dUdt_r2, axis=0)], axis = 0),\n",
    "        'max': np.stack([config_unet_dUdt_r2.max(axis=0), config_squeezeformer_dUdt_r2.max(axis=0), config_pure_resLSTM_dUdt_r2.max(axis=0), config_pao_model_dUdt_r2.max(axis=0), config_convnext_dUdt_r2.max(axis=0), config_encdec_lstm_dUdt_r2.max(axis=0)], axis = 0)\n",
    "    }\n",
    "    config_dVdt_r2 = {\n",
    "        'min': np.stack([config_unet_dVdt_r2.min(axis=0), config_squeezeformer_dVdt_r2.min(axis=0), config_pure_resLSTM_dVdt_r2.min(axis=0), config_pao_model_dVdt_r2.min(axis=0), config_convnext_dVdt_r2.min(axis=0), config_encdec_lstm_dVdt_r2.min(axis=0)], axis = 0),\n",
    "        'median': np.stack([np.median(config_unet_dVdt_r2, axis=0), np.median(config_squeezeformer_dVdt_r2, axis=0), np.median(config_pure_resLSTM_dVdt_r2, axis=0), np.median(config_pao_model_dVdt_r2, axis=0), np.median(config_convnext_dVdt_r2, axis=0), np.median(config_encdec_lstm_dVdt_r2, axis=0)], axis = 0),\n",
    "        'max': np.stack([config_unet_dVdt_r2.max(axis=0), config_squeezeformer_dVdt_r2.max(axis=0), config_pure_resLSTM_dVdt_r2.max(axis=0), config_pao_model_dVdt_r2.max(axis=0), config_convnext_dVdt_r2.max(axis=0), config_encdec_lstm_dVdt_r2.max(axis=0)], axis = 0)\n",
    "    }\n",
    "    config_NETSW_r2 = {\n",
    "        'min': np.array([np.min(config_unet_NETSW_r2), np.min(config_squeezeformer_NETSW_r2), np.min(config_pure_resLSTM_NETSW_r2), np.min(config_pao_model_NETSW_r2), np.min(config_convnext_NETSW_r2), np.min(config_encdec_lstm_NETSW_r2)]),\n",
    "        'median': np.array([np.median(config_unet_NETSW_r2), np.median(config_squeezeformer_NETSW_r2), np.median(config_pure_resLSTM_NETSW_r2), np.median(config_pao_model_NETSW_r2), np.median(config_convnext_NETSW_r2), np.median(config_encdec_lstm_NETSW_r2)]),\n",
    "        'max': np.array([np.max(config_unet_NETSW_r2), np.max(config_squeezeformer_NETSW_r2), np.max(config_pure_resLSTM_NETSW_r2), np.max(config_pao_model_NETSW_r2), np.max(config_convnext_NETSW_r2), np.max(config_encdec_lstm_NETSW_r2)])\n",
    "    }\n",
    "    config_FLWDS_r2 = {\n",
    "        'min': np.array([np.min(config_unet_FLWDS_r2), np.min(config_squeezeformer_FLWDS_r2), np.min(config_pure_resLSTM_FLWDS_r2), np.min(config_pao_model_FLWDS_r2), np.min(config_convnext_FLWDS_r2), np.min(config_encdec_lstm_FLWDS_r2)]),\n",
    "        'median': np.array([np.median(config_unet_FLWDS_r2), np.median(config_squeezeformer_FLWDS_r2), np.median(config_pure_resLSTM_FLWDS_r2), np.median(config_pao_model_FLWDS_r2), np.median(config_convnext_FLWDS_r2), np.median(config_encdec_lstm_FLWDS_r2)]),\n",
    "        'max': np.array([np.max(config_unet_FLWDS_r2), np.max(config_squeezeformer_FLWDS_r2), np.max(config_pure_resLSTM_FLWDS_r2), np.max(config_pao_model_FLWDS_r2), np.max(config_convnext_FLWDS_r2), np.max(config_encdec_lstm_FLWDS_r2)])\n",
    "    }\n",
    "    config_PRECSC_r2 = {\n",
    "        'min': np.array([np.min(config_unet_PRECSC_r2), np.min(config_squeezeformer_PRECSC_r2), np.min(config_pure_resLSTM_PRECSC_r2), np.min(config_pao_model_PRECSC_r2), np.min(config_convnext_PRECSC_r2), np.min(config_encdec_lstm_PRECSC_r2)]),\n",
    "        'median': np.array([np.median(config_unet_PRECSC_r2), np.median(config_squeezeformer_PRECSC_r2), np.median(config_pure_resLSTM_PRECSC_r2), np.median(config_pao_model_PRECSC_r2), np.median(config_convnext_PRECSC_r2), np.median(config_encdec_lstm_PRECSC_r2)]),\n",
    "        'max': np.array([np.max(config_unet_PRECSC_r2), np.max(config_squeezeformer_PRECSC_r2), np.max(config_pure_resLSTM_PRECSC_r2), np.max(config_pao_model_PRECSC_r2), np.max(config_convnext_PRECSC_r2), np.max(config_encdec_lstm_PRECSC_r2)])\n",
    "    }\n",
    "    config_PRECC_r2 = {\n",
    "        'min': np.array([np.min(config_unet_PRECC_r2), np.min(config_squeezeformer_PRECC_r2), np.min(config_pure_resLSTM_PRECC_r2), np.min(config_pao_model_PRECC_r2), np.min(config_convnext_PRECC_r2), np.min(config_encdec_lstm_PRECC_r2)]),\n",
    "        'median': np.array([np.median(config_unet_PRECC_r2), np.median(config_squeezeformer_PRECC_r2), np.median(config_pure_resLSTM_PRECC_r2), np.median(config_pao_model_PRECC_r2), np.median(config_convnext_PRECC_r2), np.median(config_encdec_lstm_PRECC_r2)]),\n",
    "        'max': np.array([np.max(config_unet_PRECC_r2), np.max(config_squeezeformer_PRECC_r2), np.max(config_pure_resLSTM_PRECC_r2), np.max(config_pao_model_PRECC_r2), np.max(config_convnext_PRECC_r2), np.max(config_encdec_lstm_PRECC_r2)])\n",
    "    }\n",
    "    config_SOLS_r2 = {\n",
    "        'min': np.array([np.min(config_unet_SOLS_r2), np.min(config_squeezeformer_SOLS_r2), np.min(config_pure_resLSTM_SOLS_r2), np.min(config_pao_model_SOLS_r2), np.min(config_convnext_SOLS_r2), np.min(config_encdec_lstm_SOLS_r2)]),\n",
    "        'median': np.array([np.median(config_unet_SOLS_r2), np.median(config_squeezeformer_SOLS_r2), np.median(config_pure_resLSTM_SOLS_r2), np.median(config_pao_model_SOLS_r2), np.median(config_convnext_SOLS_r2), np.median(config_encdec_lstm_SOLS_r2)]),\n",
    "        'max': np.array([np.max(config_unet_SOLS_r2), np.max(config_squeezeformer_SOLS_r2), np.max(config_pure_resLSTM_SOLS_r2), np.max(config_pao_model_SOLS_r2), np.max(config_convnext_SOLS_r2), np.max(config_encdec_lstm_SOLS_r2)])\n",
    "    }\n",
    "    config_SOLL_r2 = {\n",
    "        'min': np.array([np.min(config_unet_SOLL_r2), np.min(config_squeezeformer_SOLL_r2), np.min(config_pure_resLSTM_SOLL_r2), np.min(config_pao_model_SOLL_r2), np.min(config_convnext_SOLL_r2), np.min(config_encdec_lstm_SOLL_r2)]),\n",
    "        'median': np.array([np.median(config_unet_SOLL_r2), np.median(config_squeezeformer_SOLL_r2), np.median(config_pure_resLSTM_SOLL_r2), np.median(config_pao_model_SOLL_r2), np.median(config_convnext_SOLL_r2), np.median(config_encdec_lstm_SOLL_r2)]),\n",
    "        'max': np.array([np.max(config_unet_SOLL_r2), np.max(config_squeezeformer_SOLL_r2), np.max(config_pure_resLSTM_SOLL_r2), np.max(config_pao_model_SOLL_r2), np.max(config_convnext_SOLL_r2), np.max(config_encdec_lstm_SOLL_r2)])\n",
    "    }\n",
    "    config_SOLSD_r2 = {\n",
    "        'min': np.array([np.min(config_unet_SOLSD_r2), np.min(config_squeezeformer_SOLSD_r2), np.min(config_pure_resLSTM_SOLSD_r2), np.min(config_pao_model_SOLSD_r2), np.min(config_convnext_SOLSD_r2), np.min(config_encdec_lstm_SOLSD_r2)]),\n",
    "        'median': np.array([np.median(config_unet_SOLSD_r2), np.median(config_squeezeformer_SOLSD_r2), np.median(config_pure_resLSTM_SOLSD_r2), np.median(config_pao_model_SOLSD_r2), np.median(config_convnext_SOLSD_r2), np.median(config_encdec_lstm_SOLSD_r2)]),\n",
    "        'max': np.array([np.max(config_unet_SOLSD_r2), np.max(config_squeezeformer_SOLSD_r2), np.max(config_pure_resLSTM_SOLSD_r2), np.max(config_pao_model_SOLSD_r2), np.max(config_convnext_SOLSD_r2), np.max(config_encdec_lstm_SOLSD_r2)])\n",
    "    }\n",
    "    config_SOLLD_r2 = {\n",
    "        'min': np.array([np.min(config_unet_SOLLD_r2), np.min(config_squeezeformer_SOLLD_r2), np.min(config_pure_resLSTM_SOLLD_r2), np.min(config_pao_model_SOLLD_r2), np.min(config_convnext_SOLLD_r2), np.min(config_encdec_lstm_SOLLD_r2)]),\n",
    "        'median': np.array([np.median(config_unet_SOLLD_r2), np.median(config_squeezeformer_SOLLD_r2), np.median(config_pure_resLSTM_SOLLD_r2), np.median(config_pao_model_SOLLD_r2), np.median(config_convnext_SOLLD_r2), np.median(config_encdec_lstm_SOLLD_r2)]),\n",
    "        'max': np.array([np.max(config_unet_SOLLD_r2), np.max(config_squeezeformer_SOLLD_r2), np.max(config_pure_resLSTM_SOLLD_r2), np.max(config_pao_model_SOLLD_r2), np.max(config_convnext_SOLLD_r2), np.max(config_encdec_lstm_SOLLD_r2)])\n",
    "    }\n",
    "\n",
    "    sigma_pressure_levels = data_v2_rh_mc.grid_info['lev'].values\n",
    "    models = ['U-Net', 'Squeezeformer', 'Pure ResLSTM', 'Pao Model', 'ConvNeXt', 'Encoder-Decoder LSTM']\n",
    "    colors = ['green', 'purple', 'blue', 'red', 'gold', 'orange']\n",
    "    # Six variables for the six profile panels:\n",
    "    huetal2025_r2_profiles = {\n",
    "        r'(a) $R^2$: dT/dt': huetal2025_dTdt_r2, \n",
    "        r'(b) $R^2$: dQ$_v$/dt': huetal2025_dQvdt_r2, \n",
    "        r'(c) $R^2$: dQ$_l$/dt': huetal2025_dQldt_r2,\n",
    "        r'(d) $R^2$: dQ$_i$/dt': huetal2025_dQidt_r2, \n",
    "        r'(e) $R^2$: dU/dt': huetal2025_dUdt_r2, \n",
    "        r'(f) $R^2$: dV/dt': huetal2025_dVdt_r2\n",
    "    }\n",
    "    config_r2_profiles = {\n",
    "        r'(a) $R^2$: dT/dt': config_dTdt_r2, \n",
    "        r'(b) $R^2$: dQ$_v$/dt': config_dQvdt_r2, \n",
    "        r'(c) $R^2$: dQ$_l$/dt': config_dQldt_r2,\n",
    "        r'(d) $R^2$: dQ$_i$/dt': config_dQidt_r2, \n",
    "        r'(e) $R^2$: dU/dt': config_dUdt_r2, \n",
    "        r'(f) $R^2$: dV/dt': config_dVdt_r2\n",
    "    }\n",
    "    huetal2025_r2_scalars = {\n",
    "        'NETSW': huetal2025_NETSW_r2,\n",
    "        'FLWDS': huetal2025_FLWDS_r2,\n",
    "        'PRECSC': huetal2025_PRECSC_r2,\n",
    "        'PRECC': huetal2025_PRECC_r2,\n",
    "        'SOLS': huetal2025_SOLS_r2,\n",
    "        'SOLL': huetal2025_SOLL_r2,\n",
    "        'SOLSD': huetal2025_SOLSD_r2,\n",
    "        'SOLLD': huetal2025_SOLLD_r2\n",
    "    }\n",
    "    config_r2_scalars = {\n",
    "        'NETSW': config_NETSW_r2,\n",
    "        'FLWDS': config_FLWDS_r2,\n",
    "        'PRECSC': config_PRECSC_r2,\n",
    "        'PRECC': config_PRECC_r2,\n",
    "        'SOLS': config_SOLS_r2,\n",
    "        'SOLL': config_SOLL_r2,\n",
    "        'SOLSD': config_SOLSD_r2,\n",
    "        'SOLLD': config_SOLLD_r2\n",
    "    }\n",
    "    \n",
    "    # --------------------------\n",
    "    # 2) Set up the figure\n",
    "    # --------------------------\n",
    "    fig = plt.figure(figsize=(12, 10))\n",
    "    gs = gridspec.GridSpec(3, 3, height_ratios=[1, 1, 0.7], hspace=0.3, wspace=0.2)\n",
    "    \n",
    "    # Titles for the six profile panels\n",
    "    for idx, var in enumerate(config_r2_profiles.keys()):\n",
    "        row = idx // 3\n",
    "        col = idx % 3\n",
    "        ax = fig.add_subplot(gs[row, col])\n",
    "        ax.plot(huetal2025_r2_profiles[var][0], data_v2_rh_mc.grid_info['lev'],\n",
    "                color='grey', alpha = .8, linewidth = .64, linestyle = '--', zorder = 1)\n",
    "        ax.plot(huetal2025_r2_profiles[var][1], data_v2_rh_mc.grid_info['lev'],\n",
    "                color='grey', alpha = .8, linewidth = .64, linestyle = '--', zorder = 1)\n",
    "        ax.plot(huetal2025_r2_profiles[var][2], data_v2_rh_mc.grid_info['lev'],\n",
    "                color='grey', alpha = .8, linewidth = .64, linestyle = '--', zorder = 1)\n",
    "        ax.plot(huetal2025_r2_profiles[var][3], data_v2_rh_mc.grid_info['lev'],\n",
    "                color='grey', label = 'Hu et al. 2025', alpha = .8, linewidth = .64, linestyle = '--', zorder = 1)\n",
    "        # plot each model's profile\n",
    "        for m, model in enumerate(models):\n",
    "            ax.fill_betweenx(\n",
    "                data_v2_rh_mc.grid_info['lev'],  # y-axis (pressure levels)\n",
    "                config_r2_profiles[var]['min'][m],      # lower bound (min profile)\n",
    "                config_r2_profiles[var]['max'][m],      # upper bound (max profile)\n",
    "                color=colors[m],                 # color for the model\n",
    "                alpha=0.4,\n",
    "                zorder=2                        # transparency for the filled area\n",
    "            )\n",
    "            ax.plot(config_r2_profiles[var]['median'][m], data_v2_rh_mc.grid_info['lev'],\n",
    "                    color=colors[m], label=model, alpha = 1, linewidth = .64, zorder = 2)\n",
    "\n",
    "\n",
    "        ax.set_xlim(0, 1)\n",
    "        ax.set_ylim(1000, 0)         # invert y\n",
    "        ax.set_yticks([0, 200, 400, 600, 800, 1000])\n",
    "        if col == 0:\n",
    "            ax.set_ylabel(\"Hybrid pressure (hPa)\")\n",
    "        else:\n",
    "            ax.set_yticklabels([])   # no y\u2010labels on inner panels\n",
    "        \n",
    "        ax.set_title(var)\n",
    "        ax.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "    \n",
    "    \n",
    "    # --------------------------\n",
    "    # 3) The bottom bar\u2010chart\n",
    "    # --------------------------\n",
    "    axb = fig.add_subplot(gs[2, :])\n",
    "\n",
    "    r2_scalars_labels = list(config_r2_scalars.keys())\n",
    "    num_vars = len(r2_scalars_labels)\n",
    "    num_models = len(models)\n",
    "\n",
    "    # Prepare data for plotting\n",
    "    # Each variable has an array of 6 values (one per model)\n",
    "    huetal2025_r2_scalars = np.array([huetal2025_r2_scalars[var] for var in r2_scalars_labels])  # shape (num_vars, num_models)\n",
    "\n",
    "    config_r2_scalars_min = np.array([config_r2_scalars[var]['min'] for var in r2_scalars_labels])  # shape (num_vars, num_models)\n",
    "    config_r2_scalars_median = np.array([config_r2_scalars[var]['median'] for var in r2_scalars_labels])  # shape (num_vars, num_models)\n",
    "    config_r2_scalars_max = np.array([config_r2_scalars[var]['max'] for var in r2_scalars_labels])  # shape (num_vars, num_models)\n",
    "\n",
    "    bar_width = 0.11\n",
    "    indices = np.arange(num_vars)\n",
    "\n",
    "    for i in range(num_models):\n",
    "        y = config_r2_scalars_median[:, i]\n",
    "        err_high = config_r2_scalars_max[:, i] - y\n",
    "        err_low = y - config_r2_scalars_min[:, i]\n",
    "        y_err = np.vstack([err_low, err_high])\n",
    "\n",
    "        axb.bar(indices + i * bar_width, \n",
    "                y, \n",
    "                bar_width, \n",
    "                label=models[i], \n",
    "                color=colors[i], \n",
    "                alpha = .6, \n",
    "                yerr = y_err, \n",
    "                capsize = 1,\n",
    "                error_kw = dict(elinewidth=4, ecolor = colors[i], alpha=1.0),\n",
    "                zorder = 2)\n",
    "    \n",
    "    huetal2025_y = np.mean(huetal2025_r2_scalars, axis = 1)\n",
    "    huetal2025_err_high = np.max(huetal2025_r2_scalars, axis = 1) - huetal2025_y\n",
    "    huetal2025_err_low = huetal2025_y - np.min(huetal2025_r2_scalars, axis = 1)\n",
    "    huetal2025_y_err = np.vstack([huetal2025_err_low, huetal2025_err_high])\n",
    "    axb.bar(indices + num_models * bar_width, \n",
    "            huetal2025_y, \n",
    "            bar_width,\n",
    "            label = 'Hu et al. 2025',\n",
    "            color='grey', \n",
    "            alpha = .6, \n",
    "            yerr = huetal2025_y_err, \n",
    "            capsize = 1,\n",
    "            error_kw = dict(elinewidth=4, ecolor = 'grey', alpha=1.0),\n",
    "            zorder = 1)\n",
    "\n",
    "    # Labels and title\n",
    "    axb.set_xticks(indices + bar_width * (num_models - 1) / 2)\n",
    "    axb.set_xticklabels(r2_scalars_labels)\n",
    "    axb.set_ylim(0, 1.05)\n",
    "    axb.set_ylabel(r'$R^2$')\n",
    "    axb.set_title('(g) Fluxes')\n",
    "\n",
    "    # Add horizontal grid lines for better readability\n",
    "    axb.yaxis.grid(True, linestyle='--', alpha=0.7)\n",
    "    leg = axb.legend(loc='lower left', ncol=2, frameon=True)\n",
    "    for lh in leg.legend_handles:\n",
    "        lh.set_alpha(1.0)\n",
    "\n",
    "    fig.suptitle(f\"Offline $R^2$ for each architecture (Hu et al. 2025 vs. {config_names[config]} Configuration)\", y=0.95)\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(os.path.join(save_path, f'offline_r2_lines_huetal2025_vs_{config}.png'), dpi=300, bbox_inches='tight')\n",
    "    if show:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa658151",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_offline_R2_lines_huetal_vs_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85c3247",
   "metadata": {},
   "source": [
    "## Figure 3 (Online Error and Stability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5287e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "online_var_settings_yticks = {\n",
    "    'T': {'ticks': [0.5, 1, 2, 5, 10, 20, 50, 100], 'labels': ['0.5', '1', '2', '5', '10', '20', '50', '100'], 'ylim_low': None, 'ylim_high': 100},\n",
    "    'Q': {'ticks': [0.1, 0.2, 0.5, 1, 2, 5, 10], 'labels': ['0.1', '0.2', '0.5', '1', '2', '5', '10'], 'ylim_low': None, 'ylim_high': 10},\n",
    "    'U': {'ticks': [1, 2, 5, 10, 20, 50], 'labels': ['1', '2', '5', '10', '20', '50'], 'ylim_low': None, 'ylim_high': 50},\n",
    "    'V': {'ticks': [1, 2, 5, 10, 20, 50], 'labels': ['1', '2', '5', '10', '20', '50'], 'ylim_low': None, 'ylim_high': 50},\n",
    "    'CLDLIQ': {'ticks': [2, 5, 10, 20, 50, 100, 200, 400], 'labels': ['2', '5', '10', '20', '50', '100', '200', '400'], 'ylim_low': None, 'ylim_high': 400},\n",
    "    'CLDICE': {'ticks': [2, 5, 10, 20, 50, 100, 200], 'labels': ['2', '5', '10', '20', '50', '100', '200'], 'ylim_low': None, 'ylim_high': 200},\n",
    "    'DTPHYS': {'ticks': [0.0001, 0.0002, 0.0005, .001], 'labels': ['0.0001', '0.0002', '0.0005', '0.001'], 'ylim_low': None, 'ylim_high': .001},\n",
    "    'DQ1PHYS': {'ticks': [0.0001, 0.0002, 0.0005, .001], 'labels': ['0.0001', '0.0002', '0.0005', '0.001'], 'ylim_low': None, 'ylim_high': .001},\n",
    "    'DQ2PHYS': {'ticks': [0.001, 0.002, 0.005, .01], 'labels': ['0.001', '0.002', '0.005', '0.01'], 'ylim_low': None, 'ylim_high': .01},\n",
    "    'DQ3PHYS': {'ticks': [0.001, 0.002, 0.005, .01], 'labels': ['0.001', '0.002', '0.005', '0.01'], 'ylim_low': None, 'ylim_high': .01},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0596f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_online_rmse_paper_comparison(var1 = 'T', var2 = 'Q', show = True, save_path = None):\n",
    "    num_years = 5\n",
    "    months = np.arange(1, num_years * 12 + 1)\n",
    "    fig, axes = plt.subplots(5, 2, figsize=(14, 14), constrained_layout = True)\n",
    "    axes[0,0].plot(months, mmf_1_5_year_rmse[var1], label='Internal Variability', color='black', marker='o', markersize = 3)\n",
    "    for model_name in model_names.keys():\n",
    "        axes[0,0].fill_between(\n",
    "            months,\n",
    "            np.nanmin(ds_nn_rmse_standard_5_year[var1][model_name], axis = 0),\n",
    "            np.nanmax(ds_nn_rmse_standard_5_year[var1][model_name], axis = 0),\n",
    "            color = color_dict[model_name],\n",
    "            alpha = 0.15\n",
    "        )\n",
    "        if np.sum(np.isnan(ds_nn_rmse_standard_5_year[var1][model_name])) != np.prod(ds_nn_rmse_standard_5_year[var1][model_name].shape):\n",
    "            abs_diff = np.nanmean(np.abs(ds_nn_rmse_standard_5_year[var1][model_name] - mmf_1_5_year_rmse[var1]), axis = 1)\n",
    "            line, = axes[0,0].plot(months, ds_nn_rmse_standard_5_year[var1][model_name][np.nanargmin(np.abs(abs_diff - np.nanmedian(abs_diff))),:], label = model_names[model_name], color = color_dict[model_name], linestyle = '--')\n",
    "        else:\n",
    "            line, = axes[0,0].plot(months, np.full(months.shape, np.nan), label = model_names[model_name], color = color_dict[model_name])\n",
    "    axes[0,0].set_xticks(np.arange(0,12*(num_years+1),12), np.arange(0,num_years+1)) \n",
    "    axes[0,0].set_yscale('log')\n",
    "    axes[0,0].set_yticks(online_var_settings_yticks[var1]['ticks'])\n",
    "    axes[0,0].set_ylim(online_var_settings_yticks[var1]['ylim_low'], online_var_settings_yticks[var1]['ylim_high'])\n",
    "    axes[0,0].set_yticklabels(online_var_settings_yticks[var1]['labels'])\n",
    "    axes[0,0].set_ylabel(f'Standard\\n{online_var_settings[var1][\"unit\"]}')\n",
    "    axes[0,0].set_title(f'{online_var_settings[var1][\"var_title\"]} ({online_var_settings[var1][\"unit\"]})')\n",
    "    handles_0_0, labels_0_0 = axes[0,0].get_legend_handles_labels()\n",
    "    for idx, model_name in enumerate(model_names.keys()):\n",
    "        num_survived = (~np.isnan(ds_nn_rmse_standard_5_year[var1][model_name][:,:len(months)]).any(axis=1)).sum()\n",
    "        labels_0_0[idx+1] = f'{labels_0_0[idx+1]} ({num_survived}/3 survived)'\n",
    "    axes[0,0].legend(handles = handles_0_0[:4], labels = labels_0_0[:4], loc = 'upper left', ncol = 1)\n",
    "    axes[0,0].grid(True)\n",
    "    axes[0,0].margins(x=0)\n",
    "\n",
    "    axes[0,1].plot(months, mmf_1_5_year_rmse[var2], label='Internal Variability', color='black', marker='o', markersize = 3)\n",
    "    for model_name in model_names.keys():\n",
    "        axes[0,1].fill_between(\n",
    "            months,\n",
    "            np.nanmin(ds_nn_rmse_standard_5_year[var2][model_name], axis = 0),\n",
    "            np.nanmax(ds_nn_rmse_standard_5_year[var2][model_name], axis = 0),\n",
    "            color = color_dict[model_name],\n",
    "            alpha = 0.15\n",
    "        )\n",
    "        if np.sum(np.isnan(ds_nn_rmse_standard_5_year[var2][model_name])) != np.prod(ds_nn_rmse_standard_5_year[var2][model_name].shape):\n",
    "            abs_diff = np.nanmean(np.abs(ds_nn_rmse_standard_5_year[var2][model_name] - mmf_1_5_year_rmse[var2]), axis = 1)\n",
    "            line, = axes[0,1].plot(months, ds_nn_rmse_standard_5_year[var2][model_name][np.nanargmin(np.abs(abs_diff - np.nanmedian(abs_diff))),:], label = model_names[model_name], color = color_dict[model_name], linestyle = '--')\n",
    "        else:\n",
    "            line, = axes[0,1].plot(months, np.full(months.shape, np.nan), label = model_names[model_name], color = color_dict[model_name])\n",
    "    axes[0,1].set_xticks(np.arange(0,12*(num_years+1),12), np.arange(0,num_years+1)) \n",
    "    axes[0,1].set_yscale('log')\n",
    "    axes[0,1].set_yticks(online_var_settings_yticks[var2]['ticks'])\n",
    "    axes[0,1].set_ylim(online_var_settings_yticks[var2]['ylim_low'], online_var_settings_yticks[var2]['ylim_high'])\n",
    "    axes[0,1].set_yticklabels(online_var_settings_yticks[var2]['labels'])\n",
    "    axes[0,1].set_ylabel(f'{online_var_settings[var2][\"unit\"]}')\n",
    "    axes[0,1].set_title(f'{online_var_settings[var2][\"var_title\"]} ({online_var_settings[var2][\"unit\"]})')\n",
    "    axes[0,1].legend(handles = handles_0_0[4:], labels = labels_0_0[4:], loc = 'upper left', ncol = 1)\n",
    "    axes[0,1].grid(True)\n",
    "    axes[0,1].margins(x=0)\n",
    "\n",
    "    axes[1,0].plot(months, mmf_1_5_year_rmse[var1], label='Internal Variability', color='black', marker='o', markersize = 3)\n",
    "    for model_name in model_names.keys():\n",
    "        axes[1,0].fill_between(\n",
    "            months,\n",
    "            np.nanmin(ds_nn_rmse_conf_loss_5_year[var1][model_name], axis = 0),\n",
    "            np.nanmax(ds_nn_rmse_conf_loss_5_year[var1][model_name], axis = 0),\n",
    "            color = color_dict[model_name],\n",
    "            alpha = 0.15\n",
    "        )\n",
    "        if np.sum(np.isnan(ds_nn_rmse_conf_loss_5_year[var1][model_name])) != np.prod(ds_nn_rmse_conf_loss_5_year[var1][model_name].shape):\n",
    "            abs_diff = np.nanmean(np.abs(ds_nn_rmse_conf_loss_5_year[var1][model_name] - mmf_1_5_year_rmse[var1]), axis = 1)\n",
    "            line, = axes[1,0].plot(months, ds_nn_rmse_conf_loss_5_year[var1][model_name][np.nanargmin(np.abs(abs_diff - np.nanmedian(abs_diff))),:], label = model_names[model_name], color = color_dict[model_name], linestyle = '--')\n",
    "        else:\n",
    "            line, = axes[1,0].plot(months, np.full(months.shape, np.nan), label = model_names[model_name], color = color_dict[model_name])\n",
    "    axes[1,0].set_xticks(np.arange(0,12*(num_years+1),12), np.arange(0,num_years+1)) \n",
    "    axes[1,0].set_yscale('log')\n",
    "    axes[1,0].set_yticks(online_var_settings_yticks[var1]['ticks'])\n",
    "    axes[1,0].set_ylim(online_var_settings_yticks[var1]['ylim_low'], online_var_settings_yticks[var1]['ylim_high'])\n",
    "    axes[1,0].set_yticklabels(online_var_settings_yticks[var1]['labels'])\n",
    "    axes[1,0].set_ylabel(f'Confidence Loss\\n{online_var_settings[var1][\"unit\"]}')\n",
    "    handles_1_0, labels_1_0 = axes[1,0].get_legend_handles_labels()\n",
    "    for idx, model_name in enumerate(model_names.keys()):\n",
    "        num_survived = (~np.isnan(ds_nn_rmse_conf_loss_5_year[var1][model_name][:,:len(months)]).any(axis=1)).sum()\n",
    "        labels_1_0[idx+1] = f'{labels_1_0[idx+1]} ({num_survived}/3 survived)'\n",
    "    axes[1,0].legend(handles = handles_1_0[:4], labels = labels_1_0[:4], loc = 'upper left', ncol = 1)\n",
    "    axes[1,0].grid(True)\n",
    "    axes[1,0].margins(x=0)\n",
    "\n",
    "    axes[1,1].plot(months, mmf_1_5_year_rmse[var2], label='Internal Variability', color='black', marker='o', markersize = 3)\n",
    "    for model_name in model_names.keys():\n",
    "        axes[1,1].fill_between(\n",
    "            months,\n",
    "            np.nanmin(ds_nn_rmse_conf_loss_5_year[var2][model_name], axis = 0),\n",
    "            np.nanmax(ds_nn_rmse_conf_loss_5_year[var2][model_name], axis = 0),\n",
    "            color = color_dict[model_name],\n",
    "            alpha = 0.15\n",
    "        )\n",
    "        if np.sum(np.isnan(ds_nn_rmse_conf_loss_5_year[var2][model_name])) != np.prod(ds_nn_rmse_conf_loss_5_year[var2][model_name].shape):\n",
    "            abs_diff = np.nanmean(np.abs(ds_nn_rmse_conf_loss_5_year[var2][model_name] - mmf_1_5_year_rmse[var2]), axis = 1)\n",
    "            line, = axes[1,1].plot(months, ds_nn_rmse_conf_loss_5_year[var2][model_name][np.nanargmin(np.abs(abs_diff - np.nanmedian(abs_diff))),:], label = model_names[model_name], color = color_dict[model_name], linestyle = '--')\n",
    "        else:\n",
    "            line, = axes[1,1].plot(months, np.full(months.shape, np.nan), label = model_names[model_name], color = color_dict[model_name])\n",
    "    axes[1,1].set_xticks(np.arange(0,12*(num_years+1),12), np.arange(0,num_years+1))\n",
    "    axes[1,1].set_yscale('log')\n",
    "    axes[1,1].set_yticks(online_var_settings_yticks[var2]['ticks'])\n",
    "    axes[1,1].set_ylim(online_var_settings_yticks[var2]['ylim_low'], online_var_settings_yticks[var2]['ylim_high'])\n",
    "    axes[1,1].set_yticklabels(online_var_settings_yticks[var2]['labels'])\n",
    "    axes[1,1].set_ylabel(f'{online_var_settings[var2][\"unit\"]}')\n",
    "    axes[1,1].legend(handles = handles_1_0[4:], labels = labels_1_0[4:], loc = 'upper left', ncol = 1)\n",
    "    axes[1,1].grid(True)\n",
    "    axes[1,1].margins(x=0)\n",
    "\n",
    "    axes[2,0].plot(months, mmf_1_5_year_rmse[var1], label='Internal Variability', color='black', marker='o', markersize = 3)\n",
    "    for model_name in model_names.keys():\n",
    "        axes[2,0].fill_between(\n",
    "            months,\n",
    "            np.nanmin(ds_nn_rmse_diff_loss_5_year[var1][model_name], axis = 0),\n",
    "            np.nanmax(ds_nn_rmse_diff_loss_5_year[var1][model_name], axis = 0),\n",
    "            color = color_dict[model_name],\n",
    "            alpha = 0.15\n",
    "        )\n",
    "        if np.sum(np.isnan(ds_nn_rmse_diff_loss_5_year[var1][model_name])) != np.prod(ds_nn_rmse_diff_loss_5_year[var1][model_name].shape):\n",
    "            abs_diff = np.nanmean(np.abs(ds_nn_rmse_diff_loss_5_year[var1][model_name] - mmf_1_5_year_rmse[var1]), axis = 1)\n",
    "            line, = axes[2,0].plot(months, ds_nn_rmse_diff_loss_5_year[var1][model_name][np.nanargmin(np.abs(abs_diff - np.nanmedian(abs_diff))),:], label = model_names[model_name], color = color_dict[model_name], linestyle = '--')\n",
    "        else:\n",
    "            line, = axes[2,0].plot(months, np.full(months.shape, np.nan), label = model_names[model_name], color = color_dict[model_name])\n",
    "    axes[2,0].set_xticks(np.arange(0,12*(num_years+1),12), np.arange(0,num_years+1)) \n",
    "    axes[2,0].set_yscale('log')\n",
    "    axes[2,0].set_yticks(online_var_settings_yticks[var1]['ticks'])\n",
    "    axes[2,0].set_ylim(online_var_settings_yticks[var1]['ylim_low'], online_var_settings_yticks[var1]['ylim_high'])\n",
    "    axes[2,0].set_yticklabels(online_var_settings_yticks[var1]['labels'])\n",
    "    axes[2,0].set_ylabel(f'Difference Loss\\n{online_var_settings[var1][\"unit\"]}')\n",
    "    handles_2_0, labels_2_0 = axes[2,0].get_legend_handles_labels()\n",
    "    for idx, model_name in enumerate(model_names.keys()):\n",
    "        num_survived = (~np.isnan(ds_nn_rmse_diff_loss_5_year[var1][model_name][:,:len(months)]).any(axis=1)).sum()\n",
    "        labels_2_0[idx+1] = f'{labels_2_0[idx+1]} ({num_survived}/3 survived)'\n",
    "    axes[2,0].legend(handles = handles_2_0[:4], labels = labels_2_0[:4], loc = 'upper left', ncol = 1)\n",
    "    axes[2,0].grid(True)\n",
    "    axes[2,0].margins(x=0)\n",
    "\n",
    "    axes[2,1].plot(months, mmf_1_5_year_rmse[var2], label='Internal Variability', color='black', marker='o', markersize = 3)\n",
    "    for model_name in model_names.keys():\n",
    "        axes[2,1].fill_between(\n",
    "            months,\n",
    "            np.nanmin(ds_nn_rmse_diff_loss_5_year[var2][model_name], axis = 0),\n",
    "            np.nanmax(ds_nn_rmse_diff_loss_5_year[var2][model_name], axis = 0),\n",
    "            color = color_dict[model_name],\n",
    "            alpha = 0.15\n",
    "        )\n",
    "        if np.sum(np.isnan(ds_nn_rmse_diff_loss_5_year[var2][model_name])) != np.prod(ds_nn_rmse_diff_loss_5_year[var2][model_name].shape):\n",
    "            abs_diff = np.nanmean(np.abs(ds_nn_rmse_diff_loss_5_year[var2][model_name] - mmf_1_5_year_rmse[var2]), axis = 1)\n",
    "            line, = axes[2,1].plot(months, ds_nn_rmse_diff_loss_5_year[var2][model_name][np.nanargmin(np.abs(abs_diff - np.nanmedian(abs_diff))),:], label = model_names[model_name], color = color_dict[model_name], linestyle = '--')\n",
    "        else:\n",
    "            line, = axes[2,1].plot(months, np.full(months.shape, np.nan), label = model_names[model_name], color = color_dict[model_name])\n",
    "    axes[2,1].set_xticks(np.arange(0,12*(num_years+1),12), np.arange(0,num_years+1)) \n",
    "    axes[2,1].set_yscale('log')\n",
    "    axes[2,1].set_yticks(online_var_settings_yticks[var2]['ticks'])\n",
    "    axes[2,1].set_ylim(online_var_settings_yticks[var2]['ylim_low'], online_var_settings_yticks[var2]['ylim_high'])\n",
    "    axes[2,1].set_yticklabels(online_var_settings_yticks[var2]['labels'])\n",
    "    axes[2,1].set_ylabel(f'{online_var_settings[var2][\"unit\"]}')\n",
    "    axes[2,1].set_title('')\n",
    "    axes[2,1].legend(handles = handles_2_0[4:], labels = labels_2_0[4:], loc = 'upper left', ncol = 1)\n",
    "    axes[2,1].grid(True)\n",
    "    axes[2,1].margins(x=0)\n",
    "\n",
    "    axes[3,0].plot(months, mmf_1_5_year_rmse[var1], label='Internal Variability', color='black', marker='o', markersize = 3)\n",
    "    for model_name in model_names.keys():\n",
    "        axes[3,0].fill_between(\n",
    "            months,\n",
    "            np.nanmin(ds_nn_rmse_multirep_5_year[var1][model_name], axis = 0),\n",
    "            np.nanmax(ds_nn_rmse_multirep_5_year[var1][model_name], axis = 0),\n",
    "            color = color_dict[model_name],\n",
    "            alpha = 0.15\n",
    "        )\n",
    "        if np.sum(np.isnan(ds_nn_rmse_multirep_5_year[var1][model_name])) != np.prod(ds_nn_rmse_multirep_5_year[var1][model_name].shape):\n",
    "            abs_diff = np.nanmean(np.abs(ds_nn_rmse_multirep_5_year[var1][model_name] - mmf_1_5_year_rmse[var1]), axis = 1)\n",
    "            line, = axes[3,0].plot(months, ds_nn_rmse_multirep_5_year[var1][model_name][np.nanargmin(np.abs(abs_diff - np.nanmedian(abs_diff))),:], label = model_names[model_name], color = color_dict[model_name], linestyle = '--')\n",
    "        else:\n",
    "            line, = axes[3,0].plot(months, np.full(months.shape, np.nan), label = model_names[model_name], color = color_dict[model_name])\n",
    "    axes[3,0].set_xticks(np.arange(0,12*(num_years+1),12), np.arange(0,num_years+1)) \n",
    "    axes[3,0].set_yscale('log')\n",
    "    axes[3,0].set_yticks(online_var_settings_yticks[var1]['ticks'])\n",
    "    axes[3,0].set_ylim(online_var_settings_yticks[var1]['ylim_low'], online_var_settings_yticks[var1]['ylim_high'])\n",
    "    axes[3,0].set_yticklabels(online_var_settings_yticks[var1]['labels'])\n",
    "    axes[3,0].set_ylabel(f'Multirepresentation\\n{online_var_settings[var1][\"unit\"]}')\n",
    "    axes[3,0].set_title('')\n",
    "    handles_3_0, labels_3_0 = axes[3,0].get_legend_handles_labels()\n",
    "    for idx, model_name in enumerate(model_names.keys()):\n",
    "        num_survived = (~np.isnan(ds_nn_rmse_multirep_5_year[var1][model_name][:,:len(months)]).any(axis=1)).sum()\n",
    "        labels_3_0[idx+1] = f'{labels_3_0[idx+1]} ({num_survived}/3 survived)'\n",
    "    axes[3,0].legend(handles = handles_3_0[:4], labels = labels_3_0[:4], loc = 'upper left', ncol = 1)\n",
    "    axes[3,0].grid(True)\n",
    "    axes[3,0].margins(x=0)\n",
    "\n",
    "    axes[3,1].plot(months, mmf_1_5_year_rmse[var2], label='Internal Variability', color='black', marker='o', markersize = 3)\n",
    "    for model_name in model_names.keys():\n",
    "        axes[3,1].fill_between(\n",
    "            months,\n",
    "            np.nanmin(ds_nn_rmse_multirep_5_year[var2][model_name], axis = 0),\n",
    "            np.nanmax(ds_nn_rmse_multirep_5_year[var2][model_name], axis = 0),\n",
    "            color = color_dict[model_name],\n",
    "            alpha = 0.15\n",
    "        )\n",
    "        if np.sum(np.isnan(ds_nn_rmse_multirep_5_year[var2][model_name])) != np.prod(ds_nn_rmse_multirep_5_year[var2][model_name].shape):\n",
    "            abs_diff = np.nanmean(np.abs(ds_nn_rmse_multirep_5_year[var2][model_name] - mmf_1_5_year_rmse[var2]), axis = 1)\n",
    "            line, = axes[3,1].plot(months, ds_nn_rmse_multirep_5_year[var2][model_name][np.nanargmin(np.abs(abs_diff - np.nanmedian(abs_diff))),:], label = model_names[model_name], color = color_dict[model_name], linestyle = '--')\n",
    "        else:\n",
    "            line, = axes[3,1].plot(months, np.full(months.shape, np.nan), label = model_names[model_name], color = color_dict[model_name])\n",
    "    axes[3,1].set_xticks(np.arange(0,12*(num_years+1),12), np.arange(0,num_years+1)) \n",
    "    axes[3,1].set_yscale('log')\n",
    "    axes[3,1].set_yticks(online_var_settings_yticks[var2]['ticks'])\n",
    "    axes[3,1].set_ylim(online_var_settings_yticks[var2]['ylim_low'], online_var_settings_yticks[var2]['ylim_high'])\n",
    "    axes[3,1].set_yticklabels(online_var_settings_yticks[var2]['labels'])\n",
    "    axes[3,1].set_ylabel(f'{online_var_settings[var2][\"unit\"]}')\n",
    "    axes[3,1].set_title('')\n",
    "    axes[3,1].legend(handles = handles_3_0[4:], labels = labels_3_0[4:], loc = 'upper left', ncol = 1)\n",
    "    axes[3,1].grid(True)\n",
    "    axes[3,1].margins(x=0)\n",
    "\n",
    "    axes[4,0].plot(months[:48], mmf_1_4_year_rmse[var1][:48], label='Internal Variability', color='black', marker='o', markersize = 3)\n",
    "    for model_name in model_names.keys():\n",
    "        axes[4,0].fill_between(\n",
    "            months[:48],\n",
    "            np.nanmin(ds_nn_rmse_v6_4_year[var1][model_name], axis = 0),\n",
    "            np.nanmax(ds_nn_rmse_v6_4_year[var1][model_name], axis = 0),\n",
    "            color = color_dict[model_name],\n",
    "            alpha = 0.15\n",
    "        )\n",
    "        if np.sum(np.isnan(ds_nn_rmse_v6_4_year[var1][model_name])) != np.prod(ds_nn_rmse_v6_4_year[var1][model_name].shape):\n",
    "            abs_diff = np.nanmean(np.abs(ds_nn_rmse_v6_4_year[var1][model_name] - mmf_1_4_year_rmse[var1]), axis = 1)\n",
    "            line, = axes[4,0].plot(months[:48], ds_nn_rmse_v6_4_year[var1][model_name][np.nanargmin(np.abs(abs_diff - np.nanmedian(abs_diff))),:], label = model_names[model_name], color = color_dict[model_name], linestyle = '--')\n",
    "        else:\n",
    "            line, = axes[4,0].plot(months[:48], np.full(months[:48].shape, np.nan), label = model_names[model_name], color = color_dict[model_name])\n",
    "    axes[4,0].set_xticks(np.arange(0,12*(num_years+1),12), np.arange(0,num_years+1))\n",
    "    axes[4,0].set_yscale('log')\n",
    "    axes[4,0].set_yticks(online_var_settings_yticks[var1]['ticks'])\n",
    "    axes[4,0].set_ylim(online_var_settings_yticks[var1]['ylim_low'], online_var_settings_yticks[var1]['ylim_high'])\n",
    "    axes[4,0].set_yticklabels(online_var_settings_yticks[var1]['labels'])\n",
    "    axes[4,0].set_ylabel(f'Expanded Variable List\\n{online_var_settings[var1][\"unit\"]}')\n",
    "    axes[4,0].set_title('')\n",
    "    handles_4_0, labels_4_0 = axes[4,0].get_legend_handles_labels()\n",
    "    for idx, model_name in enumerate(model_names.keys()):\n",
    "        num_survived = (~np.isnan(ds_nn_rmse_v6_4_year[var1][model_name][:,:len(months[:48])]).any(axis=1)).sum()\n",
    "        labels_4_0[idx+1] = f'{labels_4_0[idx+1]} ({num_survived}/3* survived)'\n",
    "    axes[4,0].legend(handles = handles_4_0[:4], labels = labels_4_0[:4], loc = 'upper left', ncol = 1)\n",
    "    axes[4,0].grid(True)\n",
    "\n",
    "    axes[4,1].plot(months[:48], mmf_1_4_year_rmse[var2][:48], label='Internal Variability', color='black', marker='o', markersize = 3)\n",
    "    for model_name in model_names.keys():\n",
    "        axes[4,1].fill_between(\n",
    "            months[:48],\n",
    "            np.nanmin(ds_nn_rmse_v6_4_year[var2][model_name], axis = 0),\n",
    "            np.nanmax(ds_nn_rmse_v6_4_year[var2][model_name], axis = 0),\n",
    "            color = color_dict[model_name],\n",
    "            alpha = 0.15\n",
    "        )\n",
    "        if np.sum(np.isnan(ds_nn_rmse_v6_4_year[var2][model_name])) != np.prod(ds_nn_rmse_v6_4_year[var2][model_name].shape):\n",
    "            abs_diff = np.nanmean(np.abs(ds_nn_rmse_v6_4_year[var2][model_name] - mmf_1_4_year_rmse[var2]), axis = 1)\n",
    "            line, = axes[4,1].plot(months[:48], ds_nn_rmse_v6_4_year[var2][model_name][np.nanargmin(np.abs(abs_diff - np.nanmedian(abs_diff))),:], label = model_names[model_name], color = color_dict[model_name], linestyle = '--')\n",
    "        else:\n",
    "            line, = axes[4,1].plot(months[:48], np.full(months[:48].shape, np.nan), label = model_names[model_name], color = color_dict[model_name])\n",
    "    axes[4,1].set_xticks(np.arange(0,12*(num_years+1),12), np.arange(0,num_years+1)) \n",
    "    axes[4,1].set_yscale('log')\n",
    "    axes[4,1].set_yticks(online_var_settings_yticks[var2]['ticks'])\n",
    "    axes[4,1].set_ylim(online_var_settings_yticks[var2]['ylim_low'], online_var_settings_yticks[var2]['ylim_high'])\n",
    "    axes[4,1].set_yticklabels(online_var_settings_yticks[var2]['labels'])\n",
    "    axes[4,1].set_ylabel(f'{online_var_settings[var2][\"unit\"]}')\n",
    "    axes[4,1].set_title('')\n",
    "    axes[4,1].legend(handles = handles_4_0[4:], labels = labels_4_0[4:], loc = 'upper left', ncol = 1)\n",
    "    axes[4,1].grid(True)\n",
    "\n",
    "    axes[4,0].set_xlabel('Year')\n",
    "    axes[4,1].set_xlabel('Year')\n",
    "    if var1 not in ['DTPHYS', 'DQ1PHYS', 'DQ2PHYS', 'DQ3PHYS']:\n",
    "        axes[4,0].text(50, online_var_settings_yticks[var1]['ticks'][0]*2.4, 'Out\\nOf\\nMemory\\nError', fontsize = 15, color='red', bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"yellow\", alpha=0.7))\n",
    "        axes[4,1].text(50, online_var_settings_yticks[var2]['ticks'][0]*2.4, 'Out\\nOf\\nMemory\\nError', fontsize = 15, color='red', bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"yellow\", alpha=0.7))\n",
    "    else:\n",
    "        axes[4,0].text(50, online_var_settings_yticks[var1]['ticks'][0]*.6, 'Out\\nOf\\nMemory\\nError', fontsize = 15, color='red', bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"yellow\", alpha=0.7))\n",
    "        axes[4,1].text(50, online_var_settings_yticks[var2]['ticks'][0]*.6, 'Out\\nOf\\nMemory\\nError', fontsize = 15, color='red', bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"yellow\", alpha=0.7))\n",
    "\n",
    "    letters = ['(a)', '(b)', '(c)', '(d)', '(e)', '(f)', '(g)', '(h)', '(i)', '(j)']\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        ax.text(\n",
    "            -0.1, 1.05, letters[i],  # Negative x shifts left, y > 1 shifts up\n",
    "            transform=ax.transAxes,\n",
    "            fontsize=plt.rcParams['axes.titlesize'],\n",
    "            va='top', ha='right'      # Align to the right (since x is negative)\n",
    "        )\n",
    "\n",
    "\n",
    "    fig.suptitle(f'Five Year Online Monthly RMSE for {online_var_settings[var1][\"var_title\"]} and {online_var_settings[var2][\"var_title\"]}')\n",
    "    if save_path:\n",
    "        plt.savefig(os.path.join(save_path, f'online_{num_years}_year_RMSE_comparison_{var1}_and_{var2}.png'), dpi=300, bbox_inches='tight')\n",
    "    if show:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3019625",
   "metadata": {},
   "source": [
    "## Figure 3 (Online RMSE Growth for T and Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cdb135",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_online_rmse_paper_comparison(var1='T', var2='Q', show=True, save_path=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acfd87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_online_rmse_paper_comparison(var1='U', var2='V', show=True, save_path=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8051fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_online_rmse_paper_comparison(var1='CLDLIQ', var2='CLDICE', show=True, save_path=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f22e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_online_rmse_paper_comparison(var1='DTPHYS', var2='DQ1PHYS', show=True, save_path=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f6fccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_online_rmse_paper_comparison(var1='DQ2PHYS', var2='DQ3PHYS', show=True, save_path=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9b6926",
   "metadata": {},
   "source": [
    "## Figure 4 (Five Year SOTA Global RMSE Vertical Profiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3610f41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_online_sota_global_rmse(num_years, show = True, save_path = None):\n",
    "    months = np.arange(1, num_years * 12 + 1)\n",
    "    ds_mmf_1, ds_mmf_2 = read_mmf_online_data(num_years)\n",
    "    mmf_1_total_weight = get_pressure_area_weights(ds_mmf_1)\n",
    "    variables = ['T', 'Q', 'CLDLIQ', 'CLDICE', 'U', 'V']\n",
    "    config_names_abbrev = {\n",
    "        'standard': 'A',\n",
    "        'conf_loss': 'B',\n",
    "        'diff_loss': 'C',\n",
    "        'multirep': 'D',\n",
    "        'v6': 'E'\n",
    "    }\n",
    "    model_names_abbrev = {\n",
    "        'unet': '0',\n",
    "        'squeezeformer': '1',\n",
    "        'pure_resLSTM': '2',\n",
    "        'pao_model': '3',\n",
    "        'convnext': '4',\n",
    "        'encdec_lstm': '5'\n",
    "    }\n",
    "    ylim_upper = {\n",
    "        'T': 5,\n",
    "        'Q': 0.7,\n",
    "        'CLDLIQ': 60,\n",
    "        'CLDICE': 8,\n",
    "        'U': 11,\n",
    "        'V': 5\n",
    "    }\n",
    "    sublabels = [f'({chr(97 + i)})' for i in range(6)]\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(9.4, 7), sharey=True, constrained_layout=True)  # 2 rows, 3 columns\n",
    "    axes = axes.flatten()  # Flatten axes for easier iteration\n",
    "    def load_nn_var_time_mean(ds_nn_xr, var, num_years):\n",
    "        return_vals = np.full((data_v2_rh_mc.num_levels, data_v2_rh_mc.num_latlon), np.nan)\n",
    "        if not ds_nn_xr or len(ds_nn_xr['time']) < num_years * 12:\n",
    "            return return_vals\n",
    "        else:\n",
    "            return ds_nn_xr[var].mean(dim = 'time').values\n",
    "    sublabel_idx = 0\n",
    "    for ax, var in zip(axes, variables):\n",
    "        ds_mmf_1_mean = ds_mmf_1[var].mean(dim = 'time').values * online_var_settings[var]['scaling']\n",
    "        ds_mmf_2_mean = ds_mmf_2[var].mean(dim = 'time').values * online_var_settings[var]['scaling']\n",
    "        huber_rop_mean = huber_rop_run[var].mean(dim = 'time').values * online_var_settings[var]['scaling']\n",
    "        huber_step_mean = huber_step_run[var].mean(dim = 'time').values * online_var_settings[var]['scaling']\n",
    "        mmf_rmse = np.sqrt(np.average((ds_mmf_2_mean - ds_mmf_1_mean) ** 2, axis = 1, weights = area_weight))\n",
    "        huber_rop_rmse = np.sqrt(np.average((huber_rop_mean - ds_mmf_1_mean) ** 2, axis = 1, weights = area_weight))\n",
    "        huber_step_rmse = np.sqrt(np.average((huber_step_mean - ds_mmf_1_mean) ** 2, axis = 1, weights = area_weight))\n",
    "\n",
    "        line_mmf, = ax.plot(mmf_rmse, level, label=f'MMF2: {mmf_ref_dict[var]:.2f}', linestyle = '-', color='black')\n",
    "        line_huber_rop, = ax.plot(huber_rop_rmse, level, label = f'Hu et al. 1: {huetal_sota_dict[var][0]:.2f}', linestyle = '-', color = 'grey', alpha = .7)\n",
    "        line_huber_step, = ax.plot(huber_step_rmse, level, label = f'Hu et al. 2: {huetal_sota_dict[var][1]:.2f}', linestyle = '-', color = 'grey', alpha = .7)\n",
    "\n",
    "        for idx, nn_sim in enumerate(sota_breakers[var]):\n",
    "            ds_nn = read_nn_online_data(nn_sim['config_name'], nn_sim['model_name'], nn_sim['seed_number'], 5)\n",
    "            nn_mean = ds_nn[var].mean(dim = 'time').values * online_var_settings[var]['scaling']\n",
    "            nn_rmse = np.sqrt(np.average((nn_mean - ds_mmf_1_mean) ** 2, axis = 1, weights = area_weight))\n",
    "            nn_rmse_global = np.sqrt(np.average((nn_mean - ds_mmf_1_mean) ** 2, weights = mmf_1_total_weight))\n",
    "            scaled_alpha = .85**idx\n",
    "            ax.plot(nn_rmse, level, label = f'({model_names_abbrev[nn_sim[\"model_name\"]]}{config_names_abbrev[nn_sim[\"config_name\"]]}) {nn_rmse_global:.2f}', color = color_dict[nn_sim['model_name']], linestyle = '-.', alpha = scaled_alpha)\n",
    "\n",
    "        ax.set_xlim(left = 0, right = ylim_upper[var])\n",
    "        ax.tick_params(axis='both', labelsize=12)\n",
    "        ax.set_title(f\"{sublabels[sublabel_idx]} {online_var_settings[var]['var_title']} ({online_var_settings[var]['unit']})\", loc='center')  # Add main title with subplot label\n",
    "        ax.set_xlabel(f\"{online_var_settings[var]['unit']}\")  # Keep unit in x-label\n",
    "        ax.invert_yaxis()  # Reverse the y-axis\n",
    "        if sublabel_idx == 4:\n",
    "            ax.legend(fontsize = scale_default('legend.fontsize', .72), ncol = 1)\n",
    "        else:\n",
    "            ax.legend(fontsize = scale_default('legend.fontsize', .8), ncol = 1)\n",
    "        ax.grid(True)\n",
    "        sublabel_idx += 1\n",
    "\n",
    "    # --- Proxy lines for models (color key) ---\n",
    "    unet_line = mlines.Line2D([], [], color=color_dict['unet'], lw=2, label=f'{model_names[\"unet\"]} (0)')\n",
    "    squeezeformer_line = mlines.Line2D([], [], color=color_dict['squeezeformer'], lw=2, label=f'{model_names[\"squeezeformer\"]} (1)')\n",
    "    pure_resLSTM_line = mlines.Line2D([], [], color=color_dict['pure_resLSTM'], lw=2, label=f'{model_names[\"pure_resLSTM\"]} (2)')\n",
    "    pao_model_line = mlines.Line2D([], [], color=color_dict['pao_model'], lw=2, label=f'{model_names[\"pao_model\"]} (3)')\n",
    "    convnext_line = mlines.Line2D([], [], color=color_dict['convnext'], lw=2, label=f'{model_names[\"convnext\"]} (4)')\n",
    "    encdec_lstm_line = mlines.Line2D([], [], color=color_dict['encdec_lstm'], lw=2, label=f'{model_names[\"encdec_lstm\"]} (5)')\n",
    "\n",
    "    # --- Proxy \"letters\" for configurations (letter key) ---\n",
    "    # We'll use empty lines with text as the label, or you can use markers if you prefer\n",
    "\n",
    "    standard_line = mlines.Line2D([], [], color='k', marker='', linestyle='None', label='A: Standard')\n",
    "    conf_loss_line = mlines.Line2D([], [], color='k', marker='', linestyle='None', label='B: Confidence Loss')\n",
    "    diff_loss_line = mlines.Line2D([], [], color='k', marker='', linestyle='None', label='C: Difference Loss')\n",
    "    multirep_line = mlines.Line2D([], [], color='k', marker='', linestyle='None', label='D: Multirepresentation')\n",
    "    v6_line = mlines.Line2D([], [], color='k', marker='', linestyle='None', label='E: Expanded Variable List')\n",
    "\n",
    "    # First, add the model legend\n",
    "    legend1 = fig.legend(handles=[unet_line, squeezeformer_line, pure_resLSTM_line, pao_model_line, convnext_line, encdec_lstm_line], \n",
    "                        loc='center left', bbox_to_anchor=(1.0, .6), \n",
    "                        title='Model Architectures')\n",
    "\n",
    "    # Then, add the configuration legend\n",
    "    legend2 = fig.legend(handles=[standard_line, conf_loss_line, diff_loss_line, multirep_line, v6_line], \n",
    "                        loc='center left', bbox_to_anchor=(1.0, 0.35), \n",
    "                        title='Configurations')\n",
    "\n",
    "    fig.gca().add_artist(legend1)  # Make sure both legends show up\n",
    "\n",
    "    # handles = [line_mmf, line_unet, line_squeezeformer, line_pure_resLSTM, line_pao_model, line_convnext, line_encdec_lstm]\n",
    "    # labels = ['MMF2', model_names['unet'], model_names['squeezeformer'], model_names['pure_resLSTM'], model_names['pao_model'], model_names['convnext'], model_names['encdec_lstm']]\n",
    "\n",
    "    # fig.legend(handles, labels, loc='center right', bbox_to_anchor=(1.27, 0.5), title='Model')\n",
    "    fig.suptitle(f'Five Year SOTA Online Global Mean Root Mean Squared Error')\n",
    "    # Set a shared y-label for the first column\n",
    "    axes[0].set_ylabel('Hybrid pressure (hPa)')\n",
    "    axes[3].set_ylabel('Hybrid pressure (hPa)')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    # plt.savefig('state_rmse_profiles_and_scalar.pdf', format='pdf', dpi=400, bbox_inches='tight')\n",
    "    if save_path:\n",
    "        plt.savefig(os.path.join(save_path, f'online_{num_years}_year_global_RMSE_model_comparison_{config_name}.png'), dpi=300, bbox_inches='tight')\n",
    "    if show:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bcc203",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_online_sota_global_rmse(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ef6918",
   "metadata": {},
   "source": [
    "## Figure 5 (Five Year SOTA Zonal Mean Biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9663f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sota_online_zonal_mean_bias(show = True, save_path = None):\n",
    "    # Generate the panel labels\n",
    "    num_years = 5\n",
    "    labels = [f\"({letter})\" for letter in string.ascii_lowercase[:9]]\n",
    "    latitude_ticks = [-60, -30, 0, 30, 60]\n",
    "    latitude_labels = ['60S', '30S', '0', '30N', '60N']\n",
    "    # Loop through each variable and its corresponding subplot row\n",
    "    ds_mmf_1, ds_mmf_2 = read_mmf_online_data(num_years)\n",
    "    variables = ['T', 'Q', 'U', 'CLDLIQ', 'CLDICE', 'DTPHYS', 'DQ1PHYS', 'DQnPHYS', 'DUPHYS']\n",
    "    ds_top_nn = {var: read_nn_online_data(config_name = top_model_dict_5_year[var]['config_name'], \\\n",
    "                                          model_name = top_model_dict_5_year[var]['model_name'], \\\n",
    "                                          seed = top_model_dict_5_year[var]['seed_number'], \\\n",
    "                                          num_years = 5) for var in variables}\n",
    "    zonal_mean_bias_top_nn = {var: online_var_settings[var]['scaling'] * (online_area_time_mean_3d(ds_top_nn[var], var) - online_area_time_mean_3d(ds_mmf_1, var)) for var in variables}\n",
    "    # Create a figure with subplots\n",
    "    config_names_abbrev = {\n",
    "        'standard': 'A',\n",
    "        'conf_loss': 'B',\n",
    "        'diff_loss': 'C',\n",
    "        'multirep': 'D',\n",
    "        'v6': 'E'\n",
    "    }\n",
    "    model_names_abbrev = {\n",
    "        'unet': '0',\n",
    "        'squeezeformer': '1',\n",
    "        'pure_resLSTM': '2',\n",
    "        'pao_model': '3',\n",
    "        'convnext': '4',\n",
    "        'encdec_lstm': '5'\n",
    "    }\n",
    "\n",
    "    fig, axs = plt.subplots(3, 3, figsize=(12.8, 8), constrained_layout = True)\n",
    "    # dict_keys(['T', 'Q', 'U', 'CLDLIQ', 'CLDICE', 'DTPHYS', 'DQ1PHYS', 'DQnPHYS', 'DUPHYS'])\n",
    "\n",
    "    bias_T = zonal_mean_bias_top_nn['T'].plot(ax=axs[0, 0], add_colorbar=False, cmap='RdBu_r', vmin=online_var_settings['T']['vmin'], vmax=online_var_settings['T']['vmax'])\n",
    "    axs[0, 0].set_title(f\"{labels[0]} {online_var_settings['T']['var_title']} Bias ({online_var_settings['T']['unit']})\")\n",
    "    axs[0, 0].invert_yaxis()\n",
    "    axs[0, 0].set_xlabel('')\n",
    "    cbar = fig.colorbar(bias_T)\n",
    "    axs[0, 0].set_ylabel(\"Hybrid pressure (hPa)\")\n",
    "    axs[0, 0].text(0.85, 0.15, f'{model_names_abbrev[top_model_dict_5_year[\"T\"][\"model_name\"]]}{config_names_abbrev[top_model_dict_5_year[\"T\"][\"config_name\"]]}', \n",
    "                   transform=axs[0, 0].transAxes, \n",
    "                   fontsize=14, \n",
    "                   fontweight='bold', \n",
    "                   va='top', \n",
    "                   ha='left')\n",
    "\n",
    "    bias_Q = zonal_mean_bias_top_nn['Q'].plot(ax=axs[0, 1], add_colorbar=False, cmap='RdBu_r', vmin=online_var_settings['Q']['vmin'], vmax=online_var_settings['Q']['vmax'])\n",
    "    axs[0, 1].set_title(f\"{labels[1]} {online_var_settings['Q']['var_title']} Bias ({online_var_settings['Q']['unit']})\")\n",
    "    axs[0, 1].invert_yaxis()\n",
    "    axs[0, 1].set_xlabel('')\n",
    "    axs[0, 1].set_ylabel('')\n",
    "    cbar = fig.colorbar(bias_Q)\n",
    "    axs[0, 1].text(0.85, 0.15, f'{model_names_abbrev[top_model_dict_5_year[\"Q\"][\"model_name\"]]}{config_names_abbrev[top_model_dict_5_year[\"Q\"][\"config_name\"]]}', \n",
    "                   transform=axs[0, 1].transAxes, \n",
    "                   fontsize=14, \n",
    "                   fontweight='bold', \n",
    "                   va='top', \n",
    "                   ha='left')\n",
    "\n",
    "    bias_U = zonal_mean_bias_top_nn['U'].plot(ax=axs[0, 2], add_colorbar=False, cmap='RdBu_r', vmin=online_var_settings['U']['vmin'], vmax=online_var_settings['U']['vmax'])\n",
    "    axs[0, 2].set_title(f\"{labels[2]} {online_var_settings['U']['var_title']} Bias ({online_var_settings['U']['unit']})\")\n",
    "    axs[0, 2].invert_yaxis()\n",
    "    axs[0, 2].set_xlabel('')\n",
    "    axs[0, 2].set_ylabel('')\n",
    "    cbar = fig.colorbar(bias_U)\n",
    "    axs[0, 2].text(0.85, 0.15, f'{model_names_abbrev[top_model_dict_5_year[\"U\"][\"model_name\"]]}{config_names_abbrev[top_model_dict_5_year[\"U\"][\"config_name\"]]}', \n",
    "                   transform=axs[0, 2].transAxes, \n",
    "                   fontsize=14, \n",
    "                   fontweight='bold', \n",
    "                   va='top', \n",
    "                   ha='left')\n",
    "\n",
    "    bias_CLDLIQ = zonal_mean_bias_top_nn['CLDLIQ'].plot(ax=axs[1, 0], add_colorbar=False, cmap='RdBu_r', vmin=online_var_settings['CLDLIQ']['vmin'], vmax=online_var_settings['CLDLIQ']['vmax'])\n",
    "    axs[1, 0].set_title(f\"{labels[3]} {online_var_settings['CLDLIQ']['var_title']} Bias ({online_var_settings['CLDLIQ']['unit']})\")\n",
    "    axs[1, 0].invert_yaxis()\n",
    "    axs[1, 0].set_xlabel('')\n",
    "    axs[1, 0].set_ylabel('')\n",
    "    cbar = fig.colorbar(bias_CLDLIQ)\n",
    "    axs[1, 0].set_ylabel(\"Hybrid pressure (hPa)\")\n",
    "    axs[1, 0].text(0.85, 0.15, f'{model_names_abbrev[top_model_dict_5_year[\"CLDLIQ\"][\"model_name\"]]}{config_names_abbrev[top_model_dict_5_year[\"CLDLIQ\"][\"config_name\"]]}', \n",
    "                   transform=axs[1, 0].transAxes, \n",
    "                   fontsize=14, \n",
    "                   fontweight='bold', \n",
    "                   va='top', \n",
    "                   ha='left')\n",
    "\n",
    "    bias_CLDICE = zonal_mean_bias_top_nn['CLDICE'].plot(ax=axs[1, 1], add_colorbar=False, cmap='RdBu_r', vmin=online_var_settings['CLDICE']['vmin'], vmax=online_var_settings['CLDICE']['vmax'])\n",
    "    axs[1, 1].plot(lat_bin_mids, idx_tropopause_zm, 'k--')\n",
    "    axs[1, 1].set_title(f\"{labels[4]} {online_var_settings['CLDICE']['var_title']} Bias ({online_var_settings['CLDICE']['unit']})\")\n",
    "    axs[1, 1].invert_yaxis()\n",
    "    axs[1, 1].set_xlabel('')\n",
    "    axs[1, 1].set_ylabel('')\n",
    "    cbar = fig.colorbar(bias_CLDICE)\n",
    "    axs[1, 1].text(0.85, 0.15, f'{model_names_abbrev[top_model_dict_5_year[\"CLDICE\"][\"model_name\"]]}{config_names_abbrev[top_model_dict_5_year[\"CLDICE\"][\"config_name\"]]}', \n",
    "                   transform=axs[1, 1].transAxes, \n",
    "                   fontsize=14, \n",
    "                   fontweight='bold', \n",
    "                   va='top', \n",
    "                   ha='left')\n",
    "\n",
    "    bias_DTPHYS = zonal_mean_bias_top_nn['DTPHYS'].plot(ax=axs[1, 2], add_colorbar=False, cmap='RdBu_r', vmin=online_var_settings['DTPHYS']['vmin'], vmax=online_var_settings['DTPHYS']['vmax'])\n",
    "    axs[1, 2].set_title(f\"{labels[5]} {online_var_settings['DTPHYS']['var_title']} Bias ({online_var_settings['DTPHYS']['unit']})\")\n",
    "    axs[1, 2].invert_yaxis()\n",
    "    axs[1, 2].set_xlabel('')\n",
    "    axs[1, 2].set_ylabel('')\n",
    "    cbar = fig.colorbar(bias_DTPHYS)\n",
    "    axs[1, 2].text(0.85, 0.15, f'{model_names_abbrev[top_model_dict_5_year[\"DTPHYS\"][\"model_name\"]]}{config_names_abbrev[top_model_dict_5_year[\"DTPHYS\"][\"config_name\"]]}', \n",
    "                   transform=axs[1, 2].transAxes, \n",
    "                   fontsize=14, \n",
    "                   fontweight='bold', \n",
    "                   va='top', \n",
    "                   ha='left')\n",
    "\n",
    "    bias_DQ1PHYS = zonal_mean_bias_top_nn['DQ1PHYS'].plot(ax=axs[2, 0], add_colorbar=False, cmap='RdBu_r', vmin=online_var_settings['DQ1PHYS']['vmin'], vmax=online_var_settings['DQ1PHYS']['vmax'])\n",
    "    axs[2, 0].set_title(f\"{labels[6]} {online_var_settings['DQ1PHYS']['var_title']} Bias ({online_var_settings['DQ1PHYS']['unit']})\", fontsize = plt.rcParams['axes.titlesize'] * .85)\n",
    "    axs[2, 0].invert_yaxis()\n",
    "    axs[2, 0].set_xlabel('')\n",
    "    axs[2, 0].set_ylabel('')\n",
    "    cbar = fig.colorbar(bias_DQ1PHYS)\n",
    "    axs[2, 0].set_ylabel(\"Hybrid pressure (hPa)\")\n",
    "    axs[2, 0].set_xlabel(\"Latitude\")\n",
    "    axs[2, 0].text(0.85, 0.15, f'{model_names_abbrev[top_model_dict_5_year[\"DQ1PHYS\"][\"model_name\"]]}{config_names_abbrev[top_model_dict_5_year[\"DQ1PHYS\"][\"config_name\"]]}', \n",
    "                   transform=axs[2, 0].transAxes, \n",
    "                   fontsize=14, \n",
    "                   fontweight='bold', \n",
    "                   va='top', \n",
    "                   ha='left')\n",
    "\n",
    "    bias_DQnPHYS = zonal_mean_bias_top_nn['DQnPHYS'].plot(ax=axs[2, 1], add_colorbar=False, cmap='RdBu_r', vmin=online_var_settings['DQnPHYS']['vmin'], vmax=online_var_settings['DQnPHYS']['vmax'])\n",
    "    axs[2, 1].set_title(f\"{labels[6]} {online_var_settings['DQnPHYS']['var_title']} Bias ({online_var_settings['DQnPHYS']['unit']})\", fontsize = plt.rcParams['axes.titlesize'] * .85)\n",
    "    axs[2, 1].invert_yaxis()\n",
    "    axs[2, 1].set_xlabel('')\n",
    "    axs[2, 1].set_ylabel('')\n",
    "    cbar = fig.colorbar(bias_DQnPHYS)\n",
    "    axs[2, 1].set_xlabel(\"Latitude\")\n",
    "    axs[2, 1].text(0.85, 0.15, f'{model_names_abbrev[top_model_dict_5_year[\"DQnPHYS\"][\"model_name\"]]}{config_names_abbrev[top_model_dict_5_year[\"DQnPHYS\"][\"config_name\"]]}', \n",
    "                   transform=axs[2, 1].transAxes, \n",
    "                   fontsize=14, \n",
    "                   fontweight='bold', \n",
    "                   va='top', \n",
    "                   ha='left')\n",
    "\n",
    "    bias_DUPHYS = zonal_mean_bias_top_nn['DUPHYS'].plot(ax=axs[2, 2], add_colorbar=False, cmap='RdBu_r', vmin=online_var_settings['DUPHYS']['vmin'], vmax=online_var_settings['DUPHYS']['vmax'])\n",
    "    axs[2, 2].set_title(f\"{labels[6]} {online_var_settings['DUPHYS']['var_title']} Bias ({online_var_settings['DUPHYS']['unit']})\", fontsize = plt.rcParams['axes.titlesize'] * .85)\n",
    "    axs[2, 2].invert_yaxis()\n",
    "    axs[2, 2].set_xlabel('')\n",
    "    axs[2, 2].set_ylabel('')\n",
    "    cbar = fig.colorbar(bias_DUPHYS)\n",
    "    axs[2, 2].set_xlabel(\"Latitude\")\n",
    "    axs[2, 2].text(0.85, 0.15, f'{model_names_abbrev[top_model_dict_5_year[\"DUPHYS\"][\"model_name\"]]}{config_names_abbrev[top_model_dict_5_year[\"DUPHYS\"][\"config_name\"]]}', \n",
    "                   transform=axs[2, 2].transAxes, \n",
    "                   fontsize=14, \n",
    "                   fontweight='bold', \n",
    "                   va='top', \n",
    "                   ha='left')\n",
    "\n",
    "    # Set these ticks and labels for each subplot\n",
    "    for ax_row in axs:\n",
    "        for ax in ax_row:\n",
    "            ax.set_xticks(latitude_ticks)  # Set the positions for the ticks\n",
    "            ax.set_xticklabels(latitude_labels)  # Set the custom text labels\n",
    "\n",
    "\n",
    "\n",
    "    plt.suptitle(f\"Five Year SOTA Online Zonal Mean Biases\")\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(os.path.join(save_path, f'online_5_year_zonal_mean_bias_sota.png'), dpi=300, bbox_inches='tight')\n",
    "    if show:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907eab6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sota_online_zonal_mean_bias()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0beaa372",
   "metadata": {},
   "source": [
    "## Figure 6 (Online Zonal Mean Biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02b3226",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_nn_standard_4_year['unet'][7]['T']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad3b4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_online_zonal_mean_bias_model_comparison_example(config_name, var1, var2, seed = 7, num_years = 4, show = True, save_path = None):\n",
    "    # Create a figure with subplots\n",
    "    fig = plt.figure(figsize=(12.8, 13.8))\n",
    "    # Generate the panel labels\n",
    "    labels = [f\"({letter})\" for letter in string.ascii_lowercase[:12]]\n",
    "    latitude_ticks = [-60, -30, 0, 30, 60]\n",
    "    latitude_labels = ['60S', '30S', '0', '30N', '60N']\n",
    "    # Loop through each variable and its corresponding subplot row\n",
    "    if num_years == 5:\n",
    "        ds_mmf_1, ds_mmf_2 = ds_mmf_1_5_year, ds_mmf_2_5_year\n",
    "    elif num_years == 4:\n",
    "        ds_mmf_1, ds_mmf_2 = ds_mmf_1_4_year, ds_mmf_2_4_year\n",
    "    else:\n",
    "        raise ValueError(\"num_years must be either 4 or 5.\")\n",
    "\n",
    "    if config_name == 'standard' and num_years == 5:\n",
    "        ds_nn = ds_nn_standard_5_year\n",
    "    elif config_name == 'conf_loss' and num_years == 5:\n",
    "        ds_nn = ds_nn_conf_loss_5_year\n",
    "    elif config_name == 'diff_loss' and num_years == 5:\n",
    "        ds_nn = ds_nn_diff_loss_5_year\n",
    "    elif config_name == 'multirep' and num_years == 5:\n",
    "        ds_nn = ds_nn_multirep_5_year\n",
    "    elif config_name == 'v6' and num_years == 5:\n",
    "        ds_nn = ds_nn_v6_5_year\n",
    "    elif config_name == 'standard' and num_years == 4:\n",
    "        ds_nn = ds_nn_standard_4_year\n",
    "    elif config_name == 'conf_loss' and num_years == 4:\n",
    "        ds_nn = ds_nn_conf_loss_4_year\n",
    "    elif config_name == 'diff_loss' and num_years == 4:\n",
    "        ds_nn = ds_nn_diff_loss_4_year\n",
    "    elif config_name == 'multirep' and num_years == 4:\n",
    "        ds_nn = ds_nn_multirep_4_year\n",
    "    elif config_name == 'v6' and num_years == 4:\n",
    "        ds_nn = ds_nn_v6_4_year\n",
    "    \n",
    "    if not ds_nn['unet'][seed] or not ds_nn['squeezeformer'][seed] or not ds_nn['pure_resLSTM'][seed] or not ds_nn['pao_model'][seed] or not ds_nn['convnext'][seed] or not ds_nn['encdec_lstm'][seed]:\n",
    "        return\n",
    "\n",
    "    gs = gridspec.GridSpec(\n",
    "        6, 3, figure=fig,\n",
    "        hspace=0.35,\n",
    "        height_ratios=[.5, 3, 3, .5, 3, 3]\n",
    "    )\n",
    "\n",
    "    ax_top = fig.add_subplot(gs[0, :])\n",
    "    ax_top.set_axis_off()\n",
    "    ax_top.text(\n",
    "        0.5, 0.5, f\"Four Year Online {online_var_settings[var1]['var_title']} ({online_var_settings[var1]['unit']}) Zonal Mean Bias ({config_names[config_name]} Configuration, Seed {seed})\",\n",
    "        transform=ax_top.transAxes,\n",
    "        ha='center', va='center',\n",
    "        fontsize=14.5,\n",
    "    )\n",
    "\n",
    "    # dict_keys(['T', 'Q', 'U', 'CLDLIQ', 'CLDICE', 'DTPHYS', 'DQ1PHYS', 'DQnPHYS', 'DUPHYS'])\n",
    "    zonal_mean_bias_var1 = {model:online_var_settings[var1]['scaling'] * (online_area_time_mean_3d(ds_nn[model][seed], var1) - online_area_time_mean_3d(ds_mmf_1, var1)) for model in model_names}\n",
    "\n",
    "    ax10 = fig.add_subplot(gs[1, 0])\n",
    "    unet_bias_var1 = zonal_mean_bias_var1['unet'].plot(ax=ax10, add_colorbar=False, cmap='RdBu_r', vmin=online_var_settings[var1]['vmin'], vmax=online_var_settings[var1]['vmax'])\n",
    "    ax10.set_title(f\"{labels[0]} {model_names['unet']}\")\n",
    "    ax10.invert_yaxis()\n",
    "    ax10.set_xlabel('')\n",
    "    ax10.set_xticks([])\n",
    "    cbar = fig.colorbar(unet_bias_var1)\n",
    "    ax10.set_ylabel(\"Hybrid pressure (hPa)\")\n",
    "    ax10.set_xticks(latitude_ticks)  # Set the positions for the ticks\n",
    "    ax10.set_xticklabels(latitude_labels)  # Set the custom text labels\n",
    "\n",
    "    ax11 = fig.add_subplot(gs[1, 1])\n",
    "    squeezeformer_bias_var1 = zonal_mean_bias_var1['squeezeformer'].plot(ax=ax11, add_colorbar=False, cmap='RdBu_r', vmin=online_var_settings[var1]['vmin'], vmax=online_var_settings[var1]['vmax'])\n",
    "    ax11.set_title(f\"{labels[1]} {model_names['squeezeformer']}\")\n",
    "    ax11.invert_yaxis()\n",
    "    ax11.set_xlabel('')\n",
    "    ax11.set_xticks([])\n",
    "    ax11.set_ylabel('')\n",
    "    cbar = fig.colorbar(squeezeformer_bias_var1)\n",
    "    ax11.set_xticks(latitude_ticks)  # Set the positions for the ticks\n",
    "    ax11.set_xticklabels(latitude_labels)  # Set the custom text labels\n",
    "\n",
    "    ax12 = fig.add_subplot(gs[1, 2])\n",
    "    pure_resLSTM_bias_var1 = zonal_mean_bias_var1['pure_resLSTM'].plot(ax=ax12, add_colorbar=False, cmap='RdBu_r', vmin=online_var_settings[var1]['vmin'], vmax=online_var_settings[var1]['vmax'])\n",
    "    ax12.set_title(f\"{labels[2]} {model_names['pure_resLSTM']}\")\n",
    "    ax12.invert_yaxis()\n",
    "    ax12.set_xlabel('')\n",
    "    ax12.set_xticks([])\n",
    "    ax12.set_ylabel('')\n",
    "    cbar = fig.colorbar(pure_resLSTM_bias_var1)\n",
    "    ax12.set_xticks(latitude_ticks)  # Set the positions for the ticks\n",
    "    ax12.set_xticklabels(latitude_labels)  # Set the custom text labels\n",
    "\n",
    "    ax20 = fig.add_subplot(gs[2, 0])\n",
    "    pao_model_bias_var1 = zonal_mean_bias_var1['pao_model'].plot(ax=ax20, add_colorbar=False, cmap='RdBu_r', vmin=online_var_settings[var1]['vmin'], vmax=online_var_settings[var1]['vmax'])\n",
    "    ax20.set_title(f\"{labels[3]} {model_names['pao_model']}\")\n",
    "    ax20.invert_yaxis()\n",
    "    ax20.set_xlabel('')\n",
    "    ax20.set_ylabel('')\n",
    "    cbar = fig.colorbar(pao_model_bias_var1)\n",
    "    ax20.set_ylabel(\"Hybrid pressure (hPa)\")\n",
    "    ax20.set_xticks(latitude_ticks)  # Set the positions for the ticks\n",
    "    ax20.set_xticklabels(latitude_labels)  # Set the custom text labels\n",
    "\n",
    "    ax21 = fig.add_subplot(gs[2, 1])\n",
    "    convnext_bias_var1 = zonal_mean_bias_var1['convnext'].plot(ax=ax21, add_colorbar=False, cmap='RdBu_r', vmin=online_var_settings[var1]['vmin'], vmax=online_var_settings[var1]['vmax'])\n",
    "    ax21.set_title(f\"{labels[4]} {model_names['convnext']}\")\n",
    "    ax21.invert_yaxis()\n",
    "    ax21.set_xlabel('')\n",
    "    ax21.set_ylabel('')\n",
    "    cbar = fig.colorbar(convnext_bias_var1)\n",
    "    ax21.set_xticks(latitude_ticks)  # Set the positions for the ticks\n",
    "    ax21.set_xticklabels(latitude_labels)  # Set the custom text labels\n",
    "\n",
    "    ax22 = fig.add_subplot(gs[2, 2])\n",
    "    encdec_lstm_bias_var1 = zonal_mean_bias_var1['encdec_lstm'].plot(ax=ax22, add_colorbar=False, cmap='RdBu_r', vmin=online_var_settings[var1]['vmin'], vmax=online_var_settings[var1]['vmax'])\n",
    "    ax22.set_title(f\"{labels[5]} {model_names['encdec_lstm']}\")\n",
    "    ax22.invert_yaxis()\n",
    "    ax22.set_xlabel('')\n",
    "    ax22.set_ylabel('')\n",
    "    cbar = fig.colorbar(encdec_lstm_bias_var1)\n",
    "    ax22.set_xticks(latitude_ticks)  # Set the positions for the ticks\n",
    "    ax22.set_xticklabels(latitude_labels)  # Set the custom text labels\n",
    "\n",
    "    if var1 == 'CLDICE':\n",
    "        ax10.plot(lat_bin_mids, idx_tropopause_zm, 'k--')\n",
    "        ax11.plot(lat_bin_mids, idx_tropopause_zm, 'k--')\n",
    "        ax12.plot(lat_bin_mids, idx_tropopause_zm, 'k--')\n",
    "        ax20.plot(lat_bin_mids, idx_tropopause_zm, 'k--')\n",
    "        ax21.plot(lat_bin_mids, idx_tropopause_zm, 'k--')\n",
    "        ax22.plot(lat_bin_mids, idx_tropopause_zm, 'k--')\n",
    "\n",
    "    ax_bot = fig.add_subplot(gs[3, :])\n",
    "    ax_bot.set_axis_off()\n",
    "    ax_bot.text(\n",
    "        0.5, 0.5, f\"Four Year Online {online_var_settings[var2]['var_title']} ({online_var_settings[var2]['unit']}) Zonal Mean Bias ({config_names[config_name]} Configuration, Seed {seed})\",\n",
    "        transform=ax_bot.transAxes,\n",
    "        ha='center', va='center',\n",
    "        fontsize=14.5,\n",
    "    )\n",
    "\n",
    "    zonal_mean_bias_var2 = {model:online_var_settings[var2]['scaling'] * (online_area_time_mean_3d(ds_nn[model][seed], var2) - online_area_time_mean_3d(ds_mmf_1, var2)) for model in model_names}\n",
    "\n",
    "    ax40 = fig.add_subplot(gs[4, 0])\n",
    "    unet_bias_var2 = zonal_mean_bias_var2['unet'].plot(ax=ax40, add_colorbar=False, cmap='RdBu_r', vmin=online_var_settings[var2]['vmin'], vmax=online_var_settings[var2]['vmax'])\n",
    "    ax40.set_title(f\"{labels[6]} {model_names['unet']}\")\n",
    "    ax40.invert_yaxis()\n",
    "    ax40.set_xlabel('')\n",
    "    ax40.set_xticks([])\n",
    "    cbar = fig.colorbar(unet_bias_var2)\n",
    "    ax40.set_ylabel(\"Hybrid pressure (hPa)\")\n",
    "    ax40.set_xticks(latitude_ticks)  # Set the positions for the ticks\n",
    "    ax40.set_xticklabels(latitude_labels)  # Set the custom text labels\n",
    "\n",
    "    ax41 = fig.add_subplot(gs[4, 1])\n",
    "    squeezeformer_bias_var2 = zonal_mean_bias_var2['squeezeformer'].plot(ax=ax41, add_colorbar=False, cmap='RdBu_r', vmin=online_var_settings[var2]['vmin'], vmax=online_var_settings[var2]['vmax'])\n",
    "    ax41.set_title(f\"{labels[7]} {model_names['squeezeformer']}\")\n",
    "    ax41.invert_yaxis()\n",
    "    ax41.set_xlabel('')\n",
    "    ax41.set_xticks([])\n",
    "    ax41.set_ylabel('')\n",
    "    cbar = fig.colorbar(squeezeformer_bias_var2)\n",
    "    ax41.set_xticks(latitude_ticks)  # Set the positions for the ticks\n",
    "    ax41.set_xticklabels(latitude_labels)  # Set the custom text labels\n",
    "\n",
    "    ax42 = fig.add_subplot(gs[4, 2])\n",
    "    pure_resLSTM_bias_var2 = zonal_mean_bias_var2['pure_resLSTM'].plot(ax=ax42, add_colorbar=False, cmap='RdBu_r', vmin=online_var_settings[var2]['vmin'], vmax=online_var_settings[var2]['vmax'])\n",
    "    ax42.set_title(f\"{labels[8]} {model_names['pure_resLSTM']}\")\n",
    "    ax42.invert_yaxis()\n",
    "    ax42.set_xlabel('')\n",
    "    ax42.set_xticks([])\n",
    "    ax42.set_ylabel('')\n",
    "    cbar = fig.colorbar(pure_resLSTM_bias_var2)\n",
    "    ax42.set_xticks(latitude_ticks)  # Set the positions for the ticks\n",
    "    ax42.set_xticklabels(latitude_labels)  # Set the custom text labels\n",
    "\n",
    "    ax50 = fig.add_subplot(gs[5, 0])\n",
    "    pao_model_bias_var2 = zonal_mean_bias_var2['pao_model'].plot(ax=ax50, add_colorbar=False, cmap='RdBu_r', vmin=online_var_settings[var2]['vmin'], vmax=online_var_settings[var2]['vmax'])\n",
    "    ax50.set_title(f\"{labels[9]} {model_names['pao_model']}\")\n",
    "    ax50.invert_yaxis()\n",
    "    ax50.set_ylabel('')\n",
    "    cbar = fig.colorbar(pao_model_bias_var2)\n",
    "    ax50.set_ylabel(\"Hybrid pressure (hPa)\")\n",
    "    ax50.set_xlabel(\"Latitude\")\n",
    "    ax50.set_xticks(latitude_ticks)  # Set the positions for the ticks\n",
    "    ax50.set_xticklabels(latitude_labels)  # Set the custom text labels\n",
    "\n",
    "    ax51 = fig.add_subplot(gs[5, 1])\n",
    "    convnext_bias_var2 = zonal_mean_bias_var2['convnext'].plot(ax=ax51, add_colorbar=False, cmap='RdBu_r', vmin=online_var_settings[var2]['vmin'], vmax=online_var_settings[var2]['vmax'])\n",
    "    ax51.set_title(f\"{labels[10]} {model_names['convnext']}\")\n",
    "    ax51.invert_yaxis()\n",
    "    ax51.set_ylabel('')\n",
    "    cbar = fig.colorbar(convnext_bias_var2)\n",
    "    ax51.set_xlabel(\"Latitude\")\n",
    "    ax51.set_xticks(latitude_ticks)  # Set the positions for the ticks\n",
    "    ax51.set_xticklabels(latitude_labels)  # Set the custom text labels\n",
    "\n",
    "    ax52 = fig.add_subplot(gs[5, 2])\n",
    "    encdec_lstm_bias_var2 = zonal_mean_bias_var2['encdec_lstm'].plot(ax=ax52, add_colorbar=False, cmap='RdBu_r', vmin=online_var_settings[var2]['vmin'], vmax=online_var_settings[var2]['vmax'])\n",
    "    ax52.set_title(f\"{labels[11]} {model_names['encdec_lstm']}\")\n",
    "    ax52.invert_yaxis()\n",
    "    ax52.set_ylabel('')\n",
    "    cbar = fig.colorbar(encdec_lstm_bias_var2)\n",
    "    ax52.set_xlabel(\"Latitude\")\n",
    "    ax52.set_xticks(latitude_ticks)  # Set the positions for the ticks\n",
    "    ax52.set_xticklabels(latitude_labels)  # Set the custom text labels\n",
    "\n",
    "    if var2 == 'CLDICE':\n",
    "        ax40.plot(lat_bin_mids, idx_tropopause_zm, 'k--')\n",
    "        ax41.plot(lat_bin_mids, idx_tropopause_zm, 'k--')\n",
    "        ax42.plot(lat_bin_mids, idx_tropopause_zm, 'k--')\n",
    "        ax50.plot(lat_bin_mids, idx_tropopause_zm, 'k--')\n",
    "        ax51.plot(lat_bin_mids, idx_tropopause_zm, 'k--')\n",
    "        ax52.plot(lat_bin_mids, idx_tropopause_zm, 'k--')\n",
    "\n",
    "    # plt.suptitle(f\"Four Year Online {online_var_settings[var1]['var_title']} ({online_var_settings[var1]['unit']}) Zonal Mean Bias ({config_names[config_name]} Configuration, Seed {seed})\")\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(os.path.join(save_path, f'online_{num_years}_year_zonal_mean_{var}_bias_model_comparison_{config_name}_{seed}.png'), dpi=300, bbox_inches='tight')\n",
    "    if show:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e10027",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_online_zonal_mean_bias_model_comparison_example(config_name = 'conf_loss', var1 = 'T', var2 = 'Q', seed = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3fd3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_online_zonal_mean_bias_model_comparison_example(config_name = 'conf_loss', var1 = 'U', var2 = 'V', seed = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3d9efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_online_zonal_mean_bias_model_comparison_example(config_name = 'conf_loss', var1 = 'CLDLIQ', var2 = 'CLDICE', seed = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88aeba47",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_online_zonal_mean_bias_model_comparison_example(config_name = 'conf_loss', var1 = 'DTPHYS', var2 = 'DQ1PHYS', seed = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fea0d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_online_zonal_mean_bias_model_comparison_example(config_name = 'conf_loss', var1 = 'DQ2PHYS', var2 = 'DQ3PHYS', seed = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea4dbdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bd9d6d3c",
   "metadata": {},
   "source": [
    "## Figure 7 (Precipitable Water Underestimation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59340cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_online_precip_water_area_mean_model_comparison(show = True, save_path = None):\n",
    "    num_years = 4\n",
    "    months = np.arange(1, num_years * 12 + 1)\n",
    "    ds_mmf_1, ds_mmf_2 = ds_mmf_1_4_year, ds_mmf_2_4_year\n",
    "\n",
    "    row_titles = {'global':'Global mean', 'tropics':'30S-30N mean', 'nh':'30N-90N mean', 'sh':'30S-90S mean'}\n",
    "    col_titles = [\n",
    "        config_names['standard'],\n",
    "        config_names['conf_loss'],\n",
    "        config_names['diff_loss'],\n",
    "        config_names['multirep'],\n",
    "        config_names['v6']\n",
    "    ]\n",
    "    def calculate_mean(ds, w, var):\n",
    "        mean_per_month = np.full(len(months), np.nan)\n",
    "        if not ds:\n",
    "            return mean_per_month\n",
    "        if var == 'T':\n",
    "            mean_per_month[:len(ds['time'])] = np.average(ds['T'][:, -1, :].values, weights=w, axis=1)\n",
    "        elif var == 'TMQ':\n",
    "            mean_per_month[:len(ds['time'])] = np.average(ds['TMQ'][:, :].values, weights=w, axis=1)\n",
    "        elif var == 'TCP':\n",
    "            mean_per_month[:len(ds['time'])] = get_tcp_mean(ds, w)\n",
    "        return mean_per_month\n",
    "\n",
    "    get_mean_function = {\n",
    "        'T': lambda ds, w: calculate_mean(ds, w, 'T'),\n",
    "        'TMQ': lambda ds, w: calculate_mean(ds, w, 'TMQ'),\n",
    "        'TCP': lambda ds, w: calculate_mean(ds, w, 'TCP')\n",
    "    }\n",
    "    ds_nn_4_year = {\n",
    "        'standard': ds_nn_standard_4_year,\n",
    "        'conf_loss': ds_nn_conf_loss_4_year,\n",
    "        'diff_loss': ds_nn_diff_loss_4_year,\n",
    "        'multirep': ds_nn_multirep_4_year,\n",
    "        'v6': ds_nn_v6_4_year\n",
    "    }\n",
    "    sublabels = [f'({chr(97 + i)})' for i in range(20)]\n",
    "    fig, axes = plt.subplots(4, 5, figsize=(18, 9))\n",
    "    sublabel_idx = 0\n",
    "    for row, weight_key in enumerate(['global', 'tropics', 'nh', 'sh']):\n",
    "        for col, config_name in enumerate(config_names.keys()):\n",
    "            weight = area_weight_dict[weight_key]\n",
    "            ds_mmf_1_var_vals = get_mean_function['TMQ'](ds_mmf_1, weight)\n",
    "            line_mmf_1, = axes[row, col].plot(months, ds_mmf_1_var_vals, label = 'MMF', color = 'black')\n",
    "            line_mmf_2, = axes[row, col].plot(months, get_mean_function['TMQ'](ds_mmf_2, weight), label = 'MMF2', color = 'black', linestyle = 'dashed')\n",
    "            ds_nn_mean = {\n",
    "                'unet': np.array([get_mean_function['TMQ'](ds_nn_4_year[config_name]['unet'][seed_number], weight) for seed_number in seed_numbers]),\n",
    "                'squeezeformer': np.array([get_mean_function['TMQ'](ds_nn_4_year[config_name]['squeezeformer'][seed_number], weight) for seed_number in seed_numbers]),\n",
    "                'pure_resLSTM': np.array([get_mean_function['TMQ'](ds_nn_4_year[config_name]['pure_resLSTM'][seed_number], weight) for seed_number in seed_numbers]),\n",
    "                'pao_model': np.array([get_mean_function['TMQ'](ds_nn_4_year[config_name]['pao_model'][seed_number], weight) for seed_number in seed_numbers]),\n",
    "                'convnext': np.array([get_mean_function['TMQ'](ds_nn_4_year[config_name]['convnext'][seed_number], weight) for seed_number in seed_numbers]),\n",
    "                'encdec_lstm': np.array([get_mean_function['TMQ'](ds_nn_4_year[config_name]['encdec_lstm'][seed_number], weight) for seed_number in seed_numbers])\n",
    "            }\n",
    "            for model_name in model_names.keys():\n",
    "                axes[row, col].fill_between(\n",
    "                    months,\n",
    "                    np.nanmin(ds_nn_mean[model_name], axis = 0),\n",
    "                    np.nanmax(ds_nn_mean[model_name], axis = 0),\n",
    "                    color = color_dict[model_name],\n",
    "                    alpha=0.15\n",
    "                )\n",
    "            if np.sum(np.isnan(ds_nn_mean['unet'])) != np.prod(ds_nn_mean['unet'].shape):\n",
    "                abs_diff = np.nanmean(np.abs(ds_nn_mean['unet'] - ds_mmf_1_var_vals), axis = 1)\n",
    "                line_unet, = axes[row, col].plot(months, ds_nn_mean['unet'][np.nanargmin(np.abs(abs_diff - np.nanmedian(abs_diff))),:], label = model_names['unet'], color = color_dict['unet'], linestyle = '--')\n",
    "            else:\n",
    "                line_unet, = axes[row, col].plot(months, np.full(months.shape, np.nan), label = model_names['unet'], color = color_dict['unet'], linestyle = '--')\n",
    "            if np.sum(np.isnan(ds_nn_mean['squeezeformer'])) != np.prod(ds_nn_mean['squeezeformer'].shape):\n",
    "                abs_diff = np.nanmean(np.abs(ds_nn_mean['squeezeformer'] - ds_mmf_1_var_vals), axis = 1)\n",
    "                line_squeezeformer, = axes[row, col].plot(months, ds_nn_mean['squeezeformer'][np.nanargmin(np.abs(abs_diff - np.nanmedian(abs_diff))),:], label = model_names['squeezeformer'], color = color_dict['squeezeformer'], linestyle = '--')\n",
    "            else:\n",
    "                line_squeezeformer, = axes[row, col].plot(months, np.full(months.shape, np.nan), label = model_names['squeezeformer'], color = color_dict['squeezeformer'], linestyle = '--')\n",
    "            if np.sum(np.isnan(ds_nn_mean['pure_resLSTM'])) != np.prod(ds_nn_mean['pure_resLSTM'].shape):\n",
    "                abs_diff = np.nanmean(np.abs(ds_nn_mean['pure_resLSTM'] - ds_mmf_1_var_vals), axis = 1)\n",
    "                line_pure_resLSTM, = axes[row, col].plot(months, ds_nn_mean['pure_resLSTM'][np.nanargmin(np.abs(abs_diff - np.nanmedian(abs_diff))),:], label = model_names['pure_resLSTM'], color = color_dict['pure_resLSTM'], linestyle = '--')\n",
    "            else:\n",
    "                line_pure_resLSTM, = axes[row, col].plot(months, np.full(months.shape, np.nan), label = model_names['pure_resLSTM'], color = color_dict['pure_resLSTM'], linestyle = '--')\n",
    "            if np.sum(np.isnan(ds_nn_mean['pao_model'])) != np.prod(ds_nn_mean['pao_model'].shape):\n",
    "                abs_diff = np.nanmean(np.abs(ds_nn_mean['pao_model'] - ds_mmf_1_var_vals), axis = 1)\n",
    "                line_pao_model, = axes[row, col].plot(months, ds_nn_mean['pao_model'][np.nanargmin(np.abs(abs_diff - np.nanmedian(abs_diff))),:], label = model_names['pao_model'], color = color_dict['pao_model'], linestyle = '--')\n",
    "            else:\n",
    "                line_pao_model, = axes[row, col].plot(months, np.full(months.shape, np.nan), label = model_names['pao_model'], color = color_dict['pao_model'], linestyle = '--')\n",
    "            if np.sum(np.isnan(ds_nn_mean['convnext'])) != np.prod(ds_nn_mean['convnext'].shape):\n",
    "                abs_diff = np.nanmean(np.abs(ds_nn_mean['convnext'] - ds_mmf_1_var_vals), axis = 1)\n",
    "                line_convnext, = axes[row, col].plot(months, ds_nn_mean['convnext'][np.nanargmin(np.abs(abs_diff - np.nanmedian(abs_diff))),:], label = model_names['convnext'], color = color_dict['convnext'], linestyle = '--')\n",
    "            else:\n",
    "                line_convnext, = axes[row, col].plot(months, np.full(months.shape, np.nan), label = model_names['convnext'], color = color_dict['convnext'], linestyle = '--')\n",
    "            if np.sum(np.isnan(ds_nn_mean['encdec_lstm'])) != np.prod(ds_nn_mean['encdec_lstm'].shape):\n",
    "                abs_diff = np.nanmean(np.abs(ds_nn_mean['encdec_lstm'] - ds_mmf_1_var_vals), axis = 1)\n",
    "                line_encdec_lstm, = axes[row, col].plot(months, ds_nn_mean['encdec_lstm'][np.nanargmin(np.abs(abs_diff - np.nanmedian(abs_diff))),:], label = model_names['encdec_lstm'], color = color_dict['encdec_lstm'], linestyle = '--')\n",
    "            else:\n",
    "                line_encdec_lstm, = axes[row, col].plot(months, np.full(months.shape, np.nan), label = model_names['encdec_lstm'], color = color_dict['encdec_lstm'], linestyle = '--')\n",
    "            \n",
    "            if row == 0:\n",
    "                ylim_min = 23\n",
    "                ylim_max = 34\n",
    "            elif row == 1:\n",
    "                ylim_min = 34\n",
    "                ylim_max = 44\n",
    "            elif row == 2:\n",
    "                ylim_min = 5\n",
    "                ylim_max = 35\n",
    "            elif row == 3:\n",
    "                ylim_min = 7.5\n",
    "                ylim_max = 20.5\n",
    "\n",
    "            axes[row, col].set_ylim(ylim_min, ylim_max)\n",
    "            axes[row, col].grid(True)\n",
    "            axes[row, col].tick_params(axis='both', labelsize=12)\n",
    "            axes[row, col].set_xticks(np.arange(0,12*(num_years+1),12), np.arange(0,num_years+1))\n",
    "            axes[row, col].text(-0.1, 1.1, sublabels[sublabel_idx], transform=axes[row, col].transAxes, fontsize=plt.rcParams['axes.titlesize'], va='top', ha='left')\n",
    "            # Set column titles\n",
    "            if row == 0:\n",
    "                axes[row, col].set_title(config_names[config_name])\n",
    "            \n",
    "            # Set row y-labels\n",
    "            if col == 0:\n",
    "                axes[row, col].set_ylabel(row_titles[weight_key])\n",
    "            else:\n",
    "                axes[row, col].tick_params(labelleft = False)\n",
    "            \n",
    "            # Set x-label for the last row\n",
    "            if row == 3:\n",
    "                axes[row, col].set_xlabel(\"Years\")\n",
    "            else:\n",
    "                axes[row, col].tick_params(labelbottom = False)\n",
    "            \n",
    "            if row == 3 and col == 0:\n",
    "                axes[row, col].legend(handles = [line_mmf_1, line_mmf_2, line_unet, line_squeezeformer],\n",
    "                                    labels = ['MMF', 'MMF2', model_names['unet'], model_names['squeezeformer']], loc='upper left')\n",
    "            elif row == 3 and col == 1:\n",
    "                axes[row, col].legend(handles = [line_pure_resLSTM, line_pao_model, line_convnext, line_encdec_lstm],\n",
    "                                      labels = [model_names['pure_resLSTM'], model_names['pao_model'], model_names['convnext'], model_names['encdec_lstm']], loc='upper left')\n",
    "            sublabel_idx += 1\n",
    "            \n",
    "    fig.suptitle(f'Four Year Online Precipitable Water Area-Weighted Mean Values (kg/m$^2$)')\n",
    "    # Adjust layout and display the plot\n",
    "    plt.tight_layout()\n",
    "    if save_path:\n",
    "        plt.savefig(os.path.join(save_path, f'online_{num_years}_year_area_mean_model_comparison_{config_name}.png'), dpi=300, bbox_inches='tight')\n",
    "    if show:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e6006b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_online_precip_water_area_mean_model_comparison()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38f0063",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_online_precip_water_area_std_model_comparison(show = True, save_path = None):\n",
    "    num_years = 4\n",
    "    months = np.arange(1, num_years * 12 + 1)\n",
    "    ds_mmf_1, ds_mmf_2 = ds_mmf_1_4_year, ds_mmf_2_4_year\n",
    "\n",
    "    row_titles = {'global':'Global mean', 'tropics':'30S-30N mean', 'nh':'30N-90N mean', 'sh':'30S-90S mean'}\n",
    "    col_titles = [\n",
    "        config_names['standard'],\n",
    "        config_names['conf_loss'],\n",
    "        config_names['diff_loss'],\n",
    "        config_names['multirep'],\n",
    "        config_names['v6']\n",
    "    ]\n",
    "    def calculate_std(ds, w, var):\n",
    "        mean_per_month = np.full(len(months), np.nan)\n",
    "        std_per_month = np.full(len(months), np.nan)\n",
    "        if not ds:\n",
    "            return std_per_month\n",
    "        if var == 'T':\n",
    "            mean_per_month[:len(ds['time'])] = np.average(ds['T'][:, -1, :].values, weights=w, axis=1)\n",
    "            squared_diff = (ds['T'][:,-1,:].values - mean_per_month[:len(ds['time']), None])**2\n",
    "            std_per_month[:len(ds['time'])] = np.sqrt(np.average(squared_diff, weights=w, axis=1))\n",
    "        elif var == 'TMQ':\n",
    "            mean_per_month[:len(ds['time'])] = np.average(ds['TMQ'][:, :].values, weights=w, axis=1)\n",
    "            squared_diff = (ds['TMQ'][:,:].values - mean_per_month[:len(ds['time']), None])**2\n",
    "            std_per_month[:len(ds['time'])] = np.sqrt(np.average(squared_diff, weights=w, axis=1))\n",
    "        elif var == 'TCP':\n",
    "            std_per_month[:len(ds['time'])] = get_tcp_std(ds, w)\n",
    "        return std_per_month\n",
    "\n",
    "    get_std_function = {\n",
    "        'T': lambda ds, w: calculate_std(ds, w, 'T'),\n",
    "        'TMQ': lambda ds, w: calculate_std(ds, w, 'TMQ'),\n",
    "        'TCP': lambda ds, w: calculate_std(ds, w, 'TCP')\n",
    "    }\n",
    "    ds_nn_4_year = {\n",
    "        'standard': ds_nn_standard_4_year,\n",
    "        'conf_loss': ds_nn_conf_loss_4_year,\n",
    "        'diff_loss': ds_nn_diff_loss_4_year,\n",
    "        'multirep': ds_nn_multirep_4_year,\n",
    "        'v6': ds_nn_v6_4_year\n",
    "    }\n",
    "    sublabels = [f'({chr(97 + i)})' for i in range(20)]\n",
    "    fig, axes = plt.subplots(4, 5, figsize=(18, 9))\n",
    "    sublabel_idx = 0\n",
    "    for row, weight_key in enumerate(['global', 'tropics', 'nh', 'sh']):\n",
    "        for col, config_name in enumerate(config_names.keys()):\n",
    "            weight = area_weight_dict[weight_key]\n",
    "            ds_mmf_1_var_vals = get_std_function['TMQ'](ds_mmf_1, weight)\n",
    "            line_mmf_1, = axes[row, col].plot(months, ds_mmf_1_var_vals, label = 'MMF', color = 'black')\n",
    "            line_mmf_2, = axes[row, col].plot(months, get_std_function['TMQ'](ds_mmf_2, weight), label = 'MMF2', color = 'black', linestyle = 'dashed')\n",
    "            ds_nn_std = {\n",
    "                'unet': np.array([get_std_function['TMQ'](ds_nn_4_year[config_name]['unet'][seed_number], weight) for seed_number in seed_numbers]),\n",
    "                'squeezeformer': np.array([get_std_function['TMQ'](ds_nn_4_year[config_name]['squeezeformer'][seed_number], weight) for seed_number in seed_numbers]),\n",
    "                'pure_resLSTM': np.array([get_std_function['TMQ'](ds_nn_4_year[config_name]['pure_resLSTM'][seed_number], weight) for seed_number in seed_numbers]),\n",
    "                'pao_model': np.array([get_std_function['TMQ'](ds_nn_4_year[config_name]['pao_model'][seed_number], weight) for seed_number in seed_numbers]),\n",
    "                'convnext': np.array([get_std_function['TMQ'](ds_nn_4_year[config_name]['convnext'][seed_number], weight) for seed_number in seed_numbers]),\n",
    "                'encdec_lstm': np.array([get_std_function['TMQ'](ds_nn_4_year[config_name]['encdec_lstm'][seed_number], weight) for seed_number in seed_numbers])\n",
    "            }\n",
    "            for model_name in model_names.keys():\n",
    "                axes[row, col].fill_between(\n",
    "                    months,\n",
    "                    np.nanmin(ds_nn_std[model_name], axis = 0),\n",
    "                    np.nanmax(ds_nn_std[model_name], axis = 0),\n",
    "                    color = color_dict[model_name],\n",
    "                    alpha=0.15\n",
    "                )\n",
    "            if np.sum(np.isnan(ds_nn_std['unet'])) != np.prod(ds_nn_std['unet'].shape):\n",
    "                abs_diff = np.nanmean(np.abs(ds_nn_std['unet'] - ds_mmf_1_var_vals), axis = 1)\n",
    "                line_unet, = axes[row, col].plot(months, ds_nn_std['unet'][np.nanargmin(np.abs(abs_diff - np.nanmedian(abs_diff))),:], label = model_names['unet'], color = color_dict['unet'], linestyle = '--')\n",
    "            else:\n",
    "                line_unet, = axes[row, col].plot(months, np.full(months.shape, np.nan), label = model_names['unet'], color = color_dict['unet'], linestyle = '--')\n",
    "            if np.sum(np.isnan(ds_nn_std['squeezeformer'])) != np.prod(ds_nn_std['squeezeformer'].shape):\n",
    "                abs_diff = np.nanmean(np.abs(ds_nn_std['squeezeformer'] - ds_mmf_1_var_vals), axis = 1)\n",
    "                line_squeezeformer, = axes[row, col].plot(months, ds_nn_std['squeezeformer'][np.nanargmin(np.abs(abs_diff - np.nanmedian(abs_diff))),:], label = model_names['squeezeformer'], color = color_dict['squeezeformer'], linestyle = '--')\n",
    "            else:\n",
    "                line_squeezeformer, = axes[row, col].plot(months, np.full(months.shape, np.nan), label = model_names['squeezeformer'], color = color_dict['squeezeformer'], linestyle = '--')\n",
    "            if np.sum(np.isnan(ds_nn_std['pure_resLSTM'])) != np.prod(ds_nn_std['pure_resLSTM'].shape):\n",
    "                abs_diff = np.nanmean(np.abs(ds_nn_std['pure_resLSTM'] - ds_mmf_1_var_vals), axis = 1)\n",
    "                line_pure_resLSTM, = axes[row, col].plot(months, ds_nn_std['pure_resLSTM'][np.nanargmin(np.abs(abs_diff - np.nanmedian(abs_diff))),:], label = model_names['pure_resLSTM'], color = color_dict['pure_resLSTM'], linestyle = '--')\n",
    "            else:\n",
    "                line_pure_resLSTM, = axes[row, col].plot(months, np.full(months.shape, np.nan), label = model_names['pure_resLSTM'], color = color_dict['pure_resLSTM'], linestyle = '--')\n",
    "            if np.sum(np.isnan(ds_nn_std['pao_model'])) != np.prod(ds_nn_std['pao_model'].shape):\n",
    "                abs_diff = np.nanmean(np.abs(ds_nn_std['pao_model'] - ds_mmf_1_var_vals), axis = 1)\n",
    "                line_pao_model, = axes[row, col].plot(months, ds_nn_std['pao_model'][np.nanargmin(np.abs(abs_diff - np.nanmedian(abs_diff))),:], label = model_names['pao_model'], color = color_dict['pao_model'], linestyle = '--')\n",
    "            else:\n",
    "                line_pao_model, = axes[row, col].plot(months, np.full(months.shape, np.nan), label = model_names['pao_model'], color = color_dict['pao_model'], linestyle = '--')\n",
    "            if np.sum(np.isnan(ds_nn_std['convnext'])) != np.prod(ds_nn_std['convnext'].shape):\n",
    "                abs_diff = np.nanmean(np.abs(ds_nn_std['convnext'] - ds_mmf_1_var_vals), axis = 1)\n",
    "                line_convnext, = axes[row, col].plot(months, ds_nn_std['convnext'][np.nanargmin(np.abs(abs_diff - np.nanmedian(abs_diff))),:], label = model_names['convnext'], color = color_dict['convnext'], linestyle = '--')\n",
    "            else:\n",
    "                line_convnext, = axes[row, col].plot(months, np.full(months.shape, np.nan), label = model_names['convnext'], color = color_dict['convnext'], linestyle = '--')\n",
    "            if np.sum(np.isnan(ds_nn_std['encdec_lstm'])) != np.prod(ds_nn_std['encdec_lstm'].shape):\n",
    "                abs_diff = np.nanmean(np.abs(ds_nn_std['encdec_lstm'] - ds_mmf_1_var_vals), axis = 1)\n",
    "                line_encdec_lstm, = axes[row, col].plot(months, ds_nn_std['encdec_lstm'][np.nanargmin(np.abs(abs_diff - np.nanmedian(abs_diff))),:], label = model_names['encdec_lstm'], color = color_dict['encdec_lstm'], linestyle = '--')\n",
    "            else:\n",
    "                line_encdec_lstm, = axes[row, col].plot(months, np.full(months.shape, np.nan), label = model_names['encdec_lstm'], color = color_dict['encdec_lstm'], linestyle = '--')\n",
    "            \n",
    "            if row == 0:\n",
    "                ylim_min = 14\n",
    "                ylim_max = 20\n",
    "            elif row == 1:\n",
    "                ylim_min = 7\n",
    "                ylim_max = 17\n",
    "            elif row == 2:\n",
    "                ylim_min = 2.5\n",
    "                ylim_max = 17.5\n",
    "            elif row == 3:\n",
    "                ylim_min = 5\n",
    "                ylim_max = 13\n",
    "\n",
    "            axes[row, col].set_ylim(ylim_min, ylim_max)\n",
    "            axes[row, col].grid(True)\n",
    "            axes[row, col].tick_params(axis='both', labelsize=12)\n",
    "            axes[row, col].set_xticks(np.arange(0,12*(num_years+1),12), np.arange(0,num_years+1))\n",
    "            axes[row, col].text(-0.1, 1.1, sublabels[sublabel_idx], transform=axes[row, col].transAxes, fontsize=plt.rcParams['axes.titlesize'], va='top', ha='left')\n",
    "            # Set column titles\n",
    "            if row == 0:\n",
    "                axes[row, col].set_title(config_names[config_name])\n",
    "            \n",
    "            # Set row y-labels\n",
    "            if col == 0:\n",
    "                axes[row, col].set_ylabel(row_titles[weight_key])\n",
    "            else:\n",
    "                axes[row, col].tick_params(labelleft = False)\n",
    "            \n",
    "            # Set x-label for the last row\n",
    "            if row == 3:\n",
    "                axes[row, col].set_xlabel(\"Years\")\n",
    "            else:\n",
    "                axes[row, col].tick_params(labelbottom = False)\n",
    "            \n",
    "            if row == 3 and col == 0:\n",
    "                axes[row, col].legend(handles = [line_mmf_1, line_mmf_2, line_unet, line_squeezeformer],\n",
    "                                    labels = ['MMF', 'MMF2', model_names['unet'], model_names['squeezeformer']], loc='upper left')\n",
    "            elif row == 3 and col == 1:\n",
    "                axes[row, col].legend(handles = [line_pure_resLSTM, line_pao_model, line_convnext, line_encdec_lstm],\n",
    "                                      labels = [model_names['pure_resLSTM'], model_names['pao_model'], model_names['convnext'], model_names['encdec_lstm']], loc='upper left')\n",
    "            sublabel_idx += 1\n",
    "            \n",
    "    fig.suptitle(f'Four Year Online Precipitable Water Area-Weighted Standard Deviation Values (kg/m$^2$)')\n",
    "    # Adjust layout and display the plot\n",
    "    plt.tight_layout()\n",
    "    if save_path:\n",
    "        plt.savefig(os.path.join(save_path, f'online_{num_years}_year_area_std_model_comparison_{config_name}.png'), dpi=300, bbox_inches='tight')\n",
    "    if show:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2ccac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_online_precip_water_area_std_model_comparison()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a303244",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_online_precip_water_area_std_model_comparison()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3cdf42",
   "metadata": {},
   "source": [
    "## Figure 8 (Precipitation Distributions--Standard vs. Expanded Variable List Configurations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f6939e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_precc_dists(show = False, save_path = None):\n",
    "    num_years = 4\n",
    "    mmf_1_precc = ds_mmf_1_4_year['PRECT'].values\n",
    "    mmf_1_global_weighting = None\n",
    "    mmf_1_land_weighting = get_pressure_area_weights(ds_mmf_1_4_year, surface_type = 'land')\n",
    "    mmf_1_ocean_weighting = get_pressure_area_weights(ds_mmf_1_4_year, surface_type = 'ocean')\n",
    "    mmf_1_ice_weighting = get_pressure_area_weights(ds_mmf_1_4_year, surface_type = 'ice')\n",
    "    global_tile_area = data_v2_rh_mc.grid_info_area\n",
    "    land_tile_area = data_v2_rh_mc.grid_info_area * np.mean(ds_mmf_1_4_year['LANDFRAC'], axis = 0)\n",
    "    ocean_tile_area = data_v2_rh_mc.grid_info_area * np.mean(ds_mmf_1_4_year['OCNFRAC'], axis = 0)\n",
    "    ice_tile_area = data_v2_rh_mc.grid_info_area * np.mean(ds_mmf_1_4_year['ICEFRAC'], axis = 0)\n",
    "    mmf_flat_global_area_weights = np.tile(global_tile_area, mmf_1_hourly_prect_4_year.shape[0])\n",
    "    mmf_flat_land_area_weights = np.tile(land_tile_area, mmf_1_hourly_prect_4_year.shape[0])\n",
    "    mmf_flat_ocean_area_weights = np.tile(ocean_tile_area, mmf_1_hourly_prect_4_year.shape[0])\n",
    "    mmf_flat_ice_area_weights = np.tile(ice_tile_area, mmf_1_hourly_prect_4_year.shape[0])\n",
    "    nn_standard_global_weighting = {model_name: {seed_number: None for seed_number in seed_numbers} for model_name in model_names.keys()}\n",
    "    nn_standard_land_weighting = {model_name: {seed_number: get_pressure_area_weights(ds_nn_standard_4_year[model_name][seed_number], surface_type = 'land') if ds_nn_standard_4_year[model_name][seed_number] is not None else mmf_1_land_weighting for seed_number in seed_numbers} for model_name in model_names.keys()}\n",
    "    nn_standard_ocean_weighting = {model_name: {seed_number: get_pressure_area_weights(ds_nn_standard_4_year[model_name][seed_number], surface_type = 'ocean') if ds_nn_standard_4_year[model_name][seed_number] is not None else mmf_1_ocean_weighting for seed_number in seed_numbers} for model_name in model_names.keys()}\n",
    "    nn_standard_ice_weighting = {model_name: {seed_number: get_pressure_area_weights(ds_nn_standard_4_year[model_name][seed_number], surface_type = 'ice') if ds_nn_standard_4_year[model_name][seed_number] is not None else mmf_1_ice_weighting for seed_number in seed_numbers} for model_name in model_names.keys()}\n",
    "    nn_v6_global_weighting = {model_name: {seed_number: None for seed_number in seed_numbers} for model_name in model_names.keys()}\n",
    "    nn_v6_land_weighting = {model_name: {seed_number: get_pressure_area_weights(ds_nn_v6_4_year[model_name][seed_number], surface_type = 'land') if ds_nn_v6_4_year[model_name][seed_number] is not None else mmf_1_land_weighting for seed_number in seed_numbers} for model_name in model_names.keys()}\n",
    "    nn_v6_ocean_weighting = {model_name: {seed_number: get_pressure_area_weights(ds_nn_v6_4_year[model_name][seed_number], surface_type = 'ocean') if ds_nn_v6_4_year[model_name][seed_number] is not None else mmf_1_ocean_weighting for seed_number in seed_numbers} for model_name in model_names.keys()}\n",
    "    nn_v6_ice_weighting = {model_name: {seed_number: get_pressure_area_weights(ds_nn_v6_4_year[model_name][seed_number], surface_type = 'ice') if ds_nn_v6_4_year[model_name][seed_number] is not None else mmf_1_ice_weighting for seed_number in seed_numbers} for model_name in model_names.keys()}\n",
    "    mmf_1_global_precc_mean = np.mean(data_v2_rh_mc.zonal_bin_weight_2d(mmf_1_precc, custom_weighting = mmf_1_global_weighting) * 86400 * 1000, axis = 0)\n",
    "    mmf_1_land_precc_mean = np.mean(data_v2_rh_mc.zonal_bin_weight_2d(mmf_1_precc, custom_weighting = mmf_1_land_weighting) * 86400 * 1000, axis = 0)\n",
    "    mmf_1_ocean_precc_mean = np.mean(data_v2_rh_mc.zonal_bin_weight_2d(mmf_1_precc, custom_weighting = mmf_1_ocean_weighting) * 86400 * 1000, axis = 0)\n",
    "    mmf_1_ice_precc_mean = np.mean(data_v2_rh_mc.zonal_bin_weight_2d(mmf_1_precc, custom_weighting = mmf_1_ice_weighting) * 86400 * 1000, axis = 0)\n",
    "    nn_standard_global_precc_mean = {model_name: {seed_number: np.mean(data_v2_rh_mc.zonal_bin_weight_2d(ds_nn_standard_4_year[model_name][seed_number]['PRECT'].values, custom_weighting = nn_standard_global_weighting[model_name][seed_number]) * 86400 * 1000, axis = 0)\n",
    "                if ds_nn_standard_4_year[model_name][seed_number] is not None and ds_nn_standard_4_year[model_name][seed_number]['PRECT'].shape[0] == 12 * num_years else np.full(lat_bin_mids.shape, np.nan) for seed_number in seed_numbers} for model_name in model_names.keys()}\n",
    "    nn_standard_land_precc_mean = {model_name: {seed_number: np.mean(data_v2_rh_mc.zonal_bin_weight_2d(ds_nn_standard_4_year[model_name][seed_number]['PRECT'].values, custom_weighting = nn_standard_land_weighting[model_name][seed_number]) * 86400 * 1000, axis = 0)\n",
    "                if ds_nn_standard_4_year[model_name][seed_number] is not None and ds_nn_standard_4_year[model_name][seed_number]['PRECT'].shape[0] == 12 * num_years else np.full(lat_bin_mids.shape, np.nan) for seed_number in seed_numbers} for model_name in model_names.keys()}\n",
    "    nn_standard_ocean_precc_mean = {model_name: {seed_number: np.mean(data_v2_rh_mc.zonal_bin_weight_2d(ds_nn_standard_4_year[model_name][seed_number]['PRECT'].values, custom_weighting = nn_standard_ocean_weighting[model_name][seed_number]) * 86400 * 1000, axis = 0)\n",
    "                if ds_nn_standard_4_year[model_name][seed_number] is not None and ds_nn_standard_4_year[model_name][seed_number]['PRECT'].shape[0] == 12 * num_years else np.full(lat_bin_mids.shape, np.nan) for seed_number in seed_numbers} for model_name in model_names.keys()}\n",
    "    nn_standard_ice_precc_mean = {model_name: {seed_number: np.mean(data_v2_rh_mc.zonal_bin_weight_2d(ds_nn_standard_4_year[model_name][seed_number]['PRECT'].values, custom_weighting = nn_standard_ice_weighting[model_name][seed_number]) * 86400 * 1000, axis = 0)\n",
    "                if ds_nn_standard_4_year[model_name][seed_number] is not None and ds_nn_standard_4_year[model_name][seed_number]['PRECT'].shape[0] == 12 * num_years else np.full(lat_bin_mids.shape, np.nan) for seed_number in seed_numbers} for model_name in model_names.keys()}\n",
    "    nn_v6_global_precc_mean = {model_name: {seed_number: np.mean(data_v6.zonal_bin_weight_2d(ds_nn_v6_4_year[model_name][seed_number]['PRECT'].values, custom_weighting = nn_v6_global_weighting[model_name][seed_number]) * 86400 * 1000, axis = 0)\n",
    "                if ds_nn_v6_4_year[model_name][seed_number] is not None and ds_nn_v6_4_year[model_name][seed_number]['PRECT'].shape[0] == 12 * num_years else np.full(lat_bin_mids.shape, np.nan) for seed_number in seed_numbers} for model_name in model_names.keys()}\n",
    "    nn_v6_land_precc_mean = {model_name: {seed_number: np.mean(data_v6.zonal_bin_weight_2d(ds_nn_v6_4_year[model_name][seed_number]['PRECT'].values, custom_weighting = nn_v6_land_weighting[model_name][seed_number]) * 86400 * 1000, axis = 0)\n",
    "                if ds_nn_v6_4_year[model_name][seed_number] is not None and ds_nn_v6_4_year[model_name][seed_number]['PRECT'].shape[0] == 12 * num_years else np.full(lat_bin_mids.shape, np.nan) for seed_number in seed_numbers} for model_name in model_names.keys()}\n",
    "    nn_v6_ocean_precc_mean = {model_name: {seed_number: np.mean(data_v6.zonal_bin_weight_2d(ds_nn_v6_4_year[model_name][seed_number]['PRECT'].values, custom_weighting = nn_v6_ocean_weighting[model_name][seed_number]) * 86400 * 1000, axis = 0)\n",
    "                if ds_nn_v6_4_year[model_name][seed_number] is not None and ds_nn_v6_4_year[model_name][seed_number]['PRECT'].shape[0] == 12 * num_years else np.full(lat_bin_mids.shape, np.nan) for seed_number in seed_numbers} for model_name in model_names.keys()}\n",
    "    nn_v6_ice_precc_mean = {model_name: {seed_number: np.mean(data_v6.zonal_bin_weight_2d(ds_nn_v6_4_year[model_name][seed_number]['PRECT'].values, custom_weighting = nn_v6_ice_weighting[model_name][seed_number]) * 86400 * 1000, axis = 0)\n",
    "                if ds_nn_v6_4_year[model_name][seed_number] is not None and ds_nn_v6_4_year[model_name][seed_number]['PRECT'].shape[0] == 12 * num_years else np.full(lat_bin_mids.shape, np.nan) for seed_number in seed_numbers} for model_name in model_names.keys()}\n",
    "\n",
    "    lat_ticks = [-60, -30, 0, 30, 60]\n",
    "    lat_labels = ['60S', '30S', '0', '30N', '60N']\n",
    "    bins_lev = np.arange(-2,180,4)\n",
    "    bin_centers = (bins_lev[:-1] + bins_lev[1:]) / 2\n",
    "\n",
    "    def plot_histogram(ax, data_flat, weights, label, color, linestyle):\n",
    "        hist, bins = np.histogram(data_flat, bins=bins_lev, weights=weights, density=True)\n",
    "        ax.plot(bin_centers, hist, label=label, color=color, linestyle=linestyle, linewidth=2)\n",
    "\n",
    "    fig = plt.figure(figsize=(18, 14))\n",
    "    trans = blended_transform_factory(fig.transFigure, fig.transFigure)\n",
    "\n",
    "    # Define an overall GridSpec with 3 rows: top block, spacer, bottom block\n",
    "    outer = gridspec.GridSpec(7, 1, figure=fig,\n",
    "                            height_ratios=[1, 0.005, 1, 0.35, 1, .005, 1],  # 2.5% of vertical space as gap\n",
    "                            hspace=0.3)\n",
    "\n",
    "    row0 = gridspec.GridSpecFromSubplotSpec(1, 4, subplot_spec=outer[0], hspace=0.3, wspace=0.3)\n",
    "    row1 = gridspec.GridSpecFromSubplotSpec(1, 4, subplot_spec=outer[2], hspace=0.3, wspace=0.3)\n",
    "    row2 = gridspec.GridSpecFromSubplotSpec(1, 4, subplot_spec=outer[4], hspace=0.3, wspace=0.3)\n",
    "    row3 = gridspec.GridSpecFromSubplotSpec(1, 4, subplot_spec=outer[6], hspace=0.3, wspace=0.3)\n",
    "    axes00 = fig.add_subplot(row0[0])\n",
    "    axes01 = fig.add_subplot(row0[1])\n",
    "    axes02 = fig.add_subplot(row0[2])\n",
    "    axes03 = fig.add_subplot(row0[3])\n",
    "    axes10 = fig.add_subplot(row1[0])\n",
    "    axes11 = fig.add_subplot(row1[1])\n",
    "    axes12 = fig.add_subplot(row1[2])\n",
    "    axes13 = fig.add_subplot(row1[3])\n",
    "    axes20 = fig.add_subplot(row2[0])\n",
    "    axes21 = fig.add_subplot(row2[1])\n",
    "    axes22 = fig.add_subplot(row2[2])\n",
    "    axes23 = fig.add_subplot(row2[3])\n",
    "    axes30 = fig.add_subplot(row3[0])\n",
    "    axes31 = fig.add_subplot(row3[1])\n",
    "    axes32 = fig.add_subplot(row3[2])\n",
    "    axes33 = fig.add_subplot(row3[3])\n",
    "    axes_list = [axes00, axes01, axes02, axes03, axes10, axes11, axes12, axes13, axes20, axes21, axes22, axes23, axes30, axes31, axes32, axes33]\n",
    "    label = ord('a')\n",
    "    for ax in axes_list:\n",
    "        ax.text(-0.12, 1.1, f\"({chr(label)})\", transform=ax.transAxes,\n",
    "                fontsize=12, va=\"top\")\n",
    "        label += 1  # Increment label for the next subfigure\n",
    "    standard_global_x_pos = (axes00.get_position().x0 + axes01.get_position().x1)/2\n",
    "    standard_land_x_pos = (axes02.get_position().x0 + axes03.get_position().x1)/2\n",
    "    standard_ocean_x_pos = (axes10.get_position().x0 + axes11.get_position().x1)/2\n",
    "    standard_ice_x_pos = (axes12.get_position().x0 + axes13.get_position().x1)/2\n",
    "    standard_global_y_pos = standard_land_y_pos = axes00.get_position().y1 + .02\n",
    "    standard_ocean_y_pos = standard_ice_y_pos = axes10.get_position().y1 + .02\n",
    "    v6_global_x_pos = (axes20.get_position().x0 + axes21.get_position().x1)/2\n",
    "    v6_land_x_pos = (axes22.get_position().x0 + axes23.get_position().x1)/2\n",
    "    v6_ocean_x_pos = (axes30.get_position().x0 + axes31.get_position().x1)/2\n",
    "    v6_ice_x_pos = (axes32.get_position().x0 + axes33.get_position().x1)/2\n",
    "    v6_global_y_pos = v6_land_y_pos = axes20.get_position().y1 + .02\n",
    "    v6_ocean_y_pos = v6_ice_y_pos = axes30.get_position().y1 + .02\n",
    "\n",
    "    fig.text(standard_global_x_pos, standard_global_y_pos, 'Global', ha=\"center\", va=\"bottom\", transform=trans, fontsize=plt.rcParams['axes.titlesize'], fontweight='semibold')\n",
    "    fig.text(standard_land_x_pos, standard_land_y_pos, 'Land', ha=\"center\", va=\"bottom\", transform=trans, fontsize=plt.rcParams['axes.titlesize'], fontweight='semibold')\n",
    "    fig.text(standard_ocean_x_pos, standard_ocean_y_pos, 'Ocean', ha=\"center\", va=\"bottom\", transform=trans, fontsize=plt.rcParams['axes.titlesize'], fontweight='semibold')\n",
    "    fig.text(standard_ice_x_pos, standard_ice_y_pos, 'Ice', ha=\"center\", va=\"bottom\", transform=trans, fontsize=plt.rcParams['axes.titlesize'], fontweight='semibold')\n",
    "    fig.text(v6_global_x_pos, v6_global_y_pos, 'Global', ha=\"center\", va=\"bottom\", transform=trans, fontsize=plt.rcParams['axes.titlesize'], fontweight='semibold')\n",
    "    fig.text(v6_land_x_pos, v6_land_y_pos, 'Land', ha=\"center\", va=\"bottom\", transform=trans, fontsize=plt.rcParams['axes.titlesize'], fontweight='semibold')\n",
    "    fig.text(v6_ocean_x_pos, v6_ocean_y_pos, 'Ocean', ha=\"center\", va=\"bottom\", transform=trans, fontsize=plt.rcParams['axes.titlesize'], fontweight='semibold')\n",
    "    fig.text(v6_ice_x_pos, v6_ice_y_pos, 'Ice', ha=\"center\", va=\"bottom\", transform=trans, fontsize=plt.rcParams['axes.titlesize'], fontweight='semibold')\n",
    "    \n",
    "    axes00.plot(lat_bin_mids, mmf_1_global_precc_mean, label='MMF', color='black', linestyle='-')\n",
    "    axes02.plot(lat_bin_mids, mmf_1_land_precc_mean, label='MMF', color='black', linestyle='-')\n",
    "    axes10.plot(lat_bin_mids, mmf_1_ocean_precc_mean, label='MMF', color='black', linestyle='-')\n",
    "    axes12.plot(lat_bin_mids, mmf_1_ice_precc_mean, label='MMF', color='black', linestyle='-')\n",
    "    axes20.plot(lat_bin_mids, mmf_1_global_precc_mean, label='MMF', color='black', linestyle='-')\n",
    "    axes22.plot(lat_bin_mids, mmf_1_land_precc_mean, label='MMF', color='black', linestyle='-')\n",
    "    axes30.plot(lat_bin_mids, mmf_1_ocean_precc_mean, label='MMF', color='black', linestyle='-')\n",
    "    axes32.plot(lat_bin_mids, mmf_1_ice_precc_mean, label='MMF', color='black', linestyle='-')\n",
    "    for model_name in model_names.keys():\n",
    "        model_standard_global_mean_arr = np.array([nn_standard_global_precc_mean[model_name][seed_number] for seed_number in seed_numbers])\n",
    "        model_standard_land_mean_arr = np.array([nn_standard_land_precc_mean[model_name][seed_number] for seed_number in seed_numbers])\n",
    "        model_standard_ocean_mean_arr = np.array([nn_standard_ocean_precc_mean[model_name][seed_number] for seed_number in seed_numbers])\n",
    "        model_standard_ice_mean_arr = np.array([nn_standard_ice_precc_mean[model_name][seed_number] for seed_number in seed_numbers])\n",
    "        model_v6_global_mean_arr = np.array([nn_v6_global_precc_mean[model_name][seed_number] for seed_number in seed_numbers])\n",
    "        model_v6_land_mean_arr = np.array([nn_v6_land_precc_mean[model_name][seed_number] for seed_number in seed_numbers])\n",
    "        model_v6_ocean_mean_arr = np.array([nn_v6_ocean_precc_mean[model_name][seed_number] for seed_number in seed_numbers])\n",
    "        model_v6_ice_mean_arr = np.array([nn_v6_ice_precc_mean[model_name][seed_number] for seed_number in seed_numbers])\n",
    "        if np.sum(np.isnan(model_standard_global_mean_arr)) != model_standard_global_mean_arr.size:\n",
    "            axes00.fill_between(\n",
    "                lat_bin_mids,\n",
    "                np.nanmin(model_standard_global_mean_arr, axis=0),\n",
    "                np.nanmax(model_standard_global_mean_arr, axis=0),\n",
    "                color=color_dict[model_name],\n",
    "                alpha=0.15\n",
    "            )\n",
    "            argidx = np.nanargmin(np.nanmean(np.abs(model_standard_global_mean_arr - np.nanmedian(model_standard_global_mean_arr, axis = 0)), axis=1))\n",
    "            axes00.plot(lat_bin_mids, model_standard_global_mean_arr[argidx, :], label = f\"{model_names[model_name]}\", color=color_dict[model_name], linestyle='--')\n",
    "            axes02.fill_between(\n",
    "                lat_bin_mids,\n",
    "                np.nanmin(model_standard_land_mean_arr, axis=0),\n",
    "                np.nanmax(model_standard_land_mean_arr, axis=0),\n",
    "                color=color_dict[model_name],\n",
    "                alpha=0.15\n",
    "            )\n",
    "            argidx = np.nanargmin(np.nanmean(np.abs(model_standard_land_mean_arr - np.nanmedian(model_standard_land_mean_arr, axis = 0)), axis=1))\n",
    "            axes02.plot(lat_bin_mids, model_standard_land_mean_arr[argidx, :], label = f\"{model_names[model_name]}\", color=color_dict[model_name], linestyle='--')\n",
    "            axes10.fill_between(\n",
    "                lat_bin_mids,\n",
    "                np.nanmin(model_standard_ocean_mean_arr, axis=0),\n",
    "                np.nanmax(model_standard_ocean_mean_arr, axis=0),\n",
    "                color=color_dict[model_name],\n",
    "                alpha=0.15\n",
    "            )\n",
    "            argidx = np.nanargmin(np.nanmean(np.abs(model_standard_ocean_mean_arr - np.nanmedian(model_standard_ocean_mean_arr, axis = 0)), axis=1))\n",
    "            axes10.plot(lat_bin_mids, model_standard_ocean_mean_arr[argidx, :], label = f\"{model_names[model_name]}\", color=color_dict[model_name], linestyle='--')\n",
    "            axes12.fill_between(\n",
    "                lat_bin_mids,\n",
    "                np.nanmin(model_standard_ice_mean_arr, axis=0),\n",
    "                np.nanmax(model_standard_ice_mean_arr, axis=0),\n",
    "                color=color_dict[model_name],\n",
    "                alpha=0.15\n",
    "            )\n",
    "            argidx = np.nanargmin(np.nanmean(np.abs(model_standard_ice_mean_arr - np.nanmedian(model_standard_ice_mean_arr, axis = 0)), axis=1))\n",
    "            axes12.plot(lat_bin_mids, model_standard_ice_mean_arr[argidx, :], label = f\"{model_names[model_name]}\", color=color_dict[model_name], linestyle='--')\n",
    "        if np.sum(np.isnan(model_v6_global_mean_arr)) != model_v6_global_mean_arr.size:\n",
    "            axes20.fill_between(\n",
    "                lat_bin_mids,\n",
    "                np.nanmin(model_v6_global_mean_arr, axis=0),\n",
    "                np.nanmax(model_v6_global_mean_arr, axis=0),\n",
    "                color=color_dict[model_name],\n",
    "                alpha=0.15\n",
    "            )\n",
    "            argidx = np.nanargmin(np.nanmean(np.abs(model_v6_global_mean_arr - np.nanmedian(model_v6_global_mean_arr, axis = 0)), axis=1))\n",
    "            axes20.plot(lat_bin_mids, model_v6_global_mean_arr[argidx, :], label = f\"{model_names[model_name]}\", color=color_dict[model_name], linestyle='--')\n",
    "            axes22.fill_between(\n",
    "                lat_bin_mids,\n",
    "                np.nanmin(model_v6_land_mean_arr, axis=0),\n",
    "                np.nanmax(model_v6_land_mean_arr, axis=0),\n",
    "                color=color_dict[model_name],\n",
    "                alpha=0.15\n",
    "            )\n",
    "            argidx = np.nanargmin(np.nanmean(np.abs(model_v6_land_mean_arr - np.nanmedian(model_v6_land_mean_arr, axis = 0)), axis=1))\n",
    "            axes22.plot(lat_bin_mids, model_v6_land_mean_arr[argidx, :], label = f\"{model_names[model_name]}\", color=color_dict[model_name], linestyle='--')\n",
    "            axes30.fill_between(\n",
    "                lat_bin_mids,\n",
    "                np.nanmin(model_v6_ocean_mean_arr, axis=0),\n",
    "                np.nanmax(model_v6_ocean_mean_arr, axis=0),\n",
    "                color=color_dict[model_name],\n",
    "                alpha=0.15\n",
    "            )\n",
    "            argidx = np.nanargmin(np.nanmean(np.abs(model_v6_ocean_mean_arr - np.nanmedian(model_v6_ocean_mean_arr, axis = 0)), axis=1))\n",
    "            axes30.plot(lat_bin_mids, model_v6_ocean_mean_arr[argidx, :], label = f\"{model_names[model_name]}\", color=color_dict[model_name], linestyle='--')\n",
    "            axes32.fill_between(\n",
    "                lat_bin_mids,\n",
    "                np.nanmin(model_v6_ice_mean_arr, axis=0),\n",
    "                np.nanmax(model_v6_ice_mean_arr, axis=0),\n",
    "                color=color_dict[model_name],\n",
    "                alpha=0.15\n",
    "            )\n",
    "            argidx = np.nanargmin(np.nanmean(np.abs(model_v6_ice_mean_arr - np.nanmedian(model_v6_ice_mean_arr, axis = 0)), axis=1))\n",
    "            axes32.plot(lat_bin_mids, model_v6_ice_mean_arr[argidx, :], label = f\"{model_names[model_name]}\", color=color_dict[model_name], linestyle='--')\n",
    "\n",
    "    axes30.set_xlabel('Latitude')\n",
    "    axes32.set_xlabel('Latitude')\n",
    "    axes00.set_ylabel('Precipitation (mm/day)')\n",
    "    axes02.set_ylabel('Precipitation (mm/day)')\n",
    "    axes10.set_ylabel('Precipitation (mm/day)')\n",
    "    axes12.set_ylabel('Precipitation (mm/day)')\n",
    "    axes20.set_ylabel('Precipitation (mm/day)')\n",
    "    axes22.set_ylabel('Precipitation (mm/day)')\n",
    "    axes30.set_ylabel('Precipitation (mm/day)')\n",
    "    axes32.set_ylabel('Precipitation (mm/day)')\n",
    "    axes00.set_xticks(lat_ticks)\n",
    "    axes02.set_xticks(lat_ticks)\n",
    "    axes10.set_xticks(lat_ticks)\n",
    "    axes12.set_xticks(lat_ticks)\n",
    "    axes00.set_xticklabels(lat_labels)\n",
    "    axes02.set_xticklabels(lat_labels)\n",
    "    axes10.set_xticklabels(lat_labels)\n",
    "    axes12.set_xticklabels(lat_labels)\n",
    "    axes00.set_title('Mean Precipitation')\n",
    "    axes02.set_title('Mean Precipitation')\n",
    "\n",
    "    # change fontsize of legend and make it two column\n",
    "    handles, labels = axes00.get_legend_handles_labels()\n",
    "\n",
    "    axes00.legend(ncol=2)\n",
    "    axes00.set_ylim(0, 8)\n",
    "    axes02.set_ylim(0, 8)\n",
    "    axes10.set_ylim(0, 8)\n",
    "    axes12.set_ylim(0, 8)\n",
    "    axes20.set_ylim(0, 8)\n",
    "    axes22.set_ylim(0, 8)\n",
    "    axes30.set_ylim(0, 8)\n",
    "    axes32.set_ylim(0, 8)\n",
    "    axes00.set_xlim(-90,90)\n",
    "    axes02.set_xlim(-90,90)\n",
    "    axes10.set_xlim(-90,90)\n",
    "    axes12.set_xlim(-90,90)\n",
    "    axes20.set_xlim(-90,90)\n",
    "    axes22.set_xlim(-90,90)\n",
    "    axes30.set_xlim(-90,90)\n",
    "    axes32.set_xlim(-90,90)\n",
    "    # Second plot: Weighted histogram of precipitation\n",
    "\n",
    "    plot_histogram(axes01, mmf_1_hourly_prect_4_year_flat, mmf_flat_global_area_weights, 'MMF', 'black', '-')\n",
    "    plot_histogram(axes03, mmf_1_hourly_prect_4_year_flat, mmf_flat_land_area_weights, 'MMF', 'black', '-')\n",
    "    plot_histogram(axes11, mmf_1_hourly_prect_4_year_flat, mmf_flat_ocean_area_weights, 'MMF', 'black', '-')\n",
    "    plot_histogram(axes13, mmf_1_hourly_prect_4_year_flat, mmf_flat_ice_area_weights, 'MMF', 'black', '-')\n",
    "    plot_histogram(axes21, mmf_1_hourly_prect_4_year_flat, mmf_flat_global_area_weights, 'MMF', 'black', '-')\n",
    "    plot_histogram(axes23, mmf_1_hourly_prect_4_year_flat, mmf_flat_land_area_weights, 'MMF', 'black', '-')\n",
    "    plot_histogram(axes31, mmf_1_hourly_prect_4_year_flat, mmf_flat_ocean_area_weights, 'MMF', 'black', '-')\n",
    "    plot_histogram(axes33, mmf_1_hourly_prect_4_year_flat, mmf_flat_ice_area_weights, 'MMF', 'black', '-')\n",
    "    for model_name in model_names.keys():\n",
    "        if not all(len(nn_hourly_prect_standard_4_year[model_name][seed_number]) == 0 for seed_number in seed_numbers):\n",
    "            model_standard_global_mean_arr = np.array([nn_standard_global_precc_mean[model_name][seed_number] for seed_number in seed_numbers])\n",
    "            model_standard_land_mean_arr = np.array([nn_standard_land_precc_mean[model_name][seed_number] for seed_number in seed_numbers])\n",
    "            model_standard_ocean_mean_arr = np.array([nn_standard_ocean_precc_mean[model_name][seed_number] for seed_number in seed_numbers])\n",
    "            model_standard_ice_mean_arr = np.array([nn_standard_ice_precc_mean[model_name][seed_number] for seed_number in seed_numbers])\n",
    "            if np.sum(np.isnan(model_standard_global_mean_arr)) != model_standard_global_mean_arr.size:\n",
    "                nn_global_prect_hist = np.array([np.histogram(np.array(nn_hourly_prect_standard_4_year[model_name][seed_number]).flatten(),\n",
    "                                                              bins=bins_lev,\n",
    "                                                              weights=np.tile(global_tile_area, np.array(nn_hourly_prect_standard_4_year[model_name][seed_number]).shape[0]),\n",
    "                                                              density=True)[0] for seed_number in seed_numbers])\n",
    "                nn_land_prect_hist = np.array([np.histogram(np.array(nn_hourly_prect_standard_4_year[model_name][seed_number]).flatten(),\n",
    "                                                              bins=bins_lev,\n",
    "                                                              weights=np.tile(land_tile_area, np.array(nn_hourly_prect_standard_4_year[model_name][seed_number]).shape[0]),\n",
    "                                                              density=True)[0] for seed_number in seed_numbers])\n",
    "                nn_ocean_prect_hist = np.array([np.histogram(np.array(nn_hourly_prect_standard_4_year[model_name][seed_number]).flatten(),\n",
    "                                                              bins=bins_lev,\n",
    "                                                              weights=np.tile(ocean_tile_area, np.array(nn_hourly_prect_standard_4_year[model_name][seed_number]).shape[0]),\n",
    "                                                              density=True)[0] for seed_number in seed_numbers])\n",
    "                nn_ice_prect_hist = np.array([np.histogram(np.array(nn_hourly_prect_standard_4_year[model_name][seed_number]).flatten(),\n",
    "                                                              bins=bins_lev,\n",
    "                                                              weights=np.tile(ice_tile_area, np.array(nn_hourly_prect_standard_4_year[model_name][seed_number]).shape[0]),\n",
    "                                                              density=True)[0] for seed_number in seed_numbers])\n",
    "                axes01.fill_between(\n",
    "                    bin_centers,\n",
    "                    np.nanmin(nn_global_prect_hist, axis=0),\n",
    "                    np.nanmax(nn_global_prect_hist, axis=0),\n",
    "                    color=color_dict[model_name],\n",
    "                    alpha=0.15\n",
    "                )\n",
    "                argidx = np.nanargmin(np.nanmean(np.abs(nn_global_prect_hist - np.nanmedian(nn_global_prect_hist, axis = 0)), axis=1))\n",
    "                axes01.plot(bin_centers, nn_global_prect_hist[argidx, :], label = f\"{model_names[model_name]}\", color=color_dict[model_name], linestyle='--')\n",
    "                axes03.fill_between(\n",
    "                    bin_centers,\n",
    "                    np.nanmin(nn_land_prect_hist, axis=0),\n",
    "                    np.nanmax(nn_land_prect_hist, axis=0),\n",
    "                    color=color_dict[model_name],\n",
    "                    alpha=0.15\n",
    "                )\n",
    "                argidx = np.nanargmin(np.nanmean(np.abs(nn_land_prect_hist - np.nanmedian(nn_land_prect_hist, axis = 0)), axis=1))\n",
    "                axes03.plot(bin_centers, nn_land_prect_hist[argidx, :], label = f\"{model_names[model_name]}\", color=color_dict[model_name], linestyle='--')\n",
    "                axes11.fill_between(\n",
    "                    bin_centers,\n",
    "                    np.nanmin(nn_ocean_prect_hist, axis=0),\n",
    "                    np.nanmax(nn_ocean_prect_hist, axis=0),\n",
    "                    color=color_dict[model_name],\n",
    "                    alpha=0.15\n",
    "                )\n",
    "                argidx = np.nanargmin(np.nanmean(np.abs(nn_ocean_prect_hist - np.nanmedian(nn_ocean_prect_hist, axis = 0)), axis=1))\n",
    "                axes11.plot(bin_centers, nn_ocean_prect_hist[argidx, :], label = f\"{model_names[model_name]}\", color=color_dict[model_name], linestyle='--')\n",
    "                axes13.fill_between(\n",
    "                    bin_centers,\n",
    "                    np.nanmin(nn_ice_prect_hist, axis=0),\n",
    "                    np.nanmax(nn_ice_prect_hist, axis=0),\n",
    "                    color=color_dict[model_name],\n",
    "                    alpha=0.15\n",
    "                )\n",
    "                argidx = np.nanargmin(np.nanmean(np.abs(nn_ice_prect_hist - np.nanmedian(nn_ice_prect_hist, axis = 0)), axis=1))\n",
    "                axes13.plot(bin_centers, nn_ice_prect_hist[argidx, :], label = f\"{model_names[model_name]}\", color=color_dict[model_name], linestyle='--')\n",
    "        if not all(len(nn_hourly_prect_v6_4_year[model_name][seed_number]) == 0 for seed_number in seed_numbers):\n",
    "            model_v6_global_mean_arr = np.array([nn_v6_global_precc_mean[model_name][seed_number] for seed_number in seed_numbers])\n",
    "            model_v6_land_mean_arr = np.array([nn_v6_land_precc_mean[model_name][seed_number] for seed_number in seed_numbers])\n",
    "            model_v6_ocean_mean_arr = np.array([nn_v6_ocean_precc_mean[model_name][seed_number] for seed_number in seed_numbers])\n",
    "            model_v6_ice_mean_arr = np.array([nn_v6_ice_precc_mean[model_name][seed_number] for seed_number in seed_numbers])\n",
    "            if np.sum(np.isnan(model_v6_global_mean_arr)) != model_v6_global_mean_arr.size:\n",
    "                nn_global_prect_hist = np.array([np.histogram(np.array(nn_hourly_prect_v6_4_year[model_name][seed_number]).flatten(),\n",
    "                                                              bins=bins_lev,\n",
    "                                                              weights=np.tile(global_tile_area, np.array(nn_hourly_prect_v6_4_year[model_name][seed_number]).shape[0]),\n",
    "                                                              density=True)[0] for seed_number in seed_numbers])\n",
    "                nn_land_prect_hist = np.array([np.histogram(np.array(nn_hourly_prect_v6_4_year[model_name][seed_number]).flatten(),\n",
    "                                                              bins=bins_lev,\n",
    "                                                              weights=np.tile(land_tile_area, np.array(nn_hourly_prect_v6_4_year[model_name][seed_number]).shape[0]),\n",
    "                                                              density=True)[0] for seed_number in seed_numbers])\n",
    "                nn_ocean_prect_hist = np.array([np.histogram(np.array(nn_hourly_prect_v6_4_year[model_name][seed_number]).flatten(),\n",
    "                                                              bins=bins_lev,\n",
    "                                                              weights=np.tile(ocean_tile_area, np.array(nn_hourly_prect_v6_4_year[model_name][seed_number]).shape[0]),\n",
    "                                                              density=True)[0] for seed_number in seed_numbers])\n",
    "                nn_ice_prect_hist = np.array([np.histogram(np.array(nn_hourly_prect_v6_4_year[model_name][seed_number]).flatten(),\n",
    "                                                              bins=bins_lev,\n",
    "                                                              weights=np.tile(ice_tile_area, np.array(nn_hourly_prect_v6_4_year[model_name][seed_number]).shape[0]),\n",
    "                                                              density=True)[0] for seed_number in seed_numbers])\n",
    "                axes21.fill_between(\n",
    "                    bin_centers,\n",
    "                    np.nanmin(nn_global_prect_hist, axis=0),\n",
    "                    np.nanmax(nn_global_prect_hist, axis=0),\n",
    "                    color=color_dict[model_name],\n",
    "                    alpha=0.15\n",
    "                )\n",
    "                argidx = np.nanargmin(np.nanmean(np.abs(nn_global_prect_hist - np.nanmedian(nn_global_prect_hist, axis = 0)), axis=1))\n",
    "                axes21.plot(bin_centers, nn_global_prect_hist[argidx, :], label = f\"{model_names[model_name]}\", color=color_dict[model_name], linestyle='--')\n",
    "                axes23.fill_between(\n",
    "                    bin_centers,\n",
    "                    np.nanmin(nn_land_prect_hist, axis=0),\n",
    "                    np.nanmax(nn_land_prect_hist, axis=0),\n",
    "                    color=color_dict[model_name],\n",
    "                    alpha=0.15\n",
    "                )\n",
    "                argidx = np.nanargmin(np.nanmean(np.abs(nn_land_prect_hist - np.nanmedian(nn_land_prect_hist, axis = 0)), axis=1))\n",
    "                axes23.plot(bin_centers, nn_land_prect_hist[argidx, :], label = f\"{model_names[model_name]}\", color=color_dict[model_name], linestyle='--')\n",
    "                axes31.fill_between(\n",
    "                    bin_centers,\n",
    "                    np.nanmin(nn_ocean_prect_hist, axis=0),\n",
    "                    np.nanmax(nn_ocean_prect_hist, axis=0),\n",
    "                    color=color_dict[model_name],\n",
    "                    alpha=0.15\n",
    "                )\n",
    "                argidx = np.nanargmin(np.nanmean(np.abs(nn_ocean_prect_hist - np.nanmedian(nn_ocean_prect_hist, axis = 0)), axis=1))\n",
    "                axes31.plot(bin_centers, nn_ocean_prect_hist[argidx, :], label = f\"{model_names[model_name]}\", color=color_dict[model_name], linestyle='--')\n",
    "                axes33.fill_between(\n",
    "                    bin_centers,\n",
    "                    np.nanmin(nn_ice_prect_hist, axis=0),\n",
    "                    np.nanmax(nn_ice_prect_hist, axis=0),\n",
    "                    color=color_dict[model_name],\n",
    "                    alpha=0.15\n",
    "                )\n",
    "                argidx = np.nanargmin(np.nanmean(np.abs(nn_ice_prect_hist - np.nanmedian(nn_ice_prect_hist, axis = 0)), axis=1))\n",
    "                axes33.plot(bin_centers, nn_ice_prect_hist[argidx, :], label = f\"{model_names[model_name]}\", color=color_dict[model_name], linestyle='--')\n",
    "\n",
    "    axes01.set_yscale('log')\n",
    "    axes03.set_yscale('log')\n",
    "    axes11.set_yscale('log')\n",
    "    axes13.set_yscale('log')\n",
    "    axes21.set_yscale('log')\n",
    "    axes23.set_yscale('log')\n",
    "    axes31.set_yscale('log')\n",
    "    axes33.set_yscale('log')\n",
    "    axes31.set_xlabel('Precipitation (mm/day)')\n",
    "    axes33.set_xlabel('Precipitation (mm/day)')\n",
    "    axes01.set_ylabel('Frequency')\n",
    "    axes03.set_ylabel('Frequency')\n",
    "    axes11.set_ylabel('Frequency')\n",
    "    axes13.set_ylabel('Frequency')\n",
    "    axes21.set_ylabel('Frequency')\n",
    "    axes23.set_ylabel('Frequency')\n",
    "    axes31.set_ylabel('Frequency')\n",
    "    axes33.set_ylabel('Frequency')\n",
    "    axes01.set_title('Histogram of Precipitation')\n",
    "    axes03.set_title('Histogram of Precipitation')\n",
    "    axes01.set_ylim(1e-8,0.5)\n",
    "    axes03.set_ylim(1e-8,0.5)\n",
    "    axes11.set_ylim(1e-8,0.5)\n",
    "    axes13.set_ylim(1e-8,0.5)\n",
    "    axes21.set_ylim(1e-8,0.5)\n",
    "    axes23.set_ylim(1e-8,0.5)\n",
    "    axes31.set_ylim(1e-8,0.5)\n",
    "    axes33.set_ylim(1e-8,0.5)\n",
    "    axes01.set_xlim(0,180)\n",
    "    axes03.set_xlim(0,180)\n",
    "    axes11.set_xlim(0,180)\n",
    "    axes13.set_xlim(0,180)\n",
    "    axes21.set_xlim(0,180)\n",
    "    axes23.set_xlim(0,180)\n",
    "    axes31.set_xlim(0,180)\n",
    "    axes33.set_xlim(0,180)\n",
    "\n",
    "    axes00.grid(True)\n",
    "    axes01.grid(True)\n",
    "    axes02.grid(True)\n",
    "    axes03.grid(True)\n",
    "    axes10.grid(True)\n",
    "    axes11.grid(True)\n",
    "    axes12.grid(True)\n",
    "    axes13.grid(True)\n",
    "    axes20.grid(True)\n",
    "    axes21.grid(True)\n",
    "    axes22.grid(True)\n",
    "    axes23.grid(True)\n",
    "    axes30.grid(True)\n",
    "    axes31.grid(True)\n",
    "    axes32.grid(True)\n",
    "    axes33.grid(True)\n",
    "\n",
    "    handles1 = handles[:4]\n",
    "    labels1 = labels[:4]\n",
    "    handles2 = handles[4:]\n",
    "    labels2 = labels[4:]\n",
    "\n",
    "    # Add legends to each subplot\n",
    "    axes00.legend(handles1, labels1, loc='upper left')\n",
    "    axes01.legend(handles2, labels2, loc='upper right')\n",
    "\n",
    "    fig.text(0.5, 0.93, \"Standard Configuration\",\n",
    "         ha=\"center\", va=\"bottom\", fontweight = 'semibold',\n",
    "         fontsize=plt.rcParams['axes.titlesize'], transform=fig.transFigure)\n",
    "\n",
    "    fig.text(0.5, 0.49, \"Expanded Variables List Configuration\",\n",
    "            ha=\"center\", va=\"bottom\", fontweight = 'semibold',\n",
    "            fontsize=plt.rcParams['axes.titlesize'], transform=fig.transFigure)\n",
    "\n",
    "    # Adjust layout\n",
    "    # plt.tight_layout()\n",
    "    # add space between suptitle\n",
    "    plt.suptitle(f'Four Year Online Precipitation Distributions (Standard and Expanded Variable List Configurations)')\n",
    "    # plt.subplots_adjust(top=0.85, wspace=0.3)  # Adjust the top space and width space between subplots\n",
    "    \n",
    "    # plt.savefig('precipitation_distribution_hist_nopruning_noclass.eps', format='eps', dpi=600)\n",
    "    if save_path:\n",
    "        plt.savefig(os.path.join(save_path, f'precc_dists.png'), dpi=300, bbox_inches='tight')\n",
    "    if show:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2535c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_precc_dists(show = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314eff30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_precc_dists_config(config_name, show = False, save_path = None):\n",
    "    num_years = 4\n",
    "    mmf_1_precc = ds_mmf_1_4_year['PRECT'].values\n",
    "    mmf_1_global_weighting = None\n",
    "    mmf_1_land_weighting = get_pressure_area_weights(ds_mmf_1_4_year, surface_type = 'land')\n",
    "    mmf_1_ocean_weighting = get_pressure_area_weights(ds_mmf_1_4_year, surface_type = 'ocean')\n",
    "    mmf_1_ice_weighting = get_pressure_area_weights(ds_mmf_1_4_year, surface_type = 'ice')\n",
    "    global_tile_area = data_v2_rh_mc.grid_info_area\n",
    "    land_tile_area = data_v2_rh_mc.grid_info_area * np.mean(ds_mmf_1_4_year['LANDFRAC'], axis = 0)\n",
    "    ocean_tile_area = data_v2_rh_mc.grid_info_area * np.mean(ds_mmf_1_4_year['OCNFRAC'], axis = 0)\n",
    "    ice_tile_area = data_v2_rh_mc.grid_info_area * np.mean(ds_mmf_1_4_year['ICEFRAC'], axis = 0)\n",
    "    mmf_flat_global_area_weights = np.tile(global_tile_area, mmf_1_hourly_prect_4_year.shape[0])\n",
    "    mmf_flat_land_area_weights = np.tile(land_tile_area, mmf_1_hourly_prect_4_year.shape[0])\n",
    "    mmf_flat_ocean_area_weights = np.tile(ocean_tile_area, mmf_1_hourly_prect_4_year.shape[0])\n",
    "    mmf_flat_ice_area_weights = np.tile(ice_tile_area, mmf_1_hourly_prect_4_year.shape[0])\n",
    "    \n",
    "    if config_name == 'standard' and num_years == 4:\n",
    "        ds_nn = ds_nn_standard_4_year\n",
    "        nn_hourly_prect = nn_hourly_prect_standard_4_year\n",
    "    elif config_name == 'conf_loss' and num_years == 4:\n",
    "        ds_nn = ds_nn_conf_loss_4_year\n",
    "        nn_hourly_prect = nn_hourly_prect_conf_loss_4_year\n",
    "    elif config_name == 'diff_loss' and num_years == 4:\n",
    "        ds_nn = ds_nn_diff_loss_4_year\n",
    "        nn_hourly_prect = nn_hourly_prect_diff_loss_4_year\n",
    "    elif config_name == 'multirep' and num_years == 4:\n",
    "        ds_nn = ds_nn_multirep_4_year\n",
    "        nn_hourly_prect = nn_hourly_prect_multirep_4_year\n",
    "    elif config_name == 'v6' and num_years == 4:\n",
    "        ds_nn = ds_nn_v6_4_year\n",
    "        nn_hourly_prect = nn_hourly_prect_v6_4_year\n",
    "\n",
    "    nn_global_weighting = {model_name: {seed_number: None for seed_number in seed_numbers} for model_name in model_names.keys()}\n",
    "    nn_land_weighting = {model_name: {seed_number: get_pressure_area_weights(ds_nn[model_name][seed_number], surface_type = 'land') if ds_nn[model_name][seed_number] is not None else mmf_1_land_weighting for seed_number in seed_numbers} for model_name in model_names.keys()}\n",
    "    nn_ocean_weighting = {model_name: {seed_number: get_pressure_area_weights(ds_nn[model_name][seed_number], surface_type = 'ocean') if ds_nn[model_name][seed_number] is not None else mmf_1_ocean_weighting for seed_number in seed_numbers} for model_name in model_names.keys()}\n",
    "    nn_ice_weighting = {model_name: {seed_number: get_pressure_area_weights(ds_nn[model_name][seed_number], surface_type = 'ice') if ds_nn[model_name][seed_number] is not None else mmf_1_ice_weighting for seed_number in seed_numbers} for model_name in model_names.keys()}\n",
    "    \n",
    "    mmf_1_global_precc_mean = np.mean(data_v2_rh_mc.zonal_bin_weight_2d(mmf_1_precc, custom_weighting = mmf_1_global_weighting) * 86400 * 1000, axis = 0)\n",
    "    mmf_1_land_precc_mean = np.mean(data_v2_rh_mc.zonal_bin_weight_2d(mmf_1_precc, custom_weighting = mmf_1_land_weighting) * 86400 * 1000, axis = 0)\n",
    "    mmf_1_ocean_precc_mean = np.mean(data_v2_rh_mc.zonal_bin_weight_2d(mmf_1_precc, custom_weighting = mmf_1_ocean_weighting) * 86400 * 1000, axis = 0)\n",
    "    mmf_1_ice_precc_mean = np.mean(data_v2_rh_mc.zonal_bin_weight_2d(mmf_1_precc, custom_weighting = mmf_1_ice_weighting) * 86400 * 1000, axis = 0)\n",
    "    \n",
    "    nn_global_precc_mean = {model_name: {seed_number: np.mean(data_v2_rh_mc.zonal_bin_weight_2d(ds_nn[model_name][seed_number]['PRECT'].values, custom_weighting = nn_global_weighting[model_name][seed_number]) * 86400 * 1000, axis = 0)\n",
    "                if ds_nn[model_name][seed_number] is not None and ds_nn[model_name][seed_number]['PRECT'].shape[0] == 12 * num_years else np.full(lat_bin_mids.shape, np.nan) for seed_number in seed_numbers} for model_name in model_names.keys()}\n",
    "    nn_land_precc_mean = {model_name: {seed_number: np.mean(data_v2_rh_mc.zonal_bin_weight_2d(ds_nn[model_name][seed_number]['PRECT'].values, custom_weighting = nn_land_weighting[model_name][seed_number]) * 86400 * 1000, axis = 0)\n",
    "                if ds_nn[model_name][seed_number] is not None and ds_nn[model_name][seed_number]['PRECT'].shape[0] == 12 * num_years else np.full(lat_bin_mids.shape, np.nan) for seed_number in seed_numbers} for model_name in model_names.keys()}\n",
    "    nn_ocean_precc_mean = {model_name: {seed_number: np.mean(data_v2_rh_mc.zonal_bin_weight_2d(ds_nn[model_name][seed_number]['PRECT'].values, custom_weighting = nn_ocean_weighting[model_name][seed_number]) * 86400 * 1000, axis = 0)\n",
    "                if ds_nn[model_name][seed_number] is not None and ds_nn[model_name][seed_number]['PRECT'].shape[0] == 12 * num_years else np.full(lat_bin_mids.shape, np.nan) for seed_number in seed_numbers} for model_name in model_names.keys()}\n",
    "    nn_ice_precc_mean = {model_name: {seed_number: np.mean(data_v2_rh_mc.zonal_bin_weight_2d(ds_nn[model_name][seed_number]['PRECT'].values, custom_weighting = nn_ice_weighting[model_name][seed_number]) * 86400 * 1000, axis = 0)\n",
    "                if ds_nn[model_name][seed_number] is not None and ds_nn[model_name][seed_number]['PRECT'].shape[0] == 12 * num_years else np.full(lat_bin_mids.shape, np.nan) for seed_number in seed_numbers} for model_name in model_names.keys()}\n",
    "\n",
    "    lat_ticks = [-60, -30, 0, 30, 60]\n",
    "    lat_labels = ['60S', '30S', '0', '30N', '60N']\n",
    "    bins_lev = np.arange(-2,180,4)\n",
    "    bin_centers = (bins_lev[:-1] + bins_lev[1:]) / 2\n",
    "\n",
    "    def plot_histogram(ax, data_flat, weights, label, color, linestyle):\n",
    "        hist, bins = np.histogram(data_flat, bins=bins_lev, weights=weights, density=True)\n",
    "        ax.plot(bin_centers, hist, label=label, color=color, linestyle=linestyle, linewidth=2)\n",
    "\n",
    "    fig = plt.figure(figsize=(18, 8))\n",
    "    trans = blended_transform_factory(fig.transFigure, fig.transFigure)\n",
    "\n",
    "    outer = gridspec.GridSpec(3, 1, figure=fig,\n",
    "                            height_ratios=[1, 0.005, 1],  # 2.5% of vertical space as gap\n",
    "                            hspace=0.3)\n",
    "\n",
    "    row0 = gridspec.GridSpecFromSubplotSpec(1, 4, subplot_spec=outer[0], hspace=0.3, wspace=0.3)\n",
    "    row1 = gridspec.GridSpecFromSubplotSpec(1, 4, subplot_spec=outer[2], hspace=0.3, wspace=0.3)\n",
    "\n",
    "    axes00 = fig.add_subplot(row0[0])\n",
    "    axes01 = fig.add_subplot(row0[1])\n",
    "    axes02 = fig.add_subplot(row0[2])\n",
    "    axes03 = fig.add_subplot(row0[3])\n",
    "    axes10 = fig.add_subplot(row1[0])\n",
    "    axes11 = fig.add_subplot(row1[1])\n",
    "    axes12 = fig.add_subplot(row1[2])\n",
    "    axes13 = fig.add_subplot(row1[3])\n",
    "\n",
    "    axes_list = [axes00, axes01, axes02, axes03, axes10, axes11, axes12, axes13]\n",
    "    label = ord('a')\n",
    "    for ax in axes_list:\n",
    "        ax.text(-0.12, 1.1, f\"({chr(label)})\", transform=ax.transAxes,\n",
    "                fontsize=12, va=\"top\")\n",
    "        label += 1  # Increment label for the next subfigure\n",
    "\n",
    "    global_x_pos = (axes00.get_position().x0 + axes01.get_position().x1)/2\n",
    "    land_x_pos = (axes02.get_position().x0 + axes03.get_position().x1)/2\n",
    "    ocean_x_pos = (axes10.get_position().x0 + axes11.get_position().x1)/2\n",
    "    ice_x_pos = (axes12.get_position().x0 + axes13.get_position().x1)/2\n",
    "    global_y_pos = land_y_pos = axes00.get_position().y1 + .035\n",
    "    ocean_y_pos = ice_y_pos = axes10.get_position().y1 + .035\n",
    "    \n",
    "    fig.text(global_x_pos, global_y_pos, 'Global', ha=\"center\", va=\"bottom\", transform=trans, fontsize=plt.rcParams['axes.titlesize'], fontweight='semibold')\n",
    "    fig.text(land_x_pos, land_y_pos, 'Land', ha=\"center\", va=\"bottom\", transform=trans, fontsize=plt.rcParams['axes.titlesize'], fontweight='semibold')\n",
    "    fig.text(ocean_x_pos, ocean_y_pos, 'Ocean', ha=\"center\", va=\"bottom\", transform=trans, fontsize=plt.rcParams['axes.titlesize'], fontweight='semibold')\n",
    "    fig.text(ice_x_pos, ice_y_pos, 'Ice', ha=\"center\", va=\"bottom\", transform=trans, fontsize=plt.rcParams['axes.titlesize'], fontweight='semibold')\n",
    "\n",
    "    axes00.plot(lat_bin_mids, mmf_1_global_precc_mean, label='MMF', color='black', linestyle='-')\n",
    "    axes02.plot(lat_bin_mids, mmf_1_land_precc_mean, label='MMF', color='black', linestyle='-')\n",
    "    axes10.plot(lat_bin_mids, mmf_1_ocean_precc_mean, label='MMF', color='black', linestyle='-')\n",
    "    axes12.plot(lat_bin_mids, mmf_1_ice_precc_mean, label='MMF', color='black', linestyle='-')\n",
    "\n",
    "    for model_name in model_names.keys():\n",
    "        model_global_mean_arr = np.array([nn_global_precc_mean[model_name][seed_number] for seed_number in seed_numbers])\n",
    "        model_land_mean_arr = np.array([nn_land_precc_mean[model_name][seed_number] for seed_number in seed_numbers])\n",
    "        model_ocean_mean_arr = np.array([nn_ocean_precc_mean[model_name][seed_number] for seed_number in seed_numbers])\n",
    "        model_ice_mean_arr = np.array([nn_ice_precc_mean[model_name][seed_number] for seed_number in seed_numbers])\n",
    "        if np.sum(np.isnan(model_global_mean_arr)) != model_global_mean_arr.size:\n",
    "            axes00.fill_between(\n",
    "                lat_bin_mids,\n",
    "                np.nanmin(model_global_mean_arr, axis=0),\n",
    "                np.nanmax(model_global_mean_arr, axis=0),\n",
    "                color=color_dict[model_name],\n",
    "                alpha=0.15\n",
    "            )\n",
    "            argidx = np.nanargmin(np.nanmean(np.abs(model_global_mean_arr - np.nanmedian(model_global_mean_arr, axis = 0)), axis=1))\n",
    "            axes00.plot(lat_bin_mids, model_global_mean_arr[argidx, :], label = f\"{model_names[model_name]}\", color=color_dict[model_name], linestyle='--')\n",
    "            axes02.fill_between(\n",
    "                lat_bin_mids,\n",
    "                np.nanmin(model_land_mean_arr, axis=0),\n",
    "                np.nanmax(model_land_mean_arr, axis=0),\n",
    "                color=color_dict[model_name],\n",
    "                alpha=0.15\n",
    "            )\n",
    "            argidx = np.nanargmin(np.nanmean(np.abs(model_land_mean_arr - np.nanmedian(model_land_mean_arr, axis = 0)), axis=1))\n",
    "            axes02.plot(lat_bin_mids, model_land_mean_arr[argidx, :], label = f\"{model_names[model_name]}\", color=color_dict[model_name], linestyle='--')\n",
    "            axes10.fill_between(\n",
    "                lat_bin_mids,\n",
    "                np.nanmin(model_ocean_mean_arr, axis=0),\n",
    "                np.nanmax(model_ocean_mean_arr, axis=0),\n",
    "                color=color_dict[model_name],\n",
    "                alpha=0.15\n",
    "            )\n",
    "            argidx = np.nanargmin(np.nanmean(np.abs(model_ocean_mean_arr - np.nanmedian(model_ocean_mean_arr, axis = 0)), axis=1))\n",
    "            axes10.plot(lat_bin_mids, model_ocean_mean_arr[argidx, :], label = f\"{model_names[model_name]}\", color=color_dict[model_name], linestyle='--')\n",
    "            axes12.fill_between(\n",
    "                lat_bin_mids,\n",
    "                np.nanmin(model_ice_mean_arr, axis=0),\n",
    "                np.nanmax(model_ice_mean_arr, axis=0),\n",
    "                color=color_dict[model_name],\n",
    "                alpha=0.15\n",
    "            )\n",
    "            argidx = np.nanargmin(np.nanmean(np.abs(model_ice_mean_arr - np.nanmedian(model_ice_mean_arr, axis = 0)), axis=1))\n",
    "            axes12.plot(lat_bin_mids, model_ice_mean_arr[argidx, :], label = f\"{model_names[model_name]}\", color=color_dict[model_name], linestyle='--')\n",
    "\n",
    "    plot_histogram(axes01, mmf_1_hourly_prect_4_year_flat, mmf_flat_global_area_weights, 'MMF', 'black', '-')\n",
    "    plot_histogram(axes03, mmf_1_hourly_prect_4_year_flat, mmf_flat_land_area_weights, 'MMF', 'black', '-')\n",
    "    plot_histogram(axes11, mmf_1_hourly_prect_4_year_flat, mmf_flat_ocean_area_weights, 'MMF', 'black', '-')\n",
    "    plot_histogram(axes13, mmf_1_hourly_prect_4_year_flat, mmf_flat_ice_area_weights, 'MMF', 'black', '-')\n",
    "\n",
    "    for model_name in model_names.keys():\n",
    "        if not all(len(nn_hourly_prect[model_name][seed_number]) == 0 for seed_number in seed_numbers):\n",
    "            model_global_mean_arr = np.array([nn_global_precc_mean[model_name][seed_number] for seed_number in seed_numbers])\n",
    "            model_land_mean_arr = np.array([nn_land_precc_mean[model_name][seed_number] for seed_number in seed_numbers])\n",
    "            model_ocean_mean_arr = np.array([nn_ocean_precc_mean[model_name][seed_number] for seed_number in seed_numbers])\n",
    "            model_ice_mean_arr = np.array([nn_ice_precc_mean[model_name][seed_number] for seed_number in seed_numbers])\n",
    "            if np.sum(np.isnan(model_global_mean_arr)) != model_global_mean_arr.size:\n",
    "                nn_global_prect_hist = np.array([np.histogram(np.array(nn_hourly_prect[model_name][seed_number]).flatten(),\n",
    "                                                              bins=bins_lev,\n",
    "                                                              weights=np.tile(global_tile_area, np.array(nn_hourly_prect[model_name][seed_number]).shape[0]),\n",
    "                                                              density=True)[0] for seed_number in seed_numbers])\n",
    "                nn_land_prect_hist = np.array([np.histogram(np.array(nn_hourly_prect[model_name][seed_number]).flatten(),\n",
    "                                                              bins=bins_lev,\n",
    "                                                              weights=np.tile(land_tile_area, np.array(nn_hourly_prect[model_name][seed_number]).shape[0]),\n",
    "                                                              density=True)[0] for seed_number in seed_numbers])\n",
    "                nn_ocean_prect_hist = np.array([np.histogram(np.array(nn_hourly_prect[model_name][seed_number]).flatten(),\n",
    "                                                              bins=bins_lev,\n",
    "                                                              weights=np.tile(ocean_tile_area, np.array(nn_hourly_prect[model_name][seed_number]).shape[0]),\n",
    "                                                              density=True)[0] for seed_number in seed_numbers])\n",
    "                nn_ice_prect_hist = np.array([np.histogram(np.array(nn_hourly_prect[model_name][seed_number]).flatten(),\n",
    "                                                              bins=bins_lev,\n",
    "                                                              weights=np.tile(ice_tile_area, np.array(nn_hourly_prect[model_name][seed_number]).shape[0]),\n",
    "                                                              density=True)[0] for seed_number in seed_numbers])\n",
    "                axes01.fill_between(\n",
    "                    bin_centers,\n",
    "                    np.nanmin(nn_global_prect_hist, axis=0),\n",
    "                    np.nanmax(nn_global_prect_hist, axis=0),\n",
    "                    color=color_dict[model_name],\n",
    "                    alpha=0.15\n",
    "                )\n",
    "                argidx = np.nanargmin(np.nanmean(np.abs(nn_global_prect_hist - np.nanmedian(nn_global_prect_hist, axis = 0)), axis=1))\n",
    "                axes01.plot(bin_centers, nn_global_prect_hist[argidx, :], label = f\"{model_names[model_name]}\", color=color_dict[model_name], linestyle='--')\n",
    "                axes03.fill_between(\n",
    "                    bin_centers,\n",
    "                    np.nanmin(nn_land_prect_hist, axis=0),\n",
    "                    np.nanmax(nn_land_prect_hist, axis=0),\n",
    "                    color=color_dict[model_name],\n",
    "                    alpha=0.15\n",
    "                )\n",
    "                argidx = np.nanargmin(np.nanmean(np.abs(nn_land_prect_hist - np.nanmedian(nn_land_prect_hist, axis = 0)), axis=1))\n",
    "                axes03.plot(bin_centers, nn_land_prect_hist[argidx, :], label = f\"{model_names[model_name]}\", color=color_dict[model_name], linestyle='--')\n",
    "                axes11.fill_between(\n",
    "                    bin_centers,\n",
    "                    np.nanmin(nn_ocean_prect_hist, axis=0),\n",
    "                    np.nanmax(nn_ocean_prect_hist, axis=0),\n",
    "                    color=color_dict[model_name],\n",
    "                    alpha=0.15\n",
    "                )\n",
    "                argidx = np.nanargmin(np.nanmean(np.abs(nn_ocean_prect_hist - np.nanmedian(nn_ocean_prect_hist, axis = 0)), axis=1))\n",
    "                axes11.plot(bin_centers, nn_ocean_prect_hist[argidx, :], label = f\"{model_names[model_name]}\", color=color_dict[model_name], linestyle='--')\n",
    "                axes13.fill_between(\n",
    "                    bin_centers,\n",
    "                    np.nanmin(nn_ice_prect_hist, axis=0),\n",
    "                    np.nanmax(nn_ice_prect_hist, axis=0),\n",
    "                    color=color_dict[model_name],\n",
    "                    alpha=0.15\n",
    "                )\n",
    "                argidx = np.nanargmin(np.nanmean(np.abs(nn_ice_prect_hist - np.nanmedian(nn_ice_prect_hist, axis = 0)), axis=1))\n",
    "                axes13.plot(bin_centers, nn_ice_prect_hist[argidx, :], label = f\"{model_names[model_name]}\", color=color_dict[model_name], linestyle='--')\n",
    "\n",
    "    handles, labels = axes00.get_legend_handles_labels()\n",
    "\n",
    "    axes00.legend(ncol=2)\n",
    "\n",
    "    axes00.set_xticks(lat_ticks)\n",
    "    axes02.set_xticks(lat_ticks)\n",
    "    axes10.set_xticks(lat_ticks)\n",
    "    axes12.set_xticks(lat_ticks)\n",
    "\n",
    "    axes00.set_xticklabels(lat_labels)\n",
    "    axes02.set_xticklabels(lat_labels)\n",
    "    axes10.set_xticklabels(lat_labels)\n",
    "    axes12.set_xticklabels(lat_labels)\n",
    "    \n",
    "    axes00.set_title('Mean Precipitation')\n",
    "    axes02.set_title('Mean Precipitation')\n",
    "    axes01.set_title('Histogram of Precipitation')\n",
    "    axes03.set_title('Histogram of Precipitation')\n",
    "    \n",
    "    axes00.set_ylim(0, 8)\n",
    "    axes02.set_ylim(0, 8)\n",
    "    axes10.set_ylim(0, 8)\n",
    "    axes12.set_ylim(0, 8)\n",
    "    axes01.set_ylim(1e-8,0.5)\n",
    "    axes03.set_ylim(1e-8,0.5)\n",
    "    axes11.set_ylim(1e-8,0.5)\n",
    "    axes13.set_ylim(1e-8,0.5)\n",
    "\n",
    "    axes00.set_ylabel('Precipitation (mm/day)')\n",
    "    axes02.set_ylabel('Precipitation (mm/day)')\n",
    "    axes10.set_ylabel('Precipitation (mm/day)')\n",
    "    axes12.set_ylabel('Precipitation (mm/day)')\n",
    "    axes01.set_ylabel('Frequency')\n",
    "    axes03.set_ylabel('Frequency')\n",
    "    axes11.set_ylabel('Frequency')\n",
    "    axes13.set_ylabel('Frequency')\n",
    "\n",
    "    axes01.set_yscale('log')\n",
    "    axes03.set_yscale('log')\n",
    "    axes11.set_yscale('log')\n",
    "    axes13.set_yscale('log')\n",
    "\n",
    "    axes00.set_xlim(-90,90)\n",
    "    axes02.set_xlim(-90,90)\n",
    "    axes10.set_xlim(-90,90)\n",
    "    axes12.set_xlim(-90,90)\n",
    "    axes01.set_xlim(0,180)\n",
    "    axes03.set_xlim(0,180)\n",
    "    axes11.set_xlim(0,180)\n",
    "    axes13.set_xlim(0,180)\n",
    "\n",
    "    axes00.grid(True)\n",
    "    axes01.grid(True)\n",
    "    axes02.grid(True)\n",
    "    axes03.grid(True)\n",
    "    axes10.grid(True)\n",
    "    axes11.grid(True)\n",
    "    axes12.grid(True)\n",
    "    axes13.grid(True)\n",
    "    \n",
    "    handles1 = handles[:4]\n",
    "    labels1 = labels[:4]\n",
    "    handles2 = handles[4:]\n",
    "    labels2 = labels[4:]\n",
    "\n",
    "    # Add legends to each subplot\n",
    "    axes00.legend(handles1, labels1, loc='upper left')\n",
    "    axes01.legend(handles2, labels2, loc='upper right')\n",
    "    \n",
    "    # Adjust layout\n",
    "    # plt.tight_layout()\n",
    "    # add space between suptitle\n",
    "    plt.suptitle(f'Four Year Online Precipitation Distributions ({config_names[config_name]} Configuration)')\n",
    "    # plt.subplots_adjust(top=0.85, wspace=0.3)  # Adjust the top space and width space between subplots\n",
    "    \n",
    "    # plt.savefig('precipitation_distribution_hist_nopruning_noclass.eps', format='eps', dpi=600)\n",
    "    if save_path:\n",
    "        plt.savefig(os.path.join(save_path, f'precc_dists_{config_name}.png'), dpi=300, bbox_inches='tight')\n",
    "    if show:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9895d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_precc_dists_config('conf_loss', show = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535e4ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_precc_dists_config('diff_loss', show = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a51122f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_precc_dists_config('multirep', show = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fd3785",
   "metadata": {},
   "source": [
    "## Figure 9 (Offline Moistening Bias Zonal Mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f5b2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_offline_bias_model_comparison(config_name, var, show = True, save_path = None):\n",
    "    unet_preds = np.mean(np.array([config_preds[config_name]['unet'](seed) for seed in seeds]), axis = 0)\n",
    "    squeezeformer_preds = np.mean(np.array([config_preds[config_name]['squeezeformer'](seed) for seed in seeds]), axis = 0)\n",
    "    pure_resLSTM_preds = np.mean(np.array([config_preds[config_name]['pure_resLSTM'](seed) for seed in seeds]), axis = 0)\n",
    "    pao_model_preds = np.mean(np.array([config_preds[config_name]['pao_model'](seed) for seed in seeds]), axis = 0)\n",
    "    convnext_preds = np.mean(np.array([config_preds[config_name]['convnext'](seed) for seed in seeds]), axis = 0)\n",
    "    encdec_lstm_preds = np.mean(np.array([config_preds[config_name]['encdec_lstm'](seed) for seed in seeds]), axis = 0)\n",
    "    unet_diff = offline_var_settings[var]['scaling'] * offline_area_time_mean_3d(unet_preds[:,:,offline_var_settings[var]['var_index']:(offline_var_settings[var]['var_index']+60)] - actual_target[:,:,offline_var_settings[var]['var_index']:(offline_var_settings[var]['var_index']+60)])\n",
    "    squeezeformer_diff = offline_var_settings[var]['scaling'] * offline_area_time_mean_3d(squeezeformer_preds[:,:,offline_var_settings[var]['var_index']:(offline_var_settings[var]['var_index']+60)] - actual_target[:,:,offline_var_settings[var]['var_index']:(offline_var_settings[var]['var_index']+60)])\n",
    "    pure_resLSTM_diff = offline_var_settings[var]['scaling'] * offline_area_time_mean_3d(pure_resLSTM_preds[:,:,offline_var_settings[var]['var_index']:(offline_var_settings[var]['var_index']+60)] - actual_target[:,:,offline_var_settings[var]['var_index']:(offline_var_settings[var]['var_index']+60)])\n",
    "    pao_model_diff = offline_var_settings[var]['scaling'] * offline_area_time_mean_3d(pao_model_preds[:,:,offline_var_settings[var]['var_index']:(offline_var_settings[var]['var_index']+60)] - actual_target[:,:,offline_var_settings[var]['var_index']:(offline_var_settings[var]['var_index']+60)])\n",
    "    convnext_diff = offline_var_settings[var]['scaling'] * offline_area_time_mean_3d(convnext_preds[:,:,offline_var_settings[var]['var_index']:(offline_var_settings[var]['var_index']+60)] - actual_target[:,:,offline_var_settings[var]['var_index']:(offline_var_settings[var]['var_index']+60)])\n",
    "    encdec_lstm_diff = offline_var_settings[var]['scaling'] * offline_area_time_mean_3d(encdec_lstm_preds[:,:,offline_var_settings[var]['var_index']:(offline_var_settings[var]['var_index']+60)] - actual_target[:,:,offline_var_settings[var]['var_index']:(offline_var_settings[var]['var_index']+60)])\n",
    "\n",
    "    # Create a figure with subplots\n",
    "    fig, axs = plt.subplots(2, 3, figsize=(18, 10))\n",
    "    # Generate the panel labels\n",
    "    labels = [f\"({letter})\" for letter in string.ascii_lowercase[:6]]\n",
    "    latitude_ticks = [-60, -30, 0, 30, 60]\n",
    "    latitude_labels = ['60S', '30S', '0', '30N', '60N']\n",
    "    # Loop through each variable and its corresponding subplot row\n",
    "\n",
    "    plotted_artists = {}\n",
    "\n",
    "    plotted_artists['unet'] = unet_diff.plot(ax=axs[0,0], add_colorbar=False, cmap='RdBu_r', vmin=offline_var_settings[var]['vmin'], vmax=offline_var_settings[var]['vmax'])\n",
    "    axs[0,0].set_title(f'{labels[0]} U-Net {offline_var_settings[var][\"var_title\"]} Bias')\n",
    "    axs[0,0].invert_yaxis()\n",
    "    axs[0,0].set_xlabel('')\n",
    "\n",
    "    plotted_artists['squeezeformer'] = squeezeformer_diff.plot(ax=axs[0,1], add_colorbar=False, cmap='RdBu_r', vmin=offline_var_settings[var]['vmin'], vmax=offline_var_settings[var]['vmax'])\n",
    "    axs[0,1].set_title(f'{labels[1]} SqueezeFormer {offline_var_settings[var][\"var_title\"]} Bias')\n",
    "    axs[0,1].invert_yaxis()\n",
    "    axs[0,1].set_ylabel('')\n",
    "    axs[0,1].set_xlabel('')\n",
    "\n",
    "    plotted_artists['pure_resLSTM'] = pure_resLSTM_diff.plot(ax=axs[0,2], add_colorbar=False, cmap='RdBu_r', vmin=offline_var_settings[var]['vmin'], vmax=offline_var_settings[var]['vmax'])\n",
    "    axs[0,2].set_title(f'{labels[2]} Pure ResLSTM {offline_var_settings[var][\"var_title\"]} Bias')\n",
    "    axs[0,2].invert_yaxis()\n",
    "    axs[0,2].set_ylabel('')\n",
    "    axs[0,2].set_xlabel('')\n",
    "\n",
    "    plotted_artists['pao_model'] = pao_model_diff.plot(ax=axs[1,0], add_colorbar=False, cmap='RdBu_r', vmin=offline_var_settings[var]['vmin'], vmax=offline_var_settings[var]['vmax'])\n",
    "    axs[1,0].set_title(f'{labels[3]} Pao Model {offline_var_settings[var][\"var_title\"]} Bias')\n",
    "    axs[1,0].invert_yaxis()\n",
    "    axs[1,0].set_xlabel('Latitude')\n",
    "\n",
    "    plotted_artists['convnext'] = convnext_diff.plot(ax=axs[1,1], add_colorbar=False, cmap='RdBu_r', vmin=offline_var_settings[var]['vmin'], vmax=offline_var_settings[var]['vmax'])\n",
    "    axs[1,1].set_title(f'{labels[4]} ConvNeXt {offline_var_settings[var][\"var_title\"]} Bias')\n",
    "    axs[1,1].invert_yaxis()\n",
    "    axs[1,1].set_xlabel('Latitude')\n",
    "    axs[1,1].set_ylabel('')\n",
    "\n",
    "    plotted_artists['encdec_lstm'] = encdec_lstm_diff.plot(ax=axs[1,2], add_colorbar=False, cmap='RdBu_r', vmin=offline_var_settings[var]['vmin'], vmax=offline_var_settings[var]['vmax'])\n",
    "    axs[1,2].set_title(f'{labels[5]} Encoder-Decoder LSTM {offline_var_settings[var][\"var_title\"]} Bias')\n",
    "    axs[1,2].invert_yaxis()\n",
    "    axs[1,2].set_xlabel('Latitude')\n",
    "    axs[1,2].set_ylabel('')\n",
    "\n",
    "    # add a colorbar to each subplot\n",
    "\n",
    "    model_order = ['unet', 'squeezeformer', 'pure_resLSTM', 'pao_model', 'convnext', 'encdec_lstm']\n",
    "    for ax, var_key in zip(axs.flat, model_order):\n",
    "        img = plotted_artists[var_key]  # Use the stored artist\n",
    "        if img is not None: # Check if artist exists\n",
    "            cbar = fig.colorbar(img, ax=ax, orientation='vertical', fraction=0.046, pad=0.04)\n",
    "            # if var_key in ['DQ2PHYS', 'DQ3PHYS']:\n",
    "            #     cbar.ax.yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: f\"{x:.0e}\"))\n",
    "        else:\n",
    "            print(f\"Warning: No artist found for variable {var_key} to create colorbar.\")\n",
    "    \n",
    "    for ax in axs.flat:\n",
    "        ax.set_xticks(latitude_ticks)  # Set the positions for the ticks\n",
    "        ax.set_xticklabels(latitude_labels)  # Set the custom text labels\n",
    "    plt.suptitle(f'Offline {offline_var_settings[var][\"var_title\"]} Tendency Biases Averaged Across Seeds ({offline_var_settings[var][\"unit\"]}) ({config_names[config_name]} Configuration)', x = .6, y = .95)\n",
    "    plt.subplots_adjust(right=1, top=.9)\n",
    "    if save_path:\n",
    "        plt.savefig(os.path.join(save_path, f'offline_bias_model_comparison_{config_name}_{var}.png'), dpi=300, bbox_inches='tight')\n",
    "    if show:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4971b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_offline_bias_model_comparison('v6', 'DQ1PHYS', show = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3311d71",
   "metadata": {},
   "source": [
    "## Figure 10 (Offline Moistening Bias Vertical Profile Binned by Precipitation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667770d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_binning_model_comparison(config_name, show = True, save_path = None):\n",
    "    nn_preds = {model_name: np.mean(np.array([config_preds[config_name][model_name](seed) for seed in seeds]), axis = 0) for model_name in model_names.keys()}\n",
    "    moistening_diffs = {model_name: (nn_preds[model_name][:,:,60:120] - actual_target[:,:,60:120]) * offline_var_settings['DQ1PHYS']['scaling'] for model_name in model_names.keys()}\n",
    "    offline_precip_area_weights = {model_name: get_offline_precip_area_weights(nn_preds[model_name]) for model_name in model_names.keys()}\n",
    "    cmap = matplotlib.colormaps['viridis']\n",
    "    colors = cmap(np.linspace(0, 1, 11))\n",
    "    alphas = np.linspace(0.1, 1, 11)\n",
    "    fig, axs = plt.subplots(2, 3, figsize=(16, 10), constrained_layout=True)\n",
    "    ax_flat = axs.flatten()\n",
    "    letter_labels = [f\"({letter})\" for letter in string.ascii_lowercase[:6]]\n",
    "    for ax_idx, model_name in enumerate(model_names.keys()):\n",
    "        for precip_idx, precip_key in enumerate(offline_precip_area_weights[model_name].keys()): \n",
    "            ax_flat[ax_idx].plot(np.sum(np.sum(moistening_diffs[model_name] * offline_precip_area_weights[model_name][precip_key], axis=1), axis=0), \n",
    "                                 level, label=precip_percentile_labels[precip_key], linestyle='-', color=colors[precip_idx], alpha=alphas[precip_idx])\n",
    "        ax_flat[ax_idx].invert_yaxis()\n",
    "        if ax_idx > 2:\n",
    "            ax_flat[ax_idx].set_xlabel('Moistening Tendency Bias (g/kg/s)')\n",
    "        if ax_idx == 0 or ax_idx == 3:\n",
    "            ax_flat[ax_idx].set_ylabel('Hybrid Pressure Level (hPa)')\n",
    "        ax_flat[ax_idx].set_title(f'{letter_labels[ax_idx]} {model_names[model_name]}')\n",
    "        ax_flat[ax_idx].legend()\n",
    "        ax_flat[ax_idx].grid(True)\n",
    "        ax_flat[ax_idx].set_xlim(-1.4e-6, 2.2e-6)\n",
    "    plt.suptitle(f'Seed-Averaged Binned Offline Moistening Tendency Bias by Active Precipitation Percentile ({config_names[config_name]} Configuration)')\n",
    "    if save_path:\n",
    "        plt.savefig(os.path.join(save_path, f'offline_binned_moistening_tendency_bias_model_comparison_{config_name}.png'), dpi=300, bbox_inches='tight')\n",
    "    if show:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_binning_model_comparison(config_name = 'v6', show = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3447521",
   "metadata": {},
   "source": [
    "## Figure 9 and 10 combo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda037c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xarray_minmax_magnitude(data_array, minmax = None, dim=None):\n",
    "    assert minmax in ['min', 'max'], \"minmax must be either 'min' or 'max'\"\n",
    "    # Get indices of minimum or maximum absolute values\n",
    "    if minmax == 'min':\n",
    "        idx = np.abs(data_array).argmin(dim=dim)\n",
    "    else:\n",
    "        idx = np.abs(data_array).argmax(dim=dim)\n",
    "    return data_array.isel({dim: idx})\n",
    "\n",
    "def show_offline_moistening_bias(config_name, var, show = True, save_path = None):\n",
    "    nn_preds = {model_name: np.mean(np.array([config_preds[config_name][model_name](seed) for seed in seeds]), axis = 0) for model_name in model_names.keys()}\n",
    "    moistening_diffs = {model_name: (nn_preds[model_name][:,:,60:120] - actual_target[:,:,60:120]) * offline_var_settings['DQ1PHYS']['scaling'] for model_name in model_names.keys()}\n",
    "    offline_precip_area_weights = {model_name: get_offline_precip_area_weights(nn_preds[model_name]) for model_name in model_names.keys()}\n",
    "    moistening_diffs_zonal_mean = {model_name: offline_area_time_mean_3d((nn_preds[model_name][:,:,60:120] - actual_target[:,:,60:120])) * offline_var_settings['DQ1PHYS']['scaling'] for model_name in model_names.keys()}\n",
    "    combined_zonal_mean_diffs = xr.concat([moistening_diffs_zonal_mean[model_name] for model_name in model_names.keys()], dim='ensemble')\n",
    "    combined_zonal_mean_diffs_min = xarray_minmax_magnitude(combined_zonal_mean_diffs, minmax='min', dim='ensemble')\n",
    "    combined_zonal_mean_diffs_max = xarray_minmax_magnitude(combined_zonal_mean_diffs, minmax='max', dim='ensemble')\n",
    "\n",
    "    cmap_diffs = 'RdBu_r'\n",
    "    cmap_range = 'Reds'\n",
    "    cmap_binning = matplotlib.colormaps['viridis']\n",
    "    colors = cmap_binning(np.linspace(0, 1, 11))\n",
    "    alphas = np.linspace(0.1, 1, 11)\n",
    "\n",
    "    plotted_artists = {}\n",
    "\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(13, 8))\n",
    "\n",
    "    labels = [f\"({letter})\" for letter in string.ascii_lowercase[:4]]\n",
    "    latitude_ticks = [-60, -30, 0, 30, 60]\n",
    "    latitude_labels = ['60S', '30S', '0', '30N', '60N']\n",
    "\n",
    "    plotted_artists['minimum_zonal'] = combined_zonal_mean_diffs_min.plot(ax=axs[0,0], add_colorbar=False, cmap='RdBu_r', vmin=offline_var_settings[var]['vmin'], vmax=offline_var_settings[var]['vmax'])\n",
    "    axs[0,0].set_title(f'{labels[0]} Minimum Magnitude Zonal Mean Bias', fontsize = 14)\n",
    "    axs[0,0].invert_yaxis()\n",
    "    axs[0,0].set_xlabel('')\n",
    "    plotted_artists['maximum_zonal'] = combined_zonal_mean_diffs_max.plot(ax=axs[1,0], add_colorbar=False, cmap='RdBu_r', vmin=offline_var_settings[var]['vmin'], vmax=offline_var_settings[var]['vmax'])\n",
    "    axs[1,0].set_title(f'{labels[1]} Maximum Magnitude Zonal Mean Bias', fontsize = 14)\n",
    "    axs[1,0].invert_yaxis()\n",
    "\n",
    "    img = plotted_artists['minimum_zonal']\n",
    "    cbar = fig.colorbar(img, ax = axs[0,0], orientation='vertical', fraction=0.046, pad=0.04)\n",
    "    img = plotted_artists['maximum_zonal']\n",
    "    cbar = fig.colorbar(img, ax = axs[1,0], orientation='vertical', fraction=0.046, pad=0.04)\n",
    "\n",
    "    handles = []\n",
    "    legend_labels = []\n",
    "    for precip_idx, precip_key in enumerate(precip_percentile_labels.keys()):\n",
    "        precip_arr = np.stack([np.sum(np.sum(moistening_diffs[model_name] * offline_precip_area_weights[model_name][precip_key], axis=1), axis=0) for model_name in model_names.keys()])\n",
    "        line, = axs[0,1].plot(precip_arr[np.abs(precip_arr).argmin(axis=0), np.arange(60)], level, label=precip_percentile_labels[precip_key], linestyle='-', color=colors[precip_idx], alpha=alphas[precip_idx])\n",
    "        axs[1,1].plot(precip_arr[np.abs(precip_arr).argmax(axis=0), np.arange(60)], level, linestyle='-', color=colors[precip_idx], alpha=alphas[precip_idx])\n",
    "        handles.append(line)\n",
    "        legend_labels.append(precip_percentile_labels[precip_key])\n",
    "    axs[0,1].invert_yaxis()\n",
    "    axs[0,1].set_title(f'{labels[2]} Minimum Magnitude Binned Bias', fontsize = 14)\n",
    "    axs[0,1].grid(True)\n",
    "    axs[0,1].set_xlim(-1.4e-6, 1.4e-6)\n",
    "    axs[1,1].invert_yaxis()\n",
    "    axs[1,1].set_xlabel('g/kg/s')\n",
    "    axs[1,1].set_title(f'{labels[3]} Maximum Magnitude Binned Bias', fontsize = 14)\n",
    "    axs[1,1].grid(True)\n",
    "    axs[1,1].set_xlim(-1.4e-6, 1.4e-6)\n",
    "\n",
    "    split_point = 6\n",
    "    axs[0,1].legend(handles[:split_point], legend_labels[:split_point], loc='upper right', fontsize=9, ncol=1)\n",
    "    axs[1,1].legend(handles[split_point:], legend_labels[split_point:], loc='upper right', fontsize=9, ncol=1)\n",
    "\n",
    "    plt.suptitle(f'Minimum and Maximum Magnitude Offline Moistening Tendency Bias ({config_names[config_name]})')\n",
    "    if save_path:\n",
    "        plt.savefig(os.path.join(save_path, f'offline_binned_moistening_tendency_bias_model_comparison_{config_name}.png'), dpi=300, bbox_inches='tight')\n",
    "    if show:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afc28e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_offline_moistening_bias('standard', 'DQ1PHYS', show = True, save_path = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541ea8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_offline_moistening_bias('conf_loss', 'DQ1PHYS', show = True, save_path = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de78ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_offline_moistening_bias('diff_loss', 'DQ1PHYS', show = True, save_path = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abc1940",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_offline_moistening_bias('multirep', 'DQ1PHYS', show = True, save_path = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f589d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_offline_moistening_bias('v6', 'DQ1PHYS', show = True, save_path = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2804fd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_offline_moistening_bias('standard', 'DTPHYS', show = True, save_path = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40e6fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_offline_moistening_bias('conf_loss', 'DTPHYS', show = True, save_path = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a334bb58",
   "metadata": {},
   "source": [
    "## Figure 11 (Five Year Global Mean RMSE vs SYPD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abca135",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_global_rmse_vs_sypd(show = True, save_path = None):\n",
    "    variables = ['T', 'Q', 'CLDLIQ', 'CLDICE', 'U', 'V']\n",
    "    ylim_upper = {\n",
    "        'T': 5,\n",
    "        'Q': 0.7,\n",
    "        'CLDLIQ': 40,\n",
    "        'CLDICE': 8,\n",
    "        'U': 9,\n",
    "        'V': 2.5\n",
    "    }\n",
    "    marker_config_dict = {\n",
    "        'standard': 'o',\n",
    "        'conf_loss': '*',\n",
    "        'diff_loss': '^',\n",
    "        'multirep': 'v',\n",
    "        'v6': 'D'\n",
    "    }\n",
    "    markersize_config_dict = {\n",
    "        'standard': 8,\n",
    "        'conf_loss': 11,\n",
    "        'diff_loss': 8,\n",
    "        'multirep': 8,\n",
    "        'v6': 6\n",
    "    }\n",
    "\n",
    "    sublabels = [f'({chr(97 + i)})' for i in range(6)]\n",
    "    # Create the figure with custom subplot layout\n",
    "    fig = plt.figure(figsize=(11, 12.5), constrained_layout = True)\n",
    "    gs = gridspec.GridSpec(4, 3, figure=fig, height_ratios=[1,1,.75,.75])\n",
    "\n",
    "    #     # First row: 3 square scatter plots\n",
    "    #     ax1 = plt.subplot2grid((4, 3), (0, 0))\n",
    "    #     ax2 = plt.subplot2grid((4, 3), (0, 1))\n",
    "    #     ax3 = plt.subplot2grid((4, 3), (0, 2))\n",
    "\n",
    "    #     # Second row: 3 square scatter plots\n",
    "    #     ax4 = plt.subplot2grid((4, 3), (1, 0))\n",
    "    #     ax5 = plt.subplot2grid((4, 3), (1, 1))\n",
    "    #     ax6 = plt.subplot2grid((4, 3), (1, 2))\n",
    "\n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    ax2 = fig.add_subplot(gs[0, 1])\n",
    "    ax3 = fig.add_subplot(gs[0, 2])\n",
    "\n",
    "    # Second row: 3 square scatter plots\n",
    "    ax4 = fig.add_subplot(gs[1, 0])\n",
    "    ax5 = fig.add_subplot(gs[1, 1])\n",
    "    ax6 = fig.add_subplot(gs[1, 2])\n",
    "\n",
    "    scatter_axes = [ax1, ax2, ax3, ax4, ax5, ax6]\n",
    "\n",
    "    #     # Third row: one rectangular plot spanning all 3 columns\n",
    "    #     ax7 = plt.subplot2grid((4, 3), (2, 0), colspan=3)\n",
    "\n",
    "    #     # Fourth row: one rectangular plot spanning all 3 columns\n",
    "    #     ax8 = plt.subplot2grid((4, 3), (3, 0), colspan=3)\n",
    "\n",
    "    # Third row: one rectangular plot spanning all 3 columns\n",
    "    ax7 = fig.add_subplot(gs[2, :])\n",
    "\n",
    "    # Fourth row: one rectangular plot spanning all 3 columns\n",
    "    ax8 = fig.add_subplot(gs[3, :])\n",
    "    \n",
    "    sublabel_idx = 0\n",
    "    for ax, var in zip(scatter_axes, variables):\n",
    "        ax.axvline(x = min(huetal_sota_dict[var]), ymin = 0, ymax = 30, linestyle = '--', color = 'grey', alpha = .7)\n",
    "\n",
    "        for idx, nn_sim in enumerate(nonnan_rmse_dict[var]):\n",
    "            ax.scatter(nn_sim['rmse'], nn_sim['sypd'], marker = marker_config_dict[nn_sim['config_name']], color = color_dict[nn_sim['model_name']], alpha = .7, antialiased = True)\n",
    "\n",
    "        ax.set_xlim(left = 0, right = ylim_upper[var])\n",
    "        ax.tick_params(axis='both')\n",
    "        ax.set_title(f\"{sublabels[sublabel_idx]} {online_var_settings[var]['var_title']} ({online_var_settings[var]['unit']})\", loc='center')  # Add main title with subplot label\n",
    "        ax.set_xlabel(f\"RMSE ({online_var_settings[var]['unit']})\")  # Keep unit in x-label\n",
    "        ax.grid(True, alpha = .5)\n",
    "        sublabel_idx += 1\n",
    "\n",
    "    # Create bar chart data for the middle plot\n",
    "    unet_pc = [[pc_dict[config_name][model_name] for model_name in pc_dict[config_name].keys() if 'unet' in model_name][0] for config_name in config_names.keys()]\n",
    "    squeezeformer_pc = [[pc_dict[config_name][model_name] for model_name in pc_dict[config_name].keys() if 'squeezeformer' in model_name][0] for config_name in config_names.keys()]\n",
    "    pure_resLSTM_pc = [[pc_dict[config_name][model_name] for model_name in pc_dict[config_name].keys() if 'pure_resLSTM' in model_name][0] for config_name in config_names.keys()]\n",
    "    pao_model_pc = [[pc_dict[config_name][model_name] for model_name in pc_dict[config_name].keys() if 'pao_model' in model_name][0] for config_name in config_names.keys()]\n",
    "    convnext_pc = [[pc_dict[config_name][model_name] for model_name in pc_dict[config_name].keys() if 'convnext' in model_name][0] for config_name in config_names.keys()]\n",
    "    encdec_lstm_pc = [[pc_dict[config_name][model_name] for model_name in pc_dict[config_name].keys() if 'encdec_lstm' in model_name][0] for config_name in config_names.keys()]\n",
    "\n",
    "    x_positions = np.arange(len(config_names.values()))\n",
    "    bar_width = 0.12\n",
    "    \n",
    "    # Calculate positions for 6 bars centered around each quarter\n",
    "    offsets = [-2.5, -1.5, -0.5, 0.5, 1.5, 2.5]\n",
    "\n",
    "    # Plot grouped bar charts with 6 products\n",
    "    ax7.bar(x_positions + offsets[0] * bar_width, unet_pc, bar_width, \n",
    "            label=model_names['unet'], color=color_dict['unet'])\n",
    "    ax7.bar(x_positions + offsets[1] * bar_width, squeezeformer_pc, bar_width, \n",
    "            label=model_names['squeezeformer'], color=color_dict['squeezeformer'])\n",
    "    ax7.bar(x_positions + offsets[2] * bar_width, pure_resLSTM_pc, bar_width, \n",
    "            label=model_names['pure_resLSTM'], color=color_dict['pure_resLSTM'])\n",
    "    ax7.bar(x_positions + offsets[3] * bar_width, pao_model_pc, bar_width, \n",
    "            label=model_names['pao_model'], color=color_dict['pao_model'])\n",
    "    ax7.bar(x_positions + offsets[4] * bar_width, convnext_pc, bar_width, \n",
    "            label=model_names['convnext'], color=color_dict['convnext'])\n",
    "    ax7.bar(x_positions + offsets[5] * bar_width, encdec_lstm_pc, bar_width, \n",
    "            label=model_names['encdec_lstm'], color=color_dict['encdec_lstm'])\n",
    "\n",
    "    # Customize the middle plot\n",
    "    ax7.set_title('(g) Trainable Parameter Count Per Architecture Across Configurations')\n",
    "    ax7.set_ylabel('Parameter Count')\n",
    "    ax7.set_xticks(x_positions)\n",
    "    ax7.set_xticklabels(config_names.values())\n",
    "    # ax7.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "\n",
    "    # Create bar chart data for the bottom plot\n",
    "    unet_tt = [np.mean([tt_dict[config_name][model_name] for model_name in tt_dict[config_name].keys() if 'unet' in model_name]) for config_name in config_names.keys()]\n",
    "    squeezeformer_tt = [np.mean([tt_dict[config_name][model_name] for model_name in tt_dict[config_name].keys() if 'squeezeformer' in model_name]) for config_name in config_names.keys()]\n",
    "    pure_resLSTM_tt = [np.mean([tt_dict[config_name][model_name] for model_name in tt_dict[config_name].keys() if 'pure_resLSTM' in model_name]) for config_name in config_names.keys()]\n",
    "    pao_model_tt = [np.mean([tt_dict[config_name][model_name] for model_name in tt_dict[config_name].keys() if 'pao_model' in model_name]) for config_name in config_names.keys()]\n",
    "    convnext_tt = [np.mean([tt_dict[config_name][model_name] for model_name in tt_dict[config_name].keys() if 'convnext' in model_name]) for config_name in config_names.keys()]\n",
    "    encdec_lstm_tt = [np.mean([tt_dict[config_name][model_name] for model_name in tt_dict[config_name].keys() if 'encdec_lstm' in model_name]) for config_name in config_names.keys()]\n",
    "\n",
    "    # Plot grouped bar charts with 6 products\n",
    "    ax8.bar(x_positions + offsets[0] * bar_width, unet_tt, bar_width, \n",
    "            label=model_names['unet'], color=color_dict['unet'])\n",
    "    ax8.bar(x_positions + offsets[1] * bar_width, squeezeformer_tt, bar_width, \n",
    "            label=model_names['squeezeformer'], color=color_dict['squeezeformer'])\n",
    "    ax8.bar(x_positions + offsets[2] * bar_width, pure_resLSTM_tt, bar_width, \n",
    "            label=model_names['pure_resLSTM'], color=color_dict['pure_resLSTM'])\n",
    "    ax8.bar(x_positions + offsets[3] * bar_width, pao_model_tt, bar_width, \n",
    "            label=model_names['pao_model'], color=color_dict['pao_model'])\n",
    "    ax8.bar(x_positions + offsets[4] * bar_width, convnext_tt, bar_width, \n",
    "            label=model_names['convnext'], color=color_dict['convnext'])\n",
    "    ax8.bar(x_positions + offsets[5] * bar_width, encdec_lstm_tt, bar_width, \n",
    "            label=model_names['encdec_lstm'], color=color_dict['encdec_lstm'])\n",
    "\n",
    "    # Customize the middle plot\n",
    "    ax8.set_title('(h) Seed-Averaged Training Time Per Architecture Across Configurations')\n",
    "    ax8.set_ylabel('Hours')\n",
    "    ax8.set_xticks(x_positions)\n",
    "    ax8.set_xticklabels(config_names.values())\n",
    "    # ax8.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "\n",
    "    for ax in [ax7, ax8]:\n",
    "        ax.grid(True, axis = 'y', which='major', linestyle='-', alpha=0.7)\n",
    "        ax.grid(True, axis = 'y', which='minor', linestyle='--', alpha=0.4)\n",
    "        ax.minorticks_on()  # Enable minor ticks for more grid lines\n",
    "\n",
    "    # --- Proxy lines for models (color key) ---\n",
    "    huetal_line = mlines.Line2D([], [], color='grey', lw=2, linestyle = '--', label='Hu et al. 2025')\n",
    "    unet_line = mlines.Line2D([0], [0], marker='s', color='w', markerfacecolor=color_dict['unet'], markersize=8, label=f'{model_names[\"unet\"]}')\n",
    "    squeezeformer_line = mlines.Line2D([0], [0], marker='s', color='w', markerfacecolor=color_dict['squeezeformer'], markersize=8, label=f'{model_names[\"squeezeformer\"]}')\n",
    "    pure_resLSTM_line = mlines.Line2D([0], [0], marker='s', color='w', markerfacecolor=color_dict['pure_resLSTM'], markersize=8, label=f'{model_names[\"pure_resLSTM\"]}')\n",
    "    pao_model_line = mlines.Line2D([0], [0], marker='s', color='w', markerfacecolor=color_dict['pao_model'], markersize=8, label=f'{model_names[\"pao_model\"]}')\n",
    "    convnext_line = mlines.Line2D([0], [0], marker='s', color='w', markerfacecolor=color_dict['convnext'], markersize=8, label=f'{model_names[\"convnext\"]}')\n",
    "    encdec_lstm_line = mlines.Line2D([0], [0], marker='s', color='w', markerfacecolor=color_dict['encdec_lstm'], markersize=8, label=f'{model_names[\"encdec_lstm\"]}')\n",
    "\n",
    "    # --- Proxy \"letters\" for configurations (letter key) ---\n",
    "    shape_handles = [\n",
    "        mlines.Line2D([0], [0], marker=marker, color='w', markerfacecolor='gray', markersize=markersize_config_dict[label], label=config_names[label], linestyle='None') for label, marker in marker_config_dict.items()\n",
    "    ]\n",
    "\n",
    "    # First, add the model legend\n",
    "    legend1 = fig.legend(handles=[huetal_line, unet_line, squeezeformer_line, pure_resLSTM_line, pao_model_line, convnext_line, encdec_lstm_line], \n",
    "                        loc='center left', bbox_to_anchor=(1.0, .6), \n",
    "                        title='Model Architectures')\n",
    "\n",
    "    # Then, add the configuration legend\n",
    "    legend2 = fig.legend(handles=shape_handles, \n",
    "                        loc='center left', bbox_to_anchor=(1.0, 0.35), \n",
    "                        title='Configurations')\n",
    "\n",
    "    fig.gca().add_artist(legend1)  # Make sure both legends show up\n",
    "\n",
    "    # handles = [line_mmf, line_unet, line_squeezeformer, line_pure_resLSTM, line_pao_model, line_convnext, line_encdec_lstm]\n",
    "    # labels = ['MMF2', model_names['unet'], model_names['squeezeformer'], model_names['pure_resLSTM'], model_names['pao_model'], model_names['convnext'], model_names['encdec_lstm']]\n",
    "\n",
    "    # fig.legend(handles, labels, loc='center right', bbox_to_anchor=(1.27, 0.5), title='Model')\n",
    "    fig.suptitle(f'(a-f) Five Year Online Global Mean RMSE vs. SYPD')\n",
    "    # Set a shared y-label for the first column\n",
    "    scatter_axes[0].set_ylabel('SYPD')\n",
    "    scatter_axes[3].set_ylabel('SYPD')\n",
    "    plt.tight_layout()\n",
    "    # plt.savefig('state_rmse_profiles_and_scalar.pdf', format='pdf', dpi=400, bbox_inches='tight')\n",
    "    if save_path:\n",
    "        plt.savefig(os.path.join(save_path, f'online_{num_years}_year_global_RMSE_model_comparison_{config_name}.png'), dpi=300, bbox_inches='tight')\n",
    "    if show:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9eb2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_global_rmse_vs_sypd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9552d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}