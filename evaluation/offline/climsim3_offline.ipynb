{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0c2dc73-0ed6-4070-80ec-f84fc46eb350",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-18 22:21:19.980118: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-02-18 22:21:20.144654: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-02-18 22:21:20.187951: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-18 22:21:20.466342: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/tmp/ipykernel_900785/400801370.py:81: RuntimeWarning: divide by zero encountered in divide\n",
      "  npy_input = (npy_input - input_sub)/input_div\n",
      "  0%|          | 11/4380 [00:17<1:55:12,  1.58s/it]\n",
      "  0%|          | 11/4380 [00:07<47:49,  1.52it/s] \n",
      "/tmp/ipykernel_900785/400801370.py:153: RuntimeWarning: divide by zero encountered in divide\n",
      "  coeff = 1 - rss/tss\n",
      "/tmp/ipykernel_900785/400801370.py:153: RuntimeWarning: invalid value encountered in divide\n",
      "  coeff = 1 - rss/tss\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "import torch\n",
    "import os, gc\n",
    "from climsim_utils.data_utils import *\n",
    "from tqdm import tqdm\n",
    "\n",
    "input_path = '/global/homes/j/jerrylin/scratch/hugging/E3SM-MMF_ne4/preprocessing/v2_rh_mc_full/scoring_set/scoring_input.npy'\n",
    "target_path = '/global/homes/j/jerrylin/scratch/hugging/E3SM-MMF_ne4/preprocessing/v2_rh_mc_full/scoring_set/scoring_target.npy'\n",
    "preds_path = '/global/homes/j/jerrylin/scratch/hugging/E3SM-MMF_ne4/preprocessing/v2_rh_mc_full/scoring_set/'\n",
    "\n",
    "pure_resLSTM_path = '/global/homes/j/jerrylin/scratch/hugging/E3SM-MMF_ne4/saved_models/climsim3_allhands/pure_resLSTM_AdamW/model.pt'\n",
    "pao_model_path = '/global/homes/j/jerrylin/scratch/hugging/E3SM-MMF_ne4/saved_models/climsim3_allhands/pao_model_AdamW_restart_1/model.pt'\n",
    "\n",
    "model_paths = {'pure_resLSTM': pure_resLSTM_path, \\\n",
    "               'pao_model': pao_model_path}\n",
    "\n",
    "model_colors = {'pure_resLSTM': 'blue', \\\n",
    "                'pao_model': 'red'}\n",
    "\n",
    "model_labels = {'pure_resLSTM': 'pure resLSTM', \\\n",
    "                'pao_model': 'Pao Model'}\n",
    "\n",
    "num_models = len(model_paths)\n",
    "model_preds = {}\n",
    "r2_scores = {}\n",
    "r2_scores_capped = {}\n",
    "zonal_heating_r2 = {}\n",
    "zonal_moistening_r2 = {}\n",
    "\n",
    "input_mean_file = 'input_mean_v6_pervar.nc'\n",
    "input_max_file = 'input_max_v6_pervar.nc'\n",
    "input_min_file = 'input_min_v6_pervar.nc'\n",
    "output_scale_file = 'output_scale_std_lowerthred_v6.nc'\n",
    "lbd_qn_file = 'qn_exp_lambda_large.txt'\n",
    "\n",
    "grid_path = '../../grid_info/ClimSim_low-res_grid-info.nc'\n",
    "norm_path = '../../preprocessing/normalizations/'\n",
    "\n",
    "grid_info = xr.open_dataset(grid_path)\n",
    "input_mean = xr.open_dataset('../../preprocessing/normalizations/inputs/' + input_mean_file)\n",
    "input_max = xr.open_dataset('../../preprocessing/normalizations/inputs/' + input_max_file)\n",
    "input_min = xr.open_dataset('../../preprocessing/normalizations/inputs/' + input_min_file)\n",
    "output_scale = xr.open_dataset('../../preprocessing/normalizations/outputs/' + output_scale_file)\n",
    "lbd_qn = np.loadtxt('../../preprocessing/normalizations/inputs/' + lbd_qn_file, delimiter = ',')\n",
    "\n",
    "data = data_utils(grid_info = grid_info, \n",
    "                  input_mean = input_mean, \n",
    "                  input_max = input_max, \n",
    "                  input_min = input_min, \n",
    "                  output_scale = output_scale,\n",
    "                  qinput_log = False)\n",
    "data.set_to_v2_rh_mc_vars()\n",
    "\n",
    "input_sub, input_div, out_scale = data.save_norm(write=False) # this extracts only the relevant variables\n",
    "input_sub = input_sub[None, :]\n",
    "input_div = input_div[None, :]\n",
    "out_scale = out_scale[None, :]\n",
    "\n",
    "lat = grid_info['lat'].values\n",
    "lon = grid_info['lon'].values\n",
    "lat_bin_mids = data.lat_bin_mids\n",
    "\n",
    "def preprocessing_v2_rh_mc(data, input_path, target_path):\n",
    "    npy_input = np.load(input_path)\n",
    "    npy_target = np.load(target_path)\n",
    "    \n",
    "    surface_pressure = npy_input[:, data.ps_index] * \\\n",
    "                        (input_max['state_ps'].values - input_min['state_ps'].values) + \\\n",
    "                        input_mean['state_ps'].values\n",
    "    \n",
    "    hyam_component = (data.hyam * data.p0)[np.newaxis,:]\n",
    "    hybm_component = data.hybm[np.newaxis,:] * surface_pressure[:, np.newaxis]\n",
    "    \n",
    "    pressures = hyam_component + hybm_component\n",
    "    pressures = pressures.reshape(-1,384,60)\n",
    "    \n",
    "    pressures_binned = data.zonal_bin_weight_3d(pressures)\n",
    "    \n",
    "    npy_input[:,120:180] = 1 - np.exp(-npy_input[:,120:180] * lbd_qn)\n",
    "    npy_input = (npy_input - input_sub)/input_div\n",
    "    npy_input = np.where(np.isnan(npy_input), 0, npy_input)\n",
    "    npy_input = np.where(np.isinf(npy_input), 0, npy_input)\n",
    "    npy_input[:,120:120+15] = 0\n",
    "    npy_input[:,60:120] = np.clip(npy_input[:,60:120], 0, 1.2)\n",
    "    torch_input = torch.tensor(npy_input).float()\n",
    "    reshaped_target = npy_target.reshape(-1, data.num_latlon, data.target_feature_len)\n",
    "    return torch_input, reshaped_target, pressures_binned\n",
    "\n",
    "torch_input, reshaped_target, pressures_binned = preprocessing_v2_rh_mc(data, input_path, target_path)\n",
    "\n",
    "assert torch_input.shape[0] == reshaped_target.shape[0] * reshaped_target.shape[1]\n",
    "assert torch_input.shape[0] % data.num_latlon == 0\n",
    "\n",
    "# model inference\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "for model_name in model_paths.keys():\n",
    "    model = torch.jit.load(model_paths[model_name]).to(device)\n",
    "    model.eval()\n",
    "    model_batch_pred_list = []\n",
    "    batch_size = data.num_latlon\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(0, torch_input.shape[0], batch_size)):\n",
    "            model_batch_pred = model(torch_input[i : i + batch_size, :]) # inference on batch\n",
    "            model_batch_pred_list.append(model_batch_pred.cpu().numpy() / out_scale)\n",
    "            if i > 3840: # this is temporary, remove in final code\n",
    "                break # this is temporary, remove in final code\n",
    "    model_preds[model_name] = np.stack(model_batch_pred_list, axis = 0) # 0 axis corresponds to time\n",
    "    np.save(f'{model_name}_preds.npy', model_preds[model_name])\n",
    "    \n",
    "    del model\n",
    "    del model_batch_pred_list\n",
    "    gc.collect()\n",
    "\n",
    "reshaped_target = reshaped_target[:12,...] # this is temporary, remove this later\n",
    "pressures_binned = pressures_binned[:12,...] # this is temporary, remove this later\n",
    "\n",
    "def show_r2(target, preds):\n",
    "    assert target.shape == preds.shape\n",
    "    new_shape = (np.prod(target.shape[:-1]), target.shape[-1])\n",
    "    target_flattened = target.reshape(new_shape)\n",
    "    preds_flattened = preds.reshape(new_shape)\n",
    "    r2_scores = np.array([r2_score(target_flattened[:, i], preds_flattened[:, i]) for i in range(308)])\n",
    "    r2_scores_capped = r2_scores.copy()\n",
    "    r2_scores_capped[r2_scores_capped < 0] = 0\n",
    "    return r2_scores, r2_scores_capped\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "for model_name in model_paths.keys():\n",
    "    r2_scores[model_name], r2_scores_capped[model_name] = show_r2(reshaped_target, model_preds[model_name])\n",
    "    label_text = f'{model_labels[model_name]}: {np.mean(r2_scores[model_name]):.3g}' \n",
    "    plt.plot(np.arange(data.target_feature_len), r2_scores[model_name], color = model_colors[model_name], label=f\"{label_text}\")\n",
    "    \n",
    "plt.legend()\n",
    "plt.xlabel('Feature Index')\n",
    "plt.ylabel(r'$R^2$ Score')\n",
    "plt.title(r'$R^2$ Score Comparison')\n",
    "\n",
    "feature_indices = [0, 60, 120, 180, 240, 300, 308]\n",
    "feature_labels = ['dT', 'dQv', 'dQn (liq+ice)', 'dU', 'dV', 'scalars', '']\n",
    "plt.xticks(ticks=feature_indices, labels=feature_labels)\n",
    "plt.ylim(0, 1)\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.savefig(preds_path + 'r2_lines.png')\n",
    "plt.clf()\n",
    "\n",
    "def get_coeff(target, pred):\n",
    "    rss = np.sum((pred - target)**2, axis = 0)\n",
    "    tss = np.sum((target - np.mean(target, axis = 0)[None,:,:])**2, axis = 0)\n",
    "    coeff = 1 - rss/tss\n",
    "    mask = tss == 0\n",
    "    coeff[mask] = 1.0 * (rss[mask] == 0) \n",
    "    return coeff\n",
    "\n",
    "for model_name in model_paths.keys():\n",
    "    zonal_heating_r2[model_name] = data.zonal_bin_weight_3d(get_coeff(reshaped_target[:,:,:60], \\\n",
    "                                                                      model_preds[model_name][:,:,:60]))[0]\n",
    "    zonal_moistening_r2[model_name] = data.zonal_bin_weight_3d(get_coeff(reshaped_target[:,:,60:120], \\\n",
    "                                                                          model_preds[model_name][:,:,60:120]))[0]\n",
    "\n",
    "fig, ax = plt.subplots(2, num_models, figsize = (num_models*12, 18))\n",
    "y = np.arange(60)\n",
    "X, Y = np.meshgrid(np.sin(np.pi*lat_bin_mids/180), y)\n",
    "Y = (1/100) * np.mean(pressures_binned, axis = 0).T\n",
    "for i, model_name in enumerate(['pure_resLSTM', 'pao_model']):\n",
    "    contour_plot_heating = ax[0,i].pcolor(X, Y, zonal_heating_r2[model_name].T, cmap='Blues', vmin = 0, vmax = 1)\n",
    "    ax[0,i].contour(X, Y, zonal_heating_r2[model_name].T, [0.7], colors='orange', linewidths=[4])\n",
    "    ax[0,i].contour(X, Y, zonal_heating_r2[model_name].T, [0.9], colors='yellow', linewidths=[4])\n",
    "    ax[0,i].set_ylim(ax[0,i].get_ylim()[::-1])\n",
    "    ax[0,i].set_title(f'{model_labels[model_name]} (heating)', fontsize = 20)\n",
    "    ax[0,i].set_xticks([])\n",
    "    contour_plot = ax[1,i].pcolor(X, Y, zonal_moistening_r2[model_name].T, cmap='Blues', vmin = 0, vmax = 1) # pcolormesh\n",
    "    ax[1,i].contour(X, Y, zonal_moistening_r2[model_name].T, [0.7], colors='orange', linewidths=[4])\n",
    "    ax[1,i].contour(X, Y, zonal_moistening_r2[model_name].T, [0.9], colors='yellow', linewidths=[4])\n",
    "    ax[1,i].set_ylim(ax[1,i].get_ylim()[::-1])\n",
    "    ax[1,i].set_title(f'{model_labels[model_name]} (moistening)', fontsize = 20)\n",
    "    ax[1,i].xaxis.set_ticks([np.sin(-50/180*np.pi), 0, np.sin(50/180*np.pi)])\n",
    "    ax[1,i].xaxis.set_ticklabels(['50$^\\circ$S', '0$^\\circ$', '50$^\\circ$N'], fontsize = 16)\n",
    "    ax[1,i].xaxis.set_tick_params(width = 2)\n",
    "    if i != 0:\n",
    "        ax[0,i].set_yticks([])\n",
    "        ax[1,i].set_yticks([])\n",
    "ax[0,0].set_ylabel(\"Pressure [hPa]\", fontsize = 22)\n",
    "ax[0,0].yaxis.set_label_coords(-0.2,-0.09) # (-1.38,-0.09)\n",
    "ax[0,0].yaxis.set_tick_params(labelsize = 14)\n",
    "ax[1,0].yaxis.set_tick_params(labelsize = 14)\n",
    "ax[0,0].yaxis.set_ticks([1000,800,600,400,200,0])\n",
    "ax[1,0].yaxis.set_ticks([1000,800,600,400,200,0])\n",
    "fig.subplots_adjust(right=0.8)\n",
    "cbar_ax = fig.add_axes([0.82, 0.12, 0.02, 0.76])\n",
    "cb = fig.colorbar(contour_plot, cax=cbar_ax)\n",
    "cb.set_label(\"Skill Score \"+r'$\\left(\\mathrm{R^{2}}\\right)$',labelpad=50.1, fontsize = 20)\n",
    "plt.suptitle(\"Baseline Models Skill for Vertically Resolved Tendencies\", y = 0.97, fontsize = 22)\n",
    "plt.subplots_adjust(hspace=0.1)\n",
    "plt.savefig(preds_path + 'press_lat_r2_models.png', bbox_inches='tight', pad_inches=0.1 , dpi = 300)\n",
    "plt.clf()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MyEnvironment",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
